2024-05-16 19:06:44,721 INFO: 
                ____                _       _____  ____
               / __ ) ____ _ _____ (_)_____/ ___/ / __ \
              / __  |/ __ `// ___// // ___/\__ \ / /_/ /
             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/
            /_____/ \__,_//____//_/ \___//____//_/ |_|
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	BasicSR: 1.3.5
	PyTorch: 1.8.0
	TorchVision: 0.9.0
2024-05-16 19:06:44,722 INFO: 
  name: train_DAT_S_x4
  model_type: DATModel
  scale: 4
  num_gpu: 1
  manual_seed: 10
  datasets:[
    train:[
      task: SR
      name: DF2K
      type: PairedImageDataset
      dataroot_gt: datasets/DF2K/HR
      dataroot_lq: datasets/DF2K/LR_bicubic/X4
      filename_tmpl: {}x4
      io_backend:[
        type: disk
      ]
      gt_size: 256
      use_hflip: True
      use_rot: True
      use_shuffle: True
      num_worker_per_gpu: 12
      batch_size_per_gpu: 8
      dataset_enlarge_ratio: 1
      prefetch_mode: None
      phase: train
      scale: 4
    ]
    val:[
      task: SR
      name: Set5
      type: PairedImageDataset
      dataroot_gt: datasets/benchmark/Set5/HR
      dataroot_lq: datasets/benchmark/Set5/LR_bicubic/X4
      filename_tmpl: {}x4
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 4
    ]
  ]
  network_g:[
    type: DAT
    upscale: 4
    in_chans: 3
    img_size: 64
    img_range: 1.0
    split_size: [8, 16]
    depth: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    expansion_factor: 2
    resi_connection: 1conv
  ]
  path:[
    pretrain_network_g: experiments/pretrained_models/DAT-S/DAT_S_x2.pth
    strict_load_g: False
    resume_state: None
    experiments_root: /home/user/projects_sr/DAT/experiments/train_DAT_S_x4
    models: /home/user/projects_sr/DAT/experiments/train_DAT_S_x4/models
    training_states: /home/user/projects_sr/DAT/experiments/train_DAT_S_x4/training_states
    log: /home/user/projects_sr/DAT/experiments/train_DAT_S_x4
    visualization: /home/user/projects_sr/DAT/experiments/train_DAT_S_x4/visualization
  ]
  train:[
    optim_g:[
      type: Adam
      lr: 0.0001
      weight_decay: 0
      betas: [0.9, 0.99]
    ]
    scheduler:[
      type: MultiStepLR
      milestones: [125000, 200000, 225000, 237500]
      gamma: 0.5
    ]
    total_iter: 250000
    warmup_iter: -1
    pixel_opt:[
      type: L1Loss
      loss_weight: 1.0
      reduction: mean
    ]
  ]
  val:[
    val_freq: 5000.0
    save_img: False
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 4
        test_y_channel: True
      ]
    ]
  ]
  logger:[
    print_freq: 200
    save_checkpoint_freq: 5000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: True
  rank: 0
  world_size: 1
  auto_resume: False
  is_train: True
  root_path: /home/user/projects_sr/DAT

2024-05-16 19:06:47,440 INFO: Dataset [PairedImageDataset] - DF2K is built.
2024-05-16 19:06:47,440 INFO: Training statistics:
	Number of train images: 3550
	Dataset enlarge ratio: 1
	Batch size per gpu: 8
	World size (gpu number): 1
	Require iter number per epoch: 444
	Total epochs: 564; iters: 250000.
2024-05-16 19:06:47,466 INFO: Dataset [PairedImageDataset] - Set5 is built.
2024-05-16 19:06:47,467 INFO: Number of val images/folders in Set5: 5
2024-05-16 19:06:48,319 INFO: Network [DAT] is created.
2024-05-16 19:07:14,070 INFO: Network: DistributedDataParallel - DAT, with parameters: 11,212,131
2024-05-16 19:07:14,075 INFO: DAT(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (before_RG): Sequential(
    (0): Rearrange('b c h w -> b (h w) c')
    (1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (layers): ModuleList(
    (0): ResidualGroup(
      (blocks): ModuleList(
        (0): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): Identity()
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (1): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.003)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (2): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.006)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (3): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.009)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (4): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.011)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (5): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.014)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (1): ResidualGroup(
      (blocks): ModuleList(
        (0): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.017)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (1): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.020)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (2): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.023)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (3): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.026)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (4): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.029)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (5): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.031)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (2): ResidualGroup(
      (blocks): ModuleList(
        (0): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.034)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (1): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.037)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (2): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.040)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (3): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.043)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (4): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.046)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (5): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.049)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (3): ResidualGroup(
      (blocks): ModuleList(
        (0): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.051)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (1): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.054)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (2): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.057)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (3): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.060)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (4): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.063)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (5): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.066)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (4): ResidualGroup(
      (blocks): ModuleList(
        (0): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.069)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (1): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.071)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (2): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.074)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (3): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.077)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (4): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.080)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (5): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.083)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (5): ResidualGroup(
      (blocks): ModuleList(
        (0): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.086)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (1): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.089)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (2): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.091)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (3): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.094)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (4): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.097)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (5): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.100)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
    (2): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2024-05-16 19:07:15,898 INFO: Loading DAT model from experiments/pretrained_models/DAT-S/DAT_S_x2.pth, with param key: [params].
2024-05-16 19:07:16,080 WARNING: Current net - loaded net:
2024-05-16 19:07:16,081 WARNING:   upsample.2.bias
2024-05-16 19:07:16,081 WARNING:   upsample.2.weight
2024-05-16 19:07:16,081 WARNING: Loaded net - current net:
2024-05-16 19:07:16,549 INFO: Loss [L1Loss] is created.
2024-05-16 19:07:16,555 INFO: Model [DATModel] is created.
2024-05-16 19:07:34,478 INFO: Start training from epoch: 0, iter: 0
2024-05-16 19:11:29,341 INFO: [train..][epoch:  0, iter:     200, lr:(1.000e-04,)] [eta: 3 days, 3:32:28, time (data): 1.174 (0.074)] l_pix: 3.4275e-02 
2024-05-16 19:15:07,906 INFO: [train..][epoch:  0, iter:     400, lr:(1.000e-04,)] [eta: 3 days, 3:37:27, time (data): 1.093 (0.003)] l_pix: 2.0086e-02 
2024-05-16 19:19:06,495 INFO: [train..][epoch:  1, iter:     600, lr:(1.000e-04,)] [eta: 3 days, 5:55:12, time (data): 1.194 (0.102)] l_pix: 3.3613e-02 
2024-05-16 19:22:48,288 INFO: [train..][epoch:  1, iter:     800, lr:(1.000e-04,)] [eta: 3 days, 5:35:04, time (data): 1.109 (0.003)] l_pix: 2.5241e-02 
2024-05-16 19:26:41,343 INFO: [train..][epoch:  2, iter:   1,000, lr:(1.000e-04,)] [eta: 3 days, 6:08:12, time (data): 1.167 (0.073)] l_pix: 2.0160e-02 
2024-05-16 19:30:22,570 INFO: [train..][epoch:  2, iter:   1,200, lr:(1.000e-04,)] [eta: 3 days, 5:48:10, time (data): 1.106 (0.003)] l_pix: 3.1876e-02 
2024-05-16 19:34:14,711 INFO: [train..][epoch:  3, iter:   1,400, lr:(1.000e-04,)] [eta: 3 days, 6:05:05, time (data): 1.162 (0.065)] l_pix: 3.3225e-02 
2024-05-16 19:37:55,402 INFO: [train..][epoch:  3, iter:   1,600, lr:(1.000e-04,)] [eta: 3 days, 5:47:12, time (data): 1.104 (0.003)] l_pix: 2.0601e-02 
2024-05-16 19:41:47,851 INFO: [train..][epoch:  4, iter:   1,800, lr:(1.000e-04,)] [eta: 3 days, 5:59:28, time (data): 1.165 (0.066)] l_pix: 2.2439e-02 
2024-05-16 19:45:27,483 INFO: [train..][epoch:  4, iter:   2,000, lr:(1.000e-04,)] [eta: 3 days, 5:42:02, time (data): 1.099 (0.003)] l_pix: 2.6563e-02 
2024-05-16 19:49:08,692 INFO: [train..][epoch:  4, iter:   2,200, lr:(1.000e-04,)] [eta: 3 days, 5:30:04, time (data): 1.106 (0.003)] l_pix: 1.5808e-02 
2024-05-16 19:52:59,552 INFO: [train..][epoch:  5, iter:   2,400, lr:(1.000e-04,)] [eta: 3 days, 5:36:04, time (data): 1.158 (0.068)] l_pix: 3.4505e-02 
2024-05-16 19:56:40,479 INFO: [train..][epoch:  5, iter:   2,600, lr:(1.000e-04,)] [eta: 3 days, 5:24:48, time (data): 1.105 (0.003)] l_pix: 2.8051e-02 
2024-05-16 20:00:31,780 INFO: [train..][epoch:  6, iter:   2,800, lr:(1.000e-04,)] [eta: 3 days, 5:29:53, time (data): 1.160 (0.068)] l_pix: 2.9854e-02 
2024-05-16 20:04:13,295 INFO: [train..][epoch:  6, iter:   3,000, lr:(1.000e-04,)] [eta: 3 days, 5:20:21, time (data): 1.108 (0.003)] l_pix: 3.4576e-02 
2024-05-16 20:08:04,983 INFO: [train..][epoch:  7, iter:   3,200, lr:(1.000e-04,)] [eta: 3 days, 5:24:37, time (data): 1.162 (0.068)] l_pix: 3.7725e-02 
2024-05-16 20:11:45,734 INFO: [train..][epoch:  7, iter:   3,400, lr:(1.000e-04,)] [eta: 3 days, 5:14:43, time (data): 1.104 (0.003)] l_pix: 3.5736e-02 
2024-05-16 20:15:39,132 INFO: [train..][epoch:  8, iter:   3,600, lr:(1.000e-04,)] [eta: 3 days, 5:19:55, time (data): 1.172 (0.071)] l_pix: 1.8622e-02 
2024-05-16 20:19:19,226 INFO: [train..][epoch:  8, iter:   3,800, lr:(1.000e-04,)] [eta: 3 days, 5:09:48, time (data): 1.101 (0.003)] l_pix: 1.9565e-02 
2024-05-16 20:23:12,424 INFO: [train..][epoch:  9, iter:   4,000, lr:(1.000e-04,)] [eta: 3 days, 5:13:46, time (data): 1.172 (0.069)] l_pix: 3.0407e-02 
2024-05-16 20:26:51,187 INFO: [train..][epoch:  9, iter:   4,200, lr:(1.000e-04,)] [eta: 3 days, 5:02:54, time (data): 1.094 (0.003)] l_pix: 2.5624e-02 
2024-05-16 20:30:32,227 INFO: [train..][epoch:  9, iter:   4,400, lr:(1.000e-04,)] [eta: 3 days, 4:54:49, time (data): 1.106 (0.003)] l_pix: 1.7658e-02 
2024-05-16 20:34:23,154 INFO: [train..][epoch: 10, iter:   4,600, lr:(1.000e-04,)] [eta: 3 days, 4:55:54, time (data): 1.161 (0.071)] l_pix: 1.1703e-02 
2024-05-16 20:38:03,134 INFO: [train..][epoch: 10, iter:   4,800, lr:(1.000e-04,)] [eta: 3 days, 4:47:15, time (data): 1.100 (0.003)] l_pix: 2.0598e-02 
2024-05-16 20:41:54,856 INFO: [train..][epoch: 11, iter:   5,000, lr:(1.000e-04,)] [eta: 3 days, 4:48:36, time (data): 1.166 (0.072)] l_pix: 3.5085e-02 
2024-05-16 20:41:54,857 INFO: Saving models and training states.
2024-05-16 20:41:59,329 INFO: Validation Set5
	 # psnr: 32.7693	Best: 32.7693 @ 5000 iter

2024-05-16 20:45:38,718 INFO: [train..][epoch: 11, iter:   5,200, lr:(1.000e-04,)] [eta: 3 days, 4:43:22, time (data): 1.098 (0.004)] l_pix: 2.9845e-02 
2024-05-16 20:49:31,871 INFO: [train..][epoch: 12, iter:   5,400, lr:(1.000e-04,)] [eta: 3 days, 4:45:16, time (data): 1.175 (0.076)] l_pix: 2.2796e-02 
2024-05-16 20:53:13,147 INFO: [train..][epoch: 12, iter:   5,600, lr:(1.000e-04,)] [eta: 3 days, 4:38:07, time (data): 1.106 (0.004)] l_pix: 3.0171e-02 
2024-05-16 20:57:05,115 INFO: [train..][epoch: 13, iter:   5,800, lr:(1.000e-04,)] [eta: 3 days, 4:38:42, time (data): 1.170 (0.076)] l_pix: 2.7807e-02 
2024-05-16 21:00:44,846 INFO: [train..][epoch: 13, iter:   6,000, lr:(1.000e-04,)] [eta: 3 days, 4:30:42, time (data): 1.100 (0.003)] l_pix: 2.6007e-02 
2024-05-16 21:04:25,070 INFO: [train..][epoch: 13, iter:   6,200, lr:(1.000e-04,)] [eta: 3 days, 4:23:18, time (data): 1.102 (0.003)] l_pix: 1.6356e-02 
2024-05-16 21:08:17,543 INFO: [train..][epoch: 14, iter:   6,400, lr:(1.000e-04,)] [eta: 3 days, 4:23:54, time (data): 1.100 (0.003)] l_pix: 2.9086e-02 
2024-05-16 21:11:57,605 INFO: [train..][epoch: 14, iter:   6,600, lr:(1.000e-04,)] [eta: 3 days, 4:16:36, time (data): 1.100 (0.003)] l_pix: 2.7897e-02 
2024-05-16 21:15:49,164 INFO: [train..][epoch: 15, iter:   6,800, lr:(1.000e-04,)] [eta: 3 days, 4:16:22, time (data): 1.169 (0.075)] l_pix: 2.6362e-02 
2024-05-16 21:19:29,650 INFO: [train..][epoch: 15, iter:   7,000, lr:(1.000e-04,)] [eta: 3 days, 4:09:32, time (data): 1.102 (0.003)] l_pix: 2.3171e-02 
2024-05-16 21:23:21,757 INFO: [train..][epoch: 16, iter:   7,200, lr:(1.000e-04,)] [eta: 3 days, 4:09:24, time (data): 1.173 (0.080)] l_pix: 2.9087e-02 
2024-05-16 21:27:01,747 INFO: [train..][epoch: 16, iter:   7,400, lr:(1.000e-04,)] [eta: 3 days, 4:02:26, time (data): 1.099 (0.003)] l_pix: 3.7174e-02 
2024-05-16 21:30:52,464 INFO: [train..][epoch: 17, iter:   7,600, lr:(1.000e-04,)] [eta: 3 days, 4:01:21, time (data): 1.166 (0.076)] l_pix: 1.5238e-02 
2024-05-16 21:34:32,750 INFO: [train..][epoch: 17, iter:   7,800, lr:(1.000e-04,)] [eta: 3 days, 3:54:44, time (data): 1.101 (0.003)] l_pix: 1.9413e-02 
2024-05-16 21:38:24,243 INFO: [train..][epoch: 18, iter:   8,000, lr:(1.000e-04,)] [eta: 3 days, 3:53:54, time (data): 1.172 (0.080)] l_pix: 1.7047e-02 
2024-05-16 21:42:03,693 INFO: [train..][epoch: 18, iter:   8,200, lr:(1.000e-04,)] [eta: 3 days, 3:47:01, time (data): 1.099 (0.003)] l_pix: 2.0982e-02 
2024-05-16 21:45:42,765 INFO: [train..][epoch: 18, iter:   8,400, lr:(1.000e-04,)] [eta: 3 days, 3:40:06, time (data): 1.096 (0.003)] l_pix: 2.8361e-02 
2024-05-16 21:49:34,146 INFO: [train..][epoch: 19, iter:   8,600, lr:(1.000e-04,)] [eta: 3 days, 3:39:05, time (data): 1.096 (0.003)] l_pix: 2.9911e-02 
2024-05-16 21:53:13,668 INFO: [train..][epoch: 19, iter:   8,800, lr:(1.000e-04,)] [eta: 3 days, 3:32:32, time (data): 1.097 (0.003)] l_pix: 2.3124e-02 
2024-05-16 21:57:05,533 INFO: [train..][epoch: 20, iter:   9,000, lr:(1.000e-04,)] [eta: 3 days, 3:31:37, time (data): 1.176 (0.084)] l_pix: 2.2737e-02 
2024-05-16 22:00:45,045 INFO: [train..][epoch: 20, iter:   9,200, lr:(1.000e-04,)] [eta: 3 days, 3:25:11, time (data): 1.097 (0.003)] l_pix: 2.5481e-02 
2024-05-16 22:04:35,859 INFO: [train..][epoch: 21, iter:   9,400, lr:(1.000e-04,)] [eta: 3 days, 3:23:41, time (data): 1.172 (0.081)] l_pix: 2.8257e-02 
2024-05-16 22:08:15,734 INFO: [train..][epoch: 21, iter:   9,600, lr:(1.000e-04,)] [eta: 3 days, 3:17:32, time (data): 1.098 (0.003)] l_pix: 2.0429e-02 
2024-05-16 22:12:06,356 INFO: [train..][epoch: 22, iter:   9,800, lr:(1.000e-04,)] [eta: 3 days, 3:15:52, time (data): 1.171 (0.081)] l_pix: 2.9463e-02 
2024-05-16 22:15:47,249 INFO: [train..][epoch: 22, iter:  10,000, lr:(1.000e-04,)] [eta: 3 days, 3:10:13, time (data): 1.107 (0.003)] l_pix: 2.1254e-02 
2024-05-16 22:15:47,249 INFO: Saving models and training states.
2024-05-16 22:15:48,538 INFO: Validation Set5
	 # psnr: 32.8536	Best: 32.8536 @ 10000 iter

2024-05-16 22:19:40,865 INFO: [train..][epoch: 23, iter:  10,200, lr:(1.000e-04,)] [eta: 3 days, 3:09:38, time (data): 1.182 (0.084)] l_pix: 2.4086e-02 
2024-05-16 22:23:20,175 INFO: [train..][epoch: 23, iter:  10,400, lr:(1.000e-04,)] [eta: 3 days, 3:03:26, time (data): 1.099 (0.003)] l_pix: 3.2596e-02 
2024-05-16 22:26:59,743 INFO: [train..][epoch: 23, iter:  10,600, lr:(1.000e-04,)] [eta: 3 days, 2:57:25, time (data): 1.097 (0.003)] l_pix: 4.1334e-02 
2024-05-16 22:30:51,275 INFO: [train..][epoch: 24, iter:  10,800, lr:(1.000e-04,)] [eta: 3 days, 2:55:55, time (data): 1.098 (0.004)] l_pix: 2.7184e-02 
2024-05-16 22:34:31,433 INFO: [train..][epoch: 24, iter:  11,000, lr:(1.000e-04,)] [eta: 3 days, 2:50:12, time (data): 1.100 (0.004)] l_pix: 2.0254e-02 
2024-05-16 22:38:22,646 INFO: [train..][epoch: 25, iter:  11,200, lr:(1.000e-04,)] [eta: 3 days, 2:48:29, time (data): 1.177 (0.086)] l_pix: 2.2327e-02 
2024-05-16 22:42:02,728 INFO: [train..][epoch: 25, iter:  11,400, lr:(1.000e-04,)] [eta: 3 days, 2:42:49, time (data): 1.098 (0.003)] l_pix: 1.5607e-02 
2024-05-16 22:45:54,178 INFO: [train..][epoch: 26, iter:  11,600, lr:(1.000e-04,)] [eta: 3 days, 2:41:07, time (data): 1.182 (0.087)] l_pix: 3.0586e-02 
2024-05-16 22:49:34,440 INFO: [train..][epoch: 26, iter:  11,800, lr:(1.000e-04,)] [eta: 3 days, 2:35:34, time (data): 1.101 (0.003)] l_pix: 2.3191e-02 
2024-05-16 22:53:25,306 INFO: [train..][epoch: 27, iter:  12,000, lr:(1.000e-04,)] [eta: 3 days, 2:33:36, time (data): 1.178 (0.088)] l_pix: 1.8287e-02 
2024-05-16 22:57:05,001 INFO: [train..][epoch: 27, iter:  12,200, lr:(1.000e-04,)] [eta: 3 days, 2:27:56, time (data): 1.103 (0.003)] l_pix: 2.5365e-02 
2024-05-16 23:00:44,989 INFO: [train..][epoch: 27, iter:  12,400, lr:(1.000e-04,)] [eta: 3 days, 2:22:26, time (data): 1.099 (0.003)] l_pix: 1.6118e-02 
2024-05-16 23:04:35,849 INFO: [train..][epoch: 28, iter:  12,600, lr:(1.000e-04,)] [eta: 3 days, 2:20:24, time (data): 1.099 (0.003)] l_pix: 2.5188e-02 
2024-05-16 23:08:16,378 INFO: [train..][epoch: 28, iter:  12,800, lr:(1.000e-04,)] [eta: 3 days, 2:15:07, time (data): 1.101 (0.003)] l_pix: 2.0375e-02 
2024-05-16 23:12:06,930 INFO: [train..][epoch: 29, iter:  13,000, lr:(1.000e-04,)] [eta: 3 days, 2:12:55, time (data): 1.091 (0.003)] l_pix: 4.2350e-02 
2024-05-16 23:15:47,462 INFO: [train..][epoch: 29, iter:  13,200, lr:(1.000e-04,)] [eta: 3 days, 2:07:42, time (data): 1.103 (0.003)] l_pix: 1.9038e-02 
2024-05-16 23:19:38,157 INFO: [train..][epoch: 30, iter:  13,400, lr:(1.000e-04,)] [eta: 3 days, 2:05:30, time (data): 1.181 (0.093)] l_pix: 2.5851e-02 
2024-05-16 23:23:18,882 INFO: [train..][epoch: 30, iter:  13,600, lr:(1.000e-04,)] [eta: 3 days, 2:00:22, time (data): 1.104 (0.003)] l_pix: 3.4191e-02 
2024-05-16 23:27:10,060 INFO: [train..][epoch: 31, iter:  13,800, lr:(1.000e-04,)] [eta: 3 days, 1:58:15, time (data): 1.183 (0.094)] l_pix: 2.2722e-02 
2024-05-16 23:30:51,035 INFO: [train..][epoch: 31, iter:  14,000, lr:(1.000e-04,)] [eta: 3 days, 1:53:14, time (data): 1.107 (0.003)] l_pix: 3.8446e-02 
2024-05-16 23:34:42,762 INFO: [train..][epoch: 32, iter:  14,200, lr:(1.000e-04,)] [eta: 3 days, 1:51:13, time (data): 1.189 (0.096)] l_pix: 2.5012e-02 
2024-05-16 23:38:22,077 INFO: [train..][epoch: 32, iter:  14,400, lr:(1.000e-04,)] [eta: 3 days, 1:45:46, time (data): 1.102 (0.003)] l_pix: 1.8329e-02 
2024-05-16 23:42:02,381 INFO: [train..][epoch: 32, iter:  14,600, lr:(1.000e-04,)] [eta: 3 days, 1:40:38, time (data): 1.100 (0.003)] l_pix: 2.5652e-02 
2024-05-16 23:45:52,915 INFO: [train..][epoch: 33, iter:  14,800, lr:(1.000e-04,)] [eta: 3 days, 1:38:15, time (data): 1.096 (0.003)] l_pix: 2.3333e-02 
2024-05-16 23:49:33,605 INFO: [train..][epoch: 33, iter:  15,000, lr:(1.000e-04,)] [eta: 3 days, 1:33:16, time (data): 1.103 (0.003)] l_pix: 1.6345e-02 
2024-05-16 23:49:33,605 INFO: Saving models and training states.
2024-05-16 23:49:35,032 INFO: Validation Set5
	 # psnr: 32.8037	Best: 32.8536 @ 10000 iter

2024-05-16 23:53:25,322 INFO: [train..][epoch: 34, iter:  15,200, lr:(1.000e-04,)] [eta: 3 days, 1:31:09, time (data): 1.090 (0.004)] l_pix: 2.2846e-02 
2024-05-16 23:57:06,140 INFO: [train..][epoch: 34, iter:  15,400, lr:(1.000e-04,)] [eta: 3 days, 1:26:13, time (data): 1.103 (0.003)] l_pix: 2.6251e-02 
2024-05-17 00:00:56,792 INFO: [train..][epoch: 35, iter:  15,600, lr:(1.000e-04,)] [eta: 3 days, 1:23:46, time (data): 1.187 (0.099)] l_pix: 2.0951e-02 
2024-05-17 00:04:38,846 INFO: [train..][epoch: 35, iter:  15,800, lr:(1.000e-04,)] [eta: 3 days, 1:19:11, time (data): 1.105 (0.003)] l_pix: 1.7237e-02 
2024-05-17 00:08:30,233 INFO: [train..][epoch: 36, iter:  16,000, lr:(1.000e-04,)] [eta: 3 days, 1:16:53, time (data): 1.194 (0.102)] l_pix: 1.7214e-02 
2024-05-17 00:12:10,114 INFO: [train..][epoch: 36, iter:  16,200, lr:(1.000e-04,)] [eta: 3 days, 1:11:46, time (data): 1.105 (0.003)] l_pix: 3.0096e-02 
2024-05-17 00:16:02,599 INFO: [train..][epoch: 37, iter:  16,400, lr:(1.000e-04,)] [eta: 3 days, 1:09:42, time (data): 1.202 (0.107)] l_pix: 3.1252e-02 
2024-05-17 00:19:41,806 INFO: [train..][epoch: 37, iter:  16,600, lr:(1.000e-04,)] [eta: 3 days, 1:04:28, time (data): 1.102 (0.004)] l_pix: 3.1044e-02 
2024-05-17 00:23:22,205 INFO: [train..][epoch: 37, iter:  16,800, lr:(1.000e-04,)] [eta: 3 days, 0:59:33, time (data): 1.101 (0.004)] l_pix: 2.6178e-02 
2024-05-17 00:27:12,332 INFO: [train..][epoch: 38, iter:  17,000, lr:(1.000e-04,)] [eta: 3 days, 0:56:52, time (data): 1.091 (0.003)] l_pix: 2.2679e-02 
2024-05-17 00:30:53,119 INFO: [train..][epoch: 38, iter:  17,200, lr:(1.000e-04,)] [eta: 3 days, 0:52:04, time (data): 1.103 (0.004)] l_pix: 2.2688e-02 
2024-05-17 00:34:43,485 INFO: [train..][epoch: 39, iter:  17,400, lr:(1.000e-04,)] [eta: 3 days, 0:49:26, time (data): 1.088 (0.004)] l_pix: 3.4587e-02 
2024-05-17 00:38:23,432 INFO: [train..][epoch: 39, iter:  17,600, lr:(1.000e-04,)] [eta: 3 days, 0:44:28, time (data): 1.103 (0.003)] l_pix: 2.4647e-02 
2024-05-17 00:42:16,066 INFO: [train..][epoch: 40, iter:  17,800, lr:(1.000e-04,)] [eta: 3 days, 0:42:18, time (data): 1.210 (0.111)] l_pix: 1.5974e-02 
2024-05-17 00:45:55,904 INFO: [train..][epoch: 40, iter:  18,000, lr:(1.000e-04,)] [eta: 3 days, 0:37:20, time (data): 1.099 (0.003)] l_pix: 3.1687e-02 
2024-05-17 00:49:48,312 INFO: [train..][epoch: 41, iter:  18,200, lr:(1.000e-04,)] [eta: 3 days, 0:35:04, time (data): 1.209 (0.114)] l_pix: 2.1903e-02 
2024-05-17 00:53:27,274 INFO: [train..][epoch: 41, iter:  18,400, lr:(1.000e-04,)] [eta: 3 days, 0:29:57, time (data): 1.098 (0.003)] l_pix: 2.2615e-02 
2024-05-17 00:57:07,898 INFO: [train..][epoch: 41, iter:  18,600, lr:(1.000e-04,)] [eta: 3 days, 0:25:12, time (data): 1.103 (0.003)] l_pix: 3.1176e-02 
2024-05-17 01:00:58,486 INFO: [train..][epoch: 42, iter:  18,800, lr:(1.000e-04,)] [eta: 3 days, 0:22:31, time (data): 1.096 (0.004)] l_pix: 2.5105e-02 
2024-05-17 01:04:38,978 INFO: [train..][epoch: 42, iter:  19,000, lr:(1.000e-04,)] [eta: 3 days, 0:17:46, time (data): 1.105 (0.004)] l_pix: 3.1720e-02 
2024-05-17 01:08:29,665 INFO: [train..][epoch: 43, iter:  19,200, lr:(1.000e-04,)] [eta: 3 days, 0:15:05, time (data): 1.093 (0.004)] l_pix: 1.3218e-02 
2024-05-17 01:12:10,581 INFO: [train..][epoch: 43, iter:  19,400, lr:(1.000e-04,)] [eta: 3 days, 0:10:27, time (data): 1.105 (0.004)] l_pix: 3.0616e-02 
2024-05-17 01:16:01,360 INFO: [train..][epoch: 44, iter:  19,600, lr:(1.000e-04,)] [eta: 3 days, 0:07:45, time (data): 1.086 (0.004)] l_pix: 2.1732e-02 
2024-05-17 01:19:40,461 INFO: [train..][epoch: 44, iter:  19,800, lr:(1.000e-04,)] [eta: 3 days, 0:02:47, time (data): 1.098 (0.003)] l_pix: 3.3839e-02 
2024-05-17 01:23:32,009 INFO: [train..][epoch: 45, iter:  20,000, lr:(1.000e-04,)] [eta: 3 days, 0:00:13, time (data): 1.211 (0.124)] l_pix: 3.4645e-02 
2024-05-17 01:23:32,010 INFO: Saving models and training states.
2024-05-17 01:23:33,382 INFO: Validation Set5
	 # psnr: 32.8359	Best: 32.8536 @ 10000 iter

2024-05-17 01:27:12,435 INFO: [train..][epoch: 45, iter:  20,200, lr:(1.000e-04,)] [eta: 2 days, 23:55:31, time (data): 1.098 (0.003)] l_pix: 1.9218e-02 
2024-05-17 01:31:07,110 INFO: [train..][epoch: 46, iter:  20,400, lr:(1.000e-04,)] [eta: 2 days, 23:53:30, time (data): 1.243 (0.148)] l_pix: 1.7251e-02 
2024-05-17 01:34:45,581 INFO: [train..][epoch: 46, iter:  20,600, lr:(1.000e-04,)] [eta: 2 days, 23:48:27, time (data): 1.097 (0.003)] l_pix: 3.0480e-02 
2024-05-17 01:38:26,316 INFO: [train..][epoch: 46, iter:  20,800, lr:(1.000e-04,)] [eta: 2 days, 23:43:50, time (data): 1.103 (0.003)] l_pix: 1.0465e-02 
2024-05-17 01:42:16,967 INFO: [train..][epoch: 47, iter:  21,000, lr:(1.000e-04,)] [eta: 2 days, 23:41:03, time (data): 1.095 (0.003)] l_pix: 2.7470e-02 
2024-05-17 01:45:58,018 INFO: [train..][epoch: 47, iter:  21,200, lr:(1.000e-04,)] [eta: 2 days, 23:36:31, time (data): 1.106 (0.004)] l_pix: 2.7362e-02 
2024-05-17 01:49:49,026 INFO: [train..][epoch: 48, iter:  21,400, lr:(1.000e-04,)] [eta: 2 days, 23:33:46, time (data): 1.090 (0.004)] l_pix: 2.7772e-02 
2024-05-17 01:53:29,692 INFO: [train..][epoch: 48, iter:  21,600, lr:(1.000e-04,)] [eta: 2 days, 23:29:11, time (data): 1.106 (0.003)] l_pix: 3.5362e-02 
2024-05-17 01:57:20,699 INFO: [train..][epoch: 49, iter:  21,800, lr:(1.000e-04,)] [eta: 2 days, 23:26:25, time (data): 1.088 (0.004)] l_pix: 3.0942e-02 
2024-05-17 02:01:01,857 INFO: [train..][epoch: 49, iter:  22,000, lr:(1.000e-04,)] [eta: 2 days, 23:21:55, time (data): 1.109 (0.004)] l_pix: 1.0995e-02 
2024-05-17 02:04:53,280 INFO: [train..][epoch: 50, iter:  22,200, lr:(1.000e-04,)] [eta: 2 days, 23:19:12, time (data): 1.224 (0.136)] l_pix: 2.5733e-02 
2024-05-17 02:08:32,633 INFO: [train..][epoch: 50, iter:  22,400, lr:(1.000e-04,)] [eta: 2 days, 23:14:25, time (data): 1.100 (0.003)] l_pix: 3.0429e-02 
2024-05-17 02:12:25,208 INFO: [train..][epoch: 51, iter:  22,600, lr:(1.000e-04,)] [eta: 2 days, 23:11:52, time (data): 1.237 (0.140)] l_pix: 2.3262e-02 
2024-05-17 02:16:03,771 INFO: [train..][epoch: 51, iter:  22,800, lr:(1.000e-04,)] [eta: 2 days, 23:06:58, time (data): 1.097 (0.003)] l_pix: 2.6030e-02 
2024-05-17 02:19:44,551 INFO: [train..][epoch: 51, iter:  23,000, lr:(1.000e-04,)] [eta: 2 days, 23:02:27, time (data): 1.104 (0.004)] l_pix: 2.6201e-02 
2024-05-17 02:23:35,639 INFO: [train..][epoch: 52, iter:  23,200, lr:(1.000e-04,)] [eta: 2 days, 22:59:38, time (data): 1.096 (0.004)] l_pix: 2.3993e-02 
2024-05-17 02:27:16,278 INFO: [train..][epoch: 52, iter:  23,400, lr:(1.000e-04,)] [eta: 2 days, 22:55:07, time (data): 1.107 (0.003)] l_pix: 1.9446e-02 
2024-05-17 02:31:07,214 INFO: [train..][epoch: 53, iter:  23,600, lr:(1.000e-04,)] [eta: 2 days, 22:52:16, time (data): 1.091 (0.004)] l_pix: 2.9827e-02 
2024-05-17 02:34:47,526 INFO: [train..][epoch: 53, iter:  23,800, lr:(1.000e-04,)] [eta: 2 days, 22:47:42, time (data): 1.106 (0.003)] l_pix: 2.5829e-02 
2024-05-17 02:38:39,073 INFO: [train..][epoch: 54, iter:  24,000, lr:(1.000e-04,)] [eta: 2 days, 22:44:55, time (data): 1.236 (0.152)] l_pix: 2.6101e-02 
2024-05-17 02:42:18,912 INFO: [train..][epoch: 54, iter:  24,200, lr:(1.000e-04,)] [eta: 2 days, 22:40:18, time (data): 1.104 (0.003)] l_pix: 1.6789e-02 
2024-05-17 02:46:11,045 INFO: [train..][epoch: 55, iter:  24,400, lr:(1.000e-04,)] [eta: 2 days, 22:37:35, time (data): 1.246 (0.155)] l_pix: 1.6677e-02 
2024-05-17 02:49:50,254 INFO: [train..][epoch: 55, iter:  24,600, lr:(1.000e-04,)] [eta: 2 days, 22:32:53, time (data): 1.101 (0.003)] l_pix: 2.7841e-02 
2024-05-17 02:53:30,950 INFO: [train..][epoch: 55, iter:  24,800, lr:(1.000e-04,)] [eta: 2 days, 22:28:25, time (data): 1.101 (0.003)] l_pix: 1.4481e-02 
2024-05-17 02:57:21,501 INFO: [train..][epoch: 56, iter:  25,000, lr:(1.000e-04,)] [eta: 2 days, 22:25:27, time (data): 1.100 (0.004)] l_pix: 1.3001e-02 
2024-05-17 02:57:21,503 INFO: Saving models and training states.
2024-05-17 02:57:22,842 INFO: Validation Set5
	 # psnr: 32.7966	Best: 32.8536 @ 10000 iter

2024-05-17 03:01:03,678 INFO: [train..][epoch: 56, iter:  25,200, lr:(1.000e-04,)] [eta: 2 days, 22:21:13, time (data): 1.103 (0.004)] l_pix: 1.7228e-02 
2024-05-17 03:04:54,064 INFO: [train..][epoch: 57, iter:  25,400, lr:(1.000e-04,)] [eta: 2 days, 22:18:13, time (data): 1.093 (0.003)] l_pix: 2.8599e-02 
2024-05-17 03:08:34,907 INFO: [train..][epoch: 57, iter:  25,600, lr:(1.000e-04,)] [eta: 2 days, 22:13:48, time (data): 1.106 (0.003)] l_pix: 3.6594e-02 
2024-05-17 03:12:25,526 INFO: [train..][epoch: 58, iter:  25,800, lr:(1.000e-04,)] [eta: 2 days, 22:10:48, time (data): 1.087 (0.004)] l_pix: 2.0688e-02 
2024-05-17 03:16:06,158 INFO: [train..][epoch: 58, iter:  26,000, lr:(1.000e-04,)] [eta: 2 days, 22:06:22, time (data): 1.107 (0.004)] l_pix: 3.0246e-02 
2024-05-17 03:19:57,721 INFO: [train..][epoch: 59, iter:  26,200, lr:(1.000e-04,)] [eta: 2 days, 22:03:30, time (data): 1.260 (0.176)] l_pix: 2.6316e-02 
2024-05-17 03:23:37,359 INFO: [train..][epoch: 59, iter:  26,400, lr:(1.000e-04,)] [eta: 2 days, 21:58:56, time (data): 1.102 (0.003)] l_pix: 1.7417e-02 
2024-05-17 03:27:29,841 INFO: [train..][epoch: 60, iter:  26,600, lr:(1.000e-04,)] [eta: 2 days, 21:56:10, time (data): 1.274 (0.180)] l_pix: 1.9237e-02 
2024-05-17 03:31:09,622 INFO: [train..][epoch: 60, iter:  26,800, lr:(1.000e-04,)] [eta: 2 days, 21:51:38, time (data): 1.105 (0.004)] l_pix: 1.5752e-02 
2024-05-17 03:34:50,503 INFO: [train..][epoch: 60, iter:  27,000, lr:(1.000e-04,)] [eta: 2 days, 21:47:16, time (data): 1.098 (0.003)] l_pix: 2.1502e-02 
2024-05-17 03:38:40,825 INFO: [train..][epoch: 61, iter:  27,200, lr:(1.000e-04,)] [eta: 2 days, 21:44:11, time (data): 1.096 (0.003)] l_pix: 2.5309e-02 
2024-05-17 03:42:21,736 INFO: [train..][epoch: 61, iter:  27,400, lr:(1.000e-04,)] [eta: 2 days, 21:39:50, time (data): 1.105 (0.004)] l_pix: 3.1377e-02 
2024-05-17 03:46:12,642 INFO: [train..][epoch: 62, iter:  27,600, lr:(1.000e-04,)] [eta: 2 days, 21:36:49, time (data): 1.093 (0.004)] l_pix: 3.0327e-02 
2024-05-17 03:49:53,917 INFO: [train..][epoch: 62, iter:  27,800, lr:(1.000e-04,)] [eta: 2 days, 21:32:31, time (data): 1.107 (0.004)] l_pix: 2.1678e-02 
2024-05-17 03:53:47,364 INFO: [train..][epoch: 63, iter:  28,000, lr:(1.000e-04,)] [eta: 2 days, 21:29:50, time (data): 1.089 (0.005)] l_pix: 1.0925e-02 
2024-05-17 03:57:27,695 INFO: [train..][epoch: 63, iter:  28,200, lr:(1.000e-04,)] [eta: 2 days, 21:25:25, time (data): 1.107 (0.004)] l_pix: 3.0366e-02 
2024-05-17 04:01:19,879 INFO: [train..][epoch: 64, iter:  28,400, lr:(1.000e-04,)] [eta: 2 days, 21:22:33, time (data): 1.295 (0.206)] l_pix: 3.5482e-02 
2024-05-17 04:04:58,383 INFO: [train..][epoch: 64, iter:  28,600, lr:(1.000e-04,)] [eta: 2 days, 21:17:54, time (data): 1.099 (0.003)] l_pix: 2.2318e-02 
2024-05-17 04:08:51,225 INFO: [train..][epoch: 65, iter:  28,800, lr:(1.000e-04,)] [eta: 2 days, 21:15:06, time (data): 1.316 (0.218)] l_pix: 2.5278e-02 
2024-05-17 04:12:30,437 INFO: [train..][epoch: 65, iter:  29,000, lr:(1.000e-04,)] [eta: 2 days, 21:10:33, time (data): 1.101 (0.004)] l_pix: 2.4601e-02 
2024-05-17 04:16:11,842 INFO: [train..][epoch: 65, iter:  29,200, lr:(1.000e-04,)] [eta: 2 days, 21:06:18, time (data): 1.108 (0.004)] l_pix: 3.3291e-02 
2024-05-17 04:20:02,692 INFO: [train..][epoch: 66, iter:  29,400, lr:(1.000e-04,)] [eta: 2 days, 21:03:14, time (data): 1.098 (0.004)] l_pix: 2.7608e-02 
2024-05-17 04:23:43,786 INFO: [train..][epoch: 66, iter:  29,600, lr:(1.000e-04,)] [eta: 2 days, 20:58:57, time (data): 1.109 (0.004)] l_pix: 1.3924e-02 
2024-05-17 04:27:34,821 INFO: [train..][epoch: 67, iter:  29,800, lr:(1.000e-04,)] [eta: 2 days, 20:55:53, time (data): 1.092 (0.004)] l_pix: 4.8092e-02 
2024-05-17 04:31:15,372 INFO: [train..][epoch: 67, iter:  30,000, lr:(1.000e-04,)] [eta: 2 days, 20:51:32, time (data): 1.110 (0.004)] l_pix: 2.6171e-02 
2024-05-17 04:31:15,373 INFO: Saving models and training states.
2024-05-17 04:31:16,712 INFO: Validation Set5
	 # psnr: 32.8400	Best: 32.8536 @ 10000 iter

2024-05-17 04:35:08,292 INFO: [train..][epoch: 68, iter:  30,200, lr:(1.000e-04,)] [eta: 2 days, 20:48:42, time (data): 1.088 (0.004)] l_pix: 2.5127e-02 
2024-05-17 04:38:50,109 INFO: [train..][epoch: 68, iter:  30,400, lr:(1.000e-04,)] [eta: 2 days, 20:44:31, time (data): 1.113 (0.004)] l_pix: 2.6892e-02 
2024-05-17 04:42:42,919 INFO: [train..][epoch: 69, iter:  30,600, lr:(1.000e-04,)] [eta: 2 days, 20:41:39, time (data): 1.343 (0.254)] l_pix: 1.8044e-02 
2024-05-17 04:46:22,644 INFO: [train..][epoch: 69, iter:  30,800, lr:(1.000e-04,)] [eta: 2 days, 20:37:12, time (data): 1.107 (0.004)] l_pix: 3.1203e-02 
2024-05-17 04:50:03,899 INFO: [train..][epoch: 69, iter:  31,000, lr:(1.000e-04,)] [eta: 2 days, 20:32:58, time (data): 1.102 (0.004)] l_pix: 2.8022e-02 
2024-05-17 04:53:56,184 INFO: [train..][epoch: 70, iter:  31,200, lr:(1.000e-04,)] [eta: 2 days, 20:30:01, time (data): 1.137 (0.005)] l_pix: 3.0070e-02 
2024-05-17 04:57:37,210 INFO: [train..][epoch: 70, iter:  31,400, lr:(1.000e-04,)] [eta: 2 days, 20:25:45, time (data): 1.102 (0.003)] l_pix: 2.3195e-02 
2024-05-17 05:01:27,849 INFO: [train..][epoch: 71, iter:  31,600, lr:(1.000e-04,)] [eta: 2 days, 20:22:36, time (data): 1.096 (0.003)] l_pix: 1.7432e-02 
2024-05-17 05:05:08,592 INFO: [train..][epoch: 71, iter:  31,800, lr:(1.000e-04,)] [eta: 2 days, 20:18:18, time (data): 1.102 (0.003)] l_pix: 2.5780e-02 
2024-05-17 05:08:59,201 INFO: [train..][epoch: 72, iter:  32,000, lr:(1.000e-04,)] [eta: 2 days, 20:15:09, time (data): 1.090 (0.004)] l_pix: 2.3383e-02 
2024-05-17 05:12:40,145 INFO: [train..][epoch: 72, iter:  32,200, lr:(1.000e-04,)] [eta: 2 days, 20:10:53, time (data): 1.105 (0.003)] l_pix: 1.7056e-02 
2024-05-17 05:16:31,538 INFO: [train..][epoch: 73, iter:  32,400, lr:(1.000e-04,)] [eta: 2 days, 20:07:48, time (data): 1.086 (0.003)] l_pix: 2.5158e-02 
2024-05-17 05:20:12,274 INFO: [train..][epoch: 73, iter:  32,600, lr:(1.000e-04,)] [eta: 2 days, 20:03:31, time (data): 1.108 (0.004)] l_pix: 4.8299e-02 
2024-05-17 05:24:04,483 INFO: [train..][epoch: 74, iter:  32,800, lr:(1.000e-04,)] [eta: 2 days, 20:00:31, time (data): 1.418 (0.325)] l_pix: 2.9284e-02 
2024-05-17 05:27:44,280 INFO: [train..][epoch: 74, iter:  33,000, lr:(1.000e-04,)] [eta: 2 days, 19:56:08, time (data): 1.110 (0.004)] l_pix: 1.7879e-02 
2024-05-17 05:31:25,364 INFO: [train..][epoch: 74, iter:  33,200, lr:(1.000e-04,)] [eta: 2 days, 19:51:54, time (data): 1.103 (0.004)] l_pix: 3.3294e-02 
2024-05-17 05:35:15,878 INFO: [train..][epoch: 75, iter:  33,400, lr:(1.000e-04,)] [eta: 2 days, 19:48:42, time (data): 1.103 (0.003)] l_pix: 2.1058e-02 
2024-05-17 05:38:56,702 INFO: [train..][epoch: 75, iter:  33,600, lr:(1.000e-04,)] [eta: 2 days, 19:44:27, time (data): 1.101 (0.003)] l_pix: 3.0620e-02 
2024-05-17 05:42:47,347 INFO: [train..][epoch: 76, iter:  33,800, lr:(1.000e-04,)] [eta: 2 days, 19:41:16, time (data): 1.095 (0.003)] l_pix: 2.4280e-02 
2024-05-17 05:46:28,405 INFO: [train..][epoch: 76, iter:  34,000, lr:(1.000e-04,)] [eta: 2 days, 19:37:02, time (data): 1.103 (0.004)] l_pix: 1.5158e-02 
2024-05-17 05:50:19,392 INFO: [train..][epoch: 77, iter:  34,200, lr:(1.000e-04,)] [eta: 2 days, 19:33:52, time (data): 1.090 (0.004)] l_pix: 3.1364e-02 
2024-05-17 05:54:00,045 INFO: [train..][epoch: 77, iter:  34,400, lr:(1.000e-04,)] [eta: 2 days, 19:29:37, time (data): 1.104 (0.003)] l_pix: 2.9548e-02 
2024-05-17 05:57:51,343 INFO: [train..][epoch: 78, iter:  34,600, lr:(1.000e-04,)] [eta: 2 days, 19:26:28, time (data): 1.085 (0.003)] l_pix: 2.6649e-02 
2024-05-17 06:01:31,360 INFO: [train..][epoch: 78, iter:  34,800, lr:(1.000e-04,)] [eta: 2 days, 19:22:09, time (data): 1.104 (0.003)] l_pix: 2.3680e-02 
2024-05-17 06:05:23,300 INFO: [train..][epoch: 79, iter:  35,000, lr:(1.000e-04,)] [eta: 2 days, 19:19:04, time (data): 1.551 (0.458)] l_pix: 2.7284e-02 
2024-05-17 06:05:23,301 INFO: Saving models and training states.
2024-05-17 06:05:24,608 INFO: Validation Set5
	 # psnr: 32.8676	Best: 32.8676 @ 35000 iter

2024-05-17 06:09:03,815 INFO: [train..][epoch: 79, iter:  35,200, lr:(1.000e-04,)] [eta: 2 days, 19:14:49, time (data): 1.105 (0.002)] l_pix: 2.3059e-02 
2024-05-17 06:12:44,259 INFO: [train..][epoch: 79, iter:  35,400, lr:(1.000e-04,)] [eta: 2 days, 19:10:33, time (data): 1.105 (0.003)] l_pix: 1.5242e-02 
2024-05-17 06:16:35,472 INFO: [train..][epoch: 80, iter:  35,600, lr:(1.000e-04,)] [eta: 2 days, 19:07:23, time (data): 1.106 (0.002)] l_pix: 1.7725e-02 
2024-05-17 06:20:16,467 INFO: [train..][epoch: 80, iter:  35,800, lr:(1.000e-04,)] [eta: 2 days, 19:03:11, time (data): 1.100 (0.003)] l_pix: 2.8308e-02 
2024-05-17 06:24:07,711 INFO: [train..][epoch: 81, iter:  36,000, lr:(1.000e-04,)] [eta: 2 days, 19:00:01, time (data): 1.102 (0.004)] l_pix: 2.4207e-02 
2024-05-17 06:27:48,737 INFO: [train..][epoch: 81, iter:  36,200, lr:(1.000e-04,)] [eta: 2 days, 18:55:49, time (data): 1.099 (0.003)] l_pix: 3.3733e-02 
2024-05-17 06:31:39,705 INFO: [train..][epoch: 82, iter:  36,400, lr:(1.000e-04,)] [eta: 2 days, 18:52:36, time (data): 1.087 (0.003)] l_pix: 4.0590e-02 
2024-05-17 06:35:20,185 INFO: [train..][epoch: 82, iter:  36,600, lr:(1.000e-04,)] [eta: 2 days, 18:48:22, time (data): 1.103 (0.003)] l_pix: 2.4608e-02 
2024-05-17 06:39:11,794 INFO: [train..][epoch: 83, iter:  36,800, lr:(1.000e-04,)] [eta: 2 days, 18:45:13, time (data): 1.084 (0.002)] l_pix: 1.6527e-02 
2024-05-17 06:42:51,773 INFO: [train..][epoch: 83, iter:  37,000, lr:(1.000e-04,)] [eta: 2 days, 18:40:56, time (data): 1.106 (0.004)] l_pix: 1.9724e-02 
2024-05-17 06:46:32,762 INFO: [train..][epoch: 83, iter:  37,200, lr:(1.000e-04,)] [eta: 2 days, 18:36:45, time (data): 1.093 (0.003)] l_pix: 1.6134e-02 
2024-05-17 06:50:25,482 INFO: [train..][epoch: 84, iter:  37,400, lr:(1.000e-04,)] [eta: 2 days, 18:33:42, time (data): 1.105 (0.003)] l_pix: 3.5452e-02 
2024-05-17 06:54:06,428 INFO: [train..][epoch: 84, iter:  37,600, lr:(1.000e-04,)] [eta: 2 days, 18:29:31, time (data): 1.097 (0.003)] l_pix: 3.1375e-02 
2024-05-17 06:57:57,426 INFO: [train..][epoch: 85, iter:  37,800, lr:(1.000e-04,)] [eta: 2 days, 18:26:17, time (data): 1.108 (0.002)] l_pix: 3.1005e-02 
2024-05-17 07:01:38,385 INFO: [train..][epoch: 85, iter:  38,000, lr:(1.000e-04,)] [eta: 2 days, 18:22:06, time (data): 1.099 (0.003)] l_pix: 2.0447e-02 
2024-05-17 07:05:29,142 INFO: [train..][epoch: 86, iter:  38,200, lr:(1.000e-04,)] [eta: 2 days, 18:18:51, time (data): 1.096 (0.004)] l_pix: 2.1853e-02 
2024-05-17 07:09:08,796 INFO: [train..][epoch: 86, iter:  38,400, lr:(1.000e-04,)] [eta: 2 days, 18:14:34, time (data): 1.104 (0.005)] l_pix: 2.1853e-02 
2024-05-17 07:13:00,883 INFO: [train..][epoch: 87, iter:  38,600, lr:(1.000e-04,)] [eta: 2 days, 18:11:25, time (data): 1.088 (0.003)] l_pix: 1.7251e-02 
2024-05-17 07:16:40,366 INFO: [train..][epoch: 87, iter:  38,800, lr:(1.000e-04,)] [eta: 2 days, 18:07:07, time (data): 1.100 (0.004)] l_pix: 1.8424e-02 
2024-05-17 07:20:33,047 INFO: [train..][epoch: 88, iter:  39,000, lr:(1.000e-04,)] [eta: 2 days, 18:04:01, time (data): 1.100 (0.004)] l_pix: 2.1578e-02 
2024-05-17 07:24:12,522 INFO: [train..][epoch: 88, iter:  39,200, lr:(1.000e-04,)] [eta: 2 days, 17:59:43, time (data): 1.101 (0.003)] l_pix: 1.8275e-02 
2024-05-17 07:27:52,446 INFO: [train..][epoch: 88, iter:  39,400, lr:(1.000e-04,)] [eta: 2 days, 17:55:29, time (data): 1.115 (0.003)] l_pix: 1.9128e-02 
2024-05-17 07:31:43,780 INFO: [train..][epoch: 89, iter:  39,600, lr:(1.000e-04,)] [eta: 2 days, 17:52:15, time (data): 1.104 (0.002)] l_pix: 1.4035e-02 
2024-05-17 07:35:23,489 INFO: [train..][epoch: 89, iter:  39,800, lr:(1.000e-04,)] [eta: 2 days, 17:47:59, time (data): 1.088 (0.003)] l_pix: 2.4590e-02 
2024-05-17 07:39:16,220 INFO: [train..][epoch: 90, iter:  40,000, lr:(1.000e-04,)] [eta: 2 days, 17:44:52, time (data): 1.104 (0.002)] l_pix: 2.7276e-02 
2024-05-17 07:39:16,220 INFO: Saving models and training states.
2024-05-17 07:39:17,565 INFO: Validation Set5
	 # psnr: 32.8580	Best: 32.8676 @ 35000 iter

2024-05-17 07:42:57,909 INFO: [train..][epoch: 90, iter:  40,200, lr:(1.000e-04,)] [eta: 2 days, 17:40:47, time (data): 1.102 (0.003)] l_pix: 3.4005e-02 
2024-05-17 07:46:48,638 INFO: [train..][epoch: 91, iter:  40,400, lr:(1.000e-04,)] [eta: 2 days, 17:37:30, time (data): 1.154 (0.063)] l_pix: 3.2278e-02 
2024-05-17 07:50:29,222 INFO: [train..][epoch: 91, iter:  40,600, lr:(1.000e-04,)] [eta: 2 days, 17:33:19, time (data): 1.103 (0.003)] l_pix: 2.9855e-02 
2024-05-17 07:54:20,006 INFO: [train..][epoch: 92, iter:  40,800, lr:(1.000e-04,)] [eta: 2 days, 17:30:01, time (data): 1.155 (0.062)] l_pix: 2.7657e-02 
2024-05-17 07:58:03,739 INFO: [train..][epoch: 92, iter:  41,000, lr:(1.000e-04,)] [eta: 2 days, 17:26:07, time (data): 1.119 (0.003)] l_pix: 2.3887e-02 
2024-05-17 08:01:55,602 INFO: [train..][epoch: 93, iter:  41,200, lr:(1.000e-04,)] [eta: 2 days, 17:22:55, time (data): 1.160 (0.065)] l_pix: 1.8559e-02 
2024-05-17 08:05:33,527 INFO: [train..][epoch: 93, iter:  41,400, lr:(1.000e-04,)] [eta: 2 days, 17:18:31, time (data): 1.090 (0.003)] l_pix: 2.1711e-02 
2024-05-17 08:09:13,984 INFO: [train..][epoch: 93, iter:  41,600, lr:(1.000e-04,)] [eta: 2 days, 17:14:21, time (data): 1.102 (0.003)] l_pix: 1.9085e-02 
2024-05-17 08:13:07,698 INFO: [train..][epoch: 94, iter:  41,800, lr:(1.000e-04,)] [eta: 2 days, 17:11:17, time (data): 1.171 (0.065)] l_pix: 2.6603e-02 
2024-05-17 08:16:48,431 INFO: [train..][epoch: 94, iter:  42,000, lr:(1.000e-04,)] [eta: 2 days, 17:07:08, time (data): 1.104 (0.003)] l_pix: 2.7089e-02 
2024-05-17 08:20:40,602 INFO: [train..][epoch: 95, iter:  42,200, lr:(1.000e-04,)] [eta: 2 days, 17:03:56, time (data): 1.164 (0.066)] l_pix: 2.0327e-02 
2024-05-17 08:24:20,676 INFO: [train..][epoch: 95, iter:  42,400, lr:(1.000e-04,)] [eta: 2 days, 16:59:44, time (data): 1.101 (0.003)] l_pix: 1.7766e-02 
2024-05-17 08:28:12,328 INFO: [train..][epoch: 96, iter:  42,600, lr:(1.000e-04,)] [eta: 2 days, 16:56:29, time (data): 1.161 (0.068)] l_pix: 2.1658e-02 
2024-05-17 08:31:51,297 INFO: [train..][epoch: 96, iter:  42,800, lr:(1.000e-04,)] [eta: 2 days, 16:52:12, time (data): 1.095 (0.003)] l_pix: 2.0879e-02 
2024-05-17 08:35:43,480 INFO: [train..][epoch: 97, iter:  43,000, lr:(1.000e-04,)] [eta: 2 days, 16:49:00, time (data): 1.165 (0.067)] l_pix: 3.3170e-02 
2024-05-17 08:39:22,300 INFO: [train..][epoch: 97, iter:  43,200, lr:(1.000e-04,)] [eta: 2 days, 16:44:42, time (data): 1.095 (0.003)] l_pix: 2.7843e-02 
2024-05-17 08:43:02,710 INFO: [train..][epoch: 97, iter:  43,400, lr:(1.000e-04,)] [eta: 2 days, 16:40:33, time (data): 1.102 (0.003)] l_pix: 2.7027e-02 
2024-05-17 08:46:54,665 INFO: [train..][epoch: 98, iter:  43,600, lr:(1.000e-04,)] [eta: 2 days, 16:37:19, time (data): 1.099 (0.003)] l_pix: 1.7365e-02 
2024-05-17 08:50:34,374 INFO: [train..][epoch: 98, iter:  43,800, lr:(1.000e-04,)] [eta: 2 days, 16:33:06, time (data): 1.099 (0.003)] l_pix: 2.5767e-02 
2024-05-17 08:54:25,980 INFO: [train..][epoch: 99, iter:  44,000, lr:(1.000e-04,)] [eta: 2 days, 16:29:50, time (data): 1.164 (0.069)] l_pix: 2.8914e-02 
2024-05-17 08:58:05,770 INFO: [train..][epoch: 99, iter:  44,200, lr:(1.000e-04,)] [eta: 2 days, 16:25:38, time (data): 1.099 (0.003)] l_pix: 3.9909e-02 
2024-05-17 09:01:57,394 INFO: [train..][epoch:100, iter:  44,400, lr:(1.000e-04,)] [eta: 2 days, 16:22:22, time (data): 1.164 (0.071)] l_pix: 3.4324e-02 
2024-05-17 09:05:37,254 INFO: [train..][epoch:100, iter:  44,600, lr:(1.000e-04,)] [eta: 2 days, 16:18:11, time (data): 1.099 (0.003)] l_pix: 1.6766e-02 
2024-05-17 09:09:28,755 INFO: [train..][epoch:101, iter:  44,800, lr:(1.000e-04,)] [eta: 2 days, 16:14:53, time (data): 1.165 (0.072)] l_pix: 1.7274e-02 
2024-05-17 09:13:08,672 INFO: [train..][epoch:101, iter:  45,000, lr:(1.000e-04,)] [eta: 2 days, 16:10:43, time (data): 1.100 (0.003)] l_pix: 2.4933e-02 
2024-05-17 09:13:08,673 INFO: Saving models and training states.
2024-05-17 09:13:10,038 INFO: Validation Set5
	 # psnr: 32.8979	Best: 32.8979 @ 45000 iter

2024-05-17 09:17:01,353 INFO: [train..][epoch:102, iter:  45,200, lr:(1.000e-04,)] [eta: 2 days, 16:07:30, time (data): 1.165 (0.072)] l_pix: 2.6510e-02 
2024-05-17 09:20:40,959 INFO: [train..][epoch:102, iter:  45,400, lr:(1.000e-04,)] [eta: 2 days, 16:03:18, time (data): 1.100 (0.003)] l_pix: 2.9998e-02 
2024-05-17 09:24:21,052 INFO: [train..][epoch:102, iter:  45,600, lr:(1.000e-04,)] [eta: 2 days, 15:59:09, time (data): 1.100 (0.003)] l_pix: 2.5605e-02 
2024-05-17 09:28:12,202 INFO: [train..][epoch:103, iter:  45,800, lr:(1.000e-04,)] [eta: 2 days, 15:55:49, time (data): 1.165 (0.072)] l_pix: 2.6556e-02 
2024-05-17 09:31:52,295 INFO: [train..][epoch:103, iter:  46,000, lr:(1.000e-04,)] [eta: 2 days, 15:51:40, time (data): 1.101 (0.003)] l_pix: 3.8636e-02 
2024-05-17 09:35:43,331 INFO: [train..][epoch:104, iter:  46,200, lr:(1.000e-04,)] [eta: 2 days, 15:48:20, time (data): 1.165 (0.073)] l_pix: 1.3265e-02 
2024-05-17 09:39:23,441 INFO: [train..][epoch:104, iter:  46,400, lr:(1.000e-04,)] [eta: 2 days, 15:44:11, time (data): 1.101 (0.003)] l_pix: 1.8971e-02 
2024-05-17 09:43:13,931 INFO: [train..][epoch:105, iter:  46,600, lr:(1.000e-04,)] [eta: 2 days, 15:40:48, time (data): 1.162 (0.075)] l_pix: 2.1385e-02 
2024-05-17 09:46:53,922 INFO: [train..][epoch:105, iter:  46,800, lr:(1.000e-04,)] [eta: 2 days, 15:36:39, time (data): 1.102 (0.003)] l_pix: 1.7810e-02 
2024-05-17 09:50:46,155 INFO: [train..][epoch:106, iter:  47,000, lr:(1.000e-04,)] [eta: 2 days, 15:33:23, time (data): 1.172 (0.075)] l_pix: 1.7809e-02 
2024-05-17 09:54:26,723 INFO: [train..][epoch:106, iter:  47,200, lr:(1.000e-04,)] [eta: 2 days, 15:29:17, time (data): 1.102 (0.003)] l_pix: 2.6028e-02 
2024-05-17 09:58:07,588 INFO: [train..][epoch:106, iter:  47,400, lr:(1.000e-04,)] [eta: 2 days, 15:25:12, time (data): 1.104 (0.003)] l_pix: 1.6812e-02 
2024-05-17 10:01:57,924 INFO: [train..][epoch:107, iter:  47,600, lr:(1.000e-04,)] [eta: 2 days, 15:21:48, time (data): 1.092 (0.003)] l_pix: 1.8638e-02 
2024-05-17 10:05:38,576 INFO: [train..][epoch:107, iter:  47,800, lr:(1.000e-04,)] [eta: 2 days, 15:17:42, time (data): 1.104 (0.003)] l_pix: 1.9242e-02 
2024-05-17 10:09:29,179 INFO: [train..][epoch:108, iter:  48,000, lr:(1.000e-04,)] [eta: 2 days, 15:14:19, time (data): 1.166 (0.077)] l_pix: 1.9204e-02 
2024-05-17 10:13:08,604 INFO: [train..][epoch:108, iter:  48,200, lr:(1.000e-04,)] [eta: 2 days, 15:10:08, time (data): 1.098 (0.003)] l_pix: 2.8989e-02 
2024-05-17 10:17:00,048 INFO: [train..][epoch:109, iter:  48,400, lr:(1.000e-04,)] [eta: 2 days, 15:06:48, time (data): 1.170 (0.078)] l_pix: 9.8001e-03 
2024-05-17 10:20:39,924 INFO: [train..][epoch:109, iter:  48,600, lr:(1.000e-04,)] [eta: 2 days, 15:02:40, time (data): 1.099 (0.003)] l_pix: 2.5700e-02 
2024-05-17 10:24:31,119 INFO: [train..][epoch:110, iter:  48,800, lr:(1.000e-04,)] [eta: 2 days, 14:59:18, time (data): 1.172 (0.079)] l_pix: 1.6738e-02 
2024-05-17 10:28:11,036 INFO: [train..][epoch:110, iter:  49,000, lr:(1.000e-04,)] [eta: 2 days, 14:55:11, time (data): 1.100 (0.003)] l_pix: 1.4339e-02 
2024-05-17 10:32:02,082 INFO: [train..][epoch:111, iter:  49,200, lr:(1.000e-04,)] [eta: 2 days, 14:51:48, time (data): 1.171 (0.080)] l_pix: 1.9291e-02 
2024-05-17 10:35:41,747 INFO: [train..][epoch:111, iter:  49,400, lr:(1.000e-04,)] [eta: 2 days, 14:47:40, time (data): 1.101 (0.003)] l_pix: 1.4829e-02 
2024-05-17 10:39:21,603 INFO: [train..][epoch:111, iter:  49,600, lr:(1.000e-04,)] [eta: 2 days, 14:43:32, time (data): 1.098 (0.003)] l_pix: 1.9791e-02 
2024-05-17 10:43:12,837 INFO: [train..][epoch:112, iter:  49,800, lr:(1.000e-04,)] [eta: 2 days, 14:40:10, time (data): 1.098 (0.003)] l_pix: 2.6753e-02 
2024-05-17 10:46:53,795 INFO: [train..][epoch:112, iter:  50,000, lr:(1.000e-04,)] [eta: 2 days, 14:36:07, time (data): 1.105 (0.003)] l_pix: 1.5265e-02 
2024-05-17 10:46:53,795 INFO: Saving models and training states.
2024-05-17 10:46:55,264 INFO: Validation Set5
	 # psnr: 32.8653	Best: 32.8979 @ 45000 iter

2024-05-17 10:50:45,348 INFO: [train..][epoch:113, iter:  50,200, lr:(1.000e-04,)] [eta: 2 days, 14:32:46, time (data): 1.168 (0.082)] l_pix: 3.4291e-02 
2024-05-17 10:54:25,959 INFO: [train..][epoch:113, iter:  50,400, lr:(1.000e-04,)] [eta: 2 days, 14:28:42, time (data): 1.105 (0.003)] l_pix: 2.1822e-02 
2024-05-17 10:58:17,741 INFO: [train..][epoch:114, iter:  50,600, lr:(1.000e-04,)] [eta: 2 days, 14:25:22, time (data): 1.178 (0.085)] l_pix: 2.9266e-02 
2024-05-17 11:01:56,905 INFO: [train..][epoch:114, iter:  50,800, lr:(1.000e-04,)] [eta: 2 days, 14:21:12, time (data): 1.097 (0.003)] l_pix: 4.0283e-02 
2024-05-17 11:05:48,584 INFO: [train..][epoch:115, iter:  51,000, lr:(1.000e-04,)] [eta: 2 days, 14:17:51, time (data): 1.179 (0.084)] l_pix: 2.6621e-02 
2024-05-17 11:09:27,466 INFO: [train..][epoch:115, iter:  51,200, lr:(1.000e-04,)] [eta: 2 days, 14:13:40, time (data): 1.096 (0.003)] l_pix: 1.8838e-02 
2024-05-17 11:13:18,572 INFO: [train..][epoch:116, iter:  51,400, lr:(1.000e-04,)] [eta: 2 days, 14:10:17, time (data): 1.179 (0.086)] l_pix: 3.1092e-02 
2024-05-17 11:16:58,072 INFO: [train..][epoch:116, iter:  51,600, lr:(1.000e-04,)] [eta: 2 days, 14:06:09, time (data): 1.101 (0.003)] l_pix: 2.0091e-02 
2024-05-17 11:20:37,469 INFO: [train..][epoch:116, iter:  51,800, lr:(1.000e-04,)] [eta: 2 days, 14:02:01, time (data): 1.096 (0.003)] l_pix: 3.6520e-02 
2024-05-17 11:24:28,994 INFO: [train..][epoch:117, iter:  52,000, lr:(1.000e-04,)] [eta: 2 days, 13:58:39, time (data): 1.100 (0.003)] l_pix: 2.0307e-02 
2024-05-17 11:28:09,508 INFO: [train..][epoch:117, iter:  52,200, lr:(1.000e-04,)] [eta: 2 days, 13:54:35, time (data): 1.103 (0.003)] l_pix: 1.7566e-02 
2024-05-17 11:32:00,068 INFO: [train..][epoch:118, iter:  52,400, lr:(1.000e-04,)] [eta: 2 days, 13:51:10, time (data): 1.177 (0.089)] l_pix: 4.2939e-02 
2024-05-17 11:35:40,599 INFO: [train..][epoch:118, iter:  52,600, lr:(1.000e-04,)] [eta: 2 days, 13:47:06, time (data): 1.106 (0.003)] l_pix: 2.3813e-02 
2024-05-17 11:39:31,803 INFO: [train..][epoch:119, iter:  52,800, lr:(1.000e-04,)] [eta: 2 days, 13:43:42, time (data): 1.180 (0.090)] l_pix: 2.9982e-02 
2024-05-17 11:43:11,919 INFO: [train..][epoch:119, iter:  53,000, lr:(1.000e-04,)] [eta: 2 days, 13:39:38, time (data): 1.104 (0.003)] l_pix: 1.4359e-02 
2024-05-17 11:47:04,421 INFO: [train..][epoch:120, iter:  53,200, lr:(1.000e-04,)] [eta: 2 days, 13:36:19, time (data): 1.190 (0.092)] l_pix: 2.7739e-02 
2024-05-17 11:50:45,036 INFO: [train..][epoch:120, iter:  53,400, lr:(1.000e-04,)] [eta: 2 days, 13:32:16, time (data): 1.108 (0.003)] l_pix: 2.8074e-02 
2024-05-17 11:54:24,158 INFO: [train..][epoch:120, iter:  53,600, lr:(1.000e-04,)] [eta: 2 days, 13:28:07, time (data): 1.095 (0.003)] l_pix: 2.9355e-02 
2024-05-17 11:58:15,254 INFO: [train..][epoch:121, iter:  53,800, lr:(1.000e-04,)] [eta: 2 days, 13:24:43, time (data): 1.099 (0.003)] l_pix: 1.7019e-02 
2024-05-17 12:01:55,012 INFO: [train..][epoch:121, iter:  54,000, lr:(1.000e-04,)] [eta: 2 days, 13:20:37, time (data): 1.098 (0.003)] l_pix: 2.4579e-02 
2024-05-17 12:05:46,014 INFO: [train..][epoch:122, iter:  54,200, lr:(1.000e-04,)] [eta: 2 days, 13:17:12, time (data): 1.096 (0.003)] l_pix: 2.5952e-02 
2024-05-17 12:09:26,493 INFO: [train..][epoch:122, iter:  54,400, lr:(1.000e-04,)] [eta: 2 days, 13:13:09, time (data): 1.101 (0.003)] l_pix: 2.4378e-02 
2024-05-17 12:13:16,624 INFO: [train..][epoch:123, iter:  54,600, lr:(1.000e-04,)] [eta: 2 days, 13:09:41, time (data): 1.181 (0.096)] l_pix: 3.3912e-02 
2024-05-17 12:16:56,848 INFO: [train..][epoch:123, iter:  54,800, lr:(1.000e-04,)] [eta: 2 days, 13:05:37, time (data): 1.105 (0.003)] l_pix: 1.4741e-02 
2024-05-17 12:20:48,268 INFO: [train..][epoch:124, iter:  55,000, lr:(1.000e-04,)] [eta: 2 days, 13:02:14, time (data): 1.187 (0.097)] l_pix: 3.3867e-02 
2024-05-17 12:20:48,268 INFO: Saving models and training states.
2024-05-17 12:20:49,700 INFO: Validation Set5
	 # psnr: 32.8862	Best: 32.8979 @ 45000 iter

2024-05-17 12:24:27,925 INFO: [train..][epoch:124, iter:  55,200, lr:(1.000e-04,)] [eta: 2 days, 12:58:08, time (data): 1.094 (0.003)] l_pix: 1.5531e-02 
2024-05-17 12:28:20,382 INFO: [train..][epoch:125, iter:  55,400, lr:(1.000e-04,)] [eta: 2 days, 12:54:48, time (data): 1.201 (0.100)] l_pix: 2.1101e-02 
2024-05-17 12:31:59,066 INFO: [train..][epoch:125, iter:  55,600, lr:(1.000e-04,)] [eta: 2 days, 12:50:39, time (data): 1.096 (0.003)] l_pix: 1.9016e-02 
2024-05-17 12:35:38,255 INFO: [train..][epoch:125, iter:  55,800, lr:(1.000e-04,)] [eta: 2 days, 12:46:32, time (data): 1.096 (0.003)] l_pix: 2.0640e-02 
2024-05-17 12:39:31,266 INFO: [train..][epoch:126, iter:  56,000, lr:(1.000e-04,)] [eta: 2 days, 12:43:13, time (data): 1.113 (0.003)] l_pix: 2.0862e-02 
2024-05-17 12:43:10,795 INFO: [train..][epoch:126, iter:  56,200, lr:(1.000e-04,)] [eta: 2 days, 12:39:08, time (data): 1.097 (0.003)] l_pix: 2.2741e-02 
2024-05-17 12:47:01,819 INFO: [train..][epoch:127, iter:  56,400, lr:(1.000e-04,)] [eta: 2 days, 12:35:42, time (data): 1.094 (0.003)] l_pix: 2.8378e-02 
2024-05-17 12:50:41,652 INFO: [train..][epoch:127, iter:  56,600, lr:(1.000e-04,)] [eta: 2 days, 12:31:38, time (data): 1.099 (0.003)] l_pix: 2.1807e-02 
2024-05-17 12:54:33,018 INFO: [train..][epoch:128, iter:  56,800, lr:(1.000e-04,)] [eta: 2 days, 12:28:13, time (data): 1.201 (0.107)] l_pix: 1.2419e-02 
2024-05-17 12:58:13,221 INFO: [train..][epoch:128, iter:  57,000, lr:(1.000e-04,)] [eta: 2 days, 12:24:10, time (data): 1.101 (0.003)] l_pix: 2.5300e-02 
2024-05-17 13:02:04,063 INFO: [train..][epoch:129, iter:  57,200, lr:(1.000e-04,)] [eta: 2 days, 12:20:44, time (data): 1.194 (0.105)] l_pix: 2.1319e-02 
2024-05-17 13:05:43,546 INFO: [train..][epoch:129, iter:  57,400, lr:(1.000e-04,)] [eta: 2 days, 12:16:39, time (data): 1.102 (0.003)] l_pix: 2.3254e-02 
2024-05-17 13:09:35,687 INFO: [train..][epoch:130, iter:  57,600, lr:(1.000e-04,)] [eta: 2 days, 12:13:16, time (data): 1.203 (0.108)] l_pix: 2.7100e-02 
2024-05-17 13:13:14,077 INFO: [train..][epoch:130, iter:  57,800, lr:(1.000e-04,)] [eta: 2 days, 12:09:07, time (data): 1.095 (0.003)] l_pix: 3.0785e-02 
2024-05-17 13:16:54,527 INFO: [train..][epoch:130, iter:  58,000, lr:(1.000e-04,)] [eta: 2 days, 12:05:06, time (data): 1.103 (0.003)] l_pix: 2.0185e-02 
2024-05-17 13:20:45,100 INFO: [train..][epoch:131, iter:  58,200, lr:(1.000e-04,)] [eta: 2 days, 12:01:38, time (data): 1.094 (0.003)] l_pix: 2.4845e-02 
2024-05-17 13:24:25,621 INFO: [train..][epoch:131, iter:  58,400, lr:(1.000e-04,)] [eta: 2 days, 11:57:37, time (data): 1.105 (0.003)] l_pix: 2.9312e-02 
2024-05-17 13:28:16,685 INFO: [train..][epoch:132, iter:  58,600, lr:(1.000e-04,)] [eta: 2 days, 11:54:10, time (data): 1.090 (0.003)] l_pix: 3.0943e-02 
2024-05-17 13:31:56,483 INFO: [train..][epoch:132, iter:  58,800, lr:(1.000e-04,)] [eta: 2 days, 11:50:07, time (data): 1.099 (0.003)] l_pix: 3.4327e-02 
2024-05-17 13:35:47,807 INFO: [train..][epoch:133, iter:  59,000, lr:(1.000e-04,)] [eta: 2 days, 11:46:41, time (data): 1.204 (0.117)] l_pix: 1.7004e-02 
2024-05-17 13:39:27,879 INFO: [train..][epoch:133, iter:  59,200, lr:(1.000e-04,)] [eta: 2 days, 11:42:39, time (data): 1.097 (0.003)] l_pix: 2.0745e-02 
2024-05-17 13:43:19,188 INFO: [train..][epoch:134, iter:  59,400, lr:(1.000e-04,)] [eta: 2 days, 11:39:12, time (data): 1.209 (0.116)] l_pix: 1.7217e-02 
2024-05-17 13:46:59,663 INFO: [train..][epoch:134, iter:  59,600, lr:(1.000e-04,)] [eta: 2 days, 11:35:12, time (data): 1.106 (0.004)] l_pix: 2.1581e-02 
2024-05-17 13:50:40,484 INFO: [train..][epoch:134, iter:  59,800, lr:(1.000e-04,)] [eta: 2 days, 11:31:12, time (data): 1.101 (0.003)] l_pix: 2.9123e-02 
2024-05-17 13:54:31,819 INFO: [train..][epoch:135, iter:  60,000, lr:(1.000e-04,)] [eta: 2 days, 11:27:46, time (data): 1.103 (0.004)] l_pix: 2.8398e-02 
2024-05-17 13:54:31,820 INFO: Saving models and training states.
2024-05-17 13:54:33,225 INFO: Validation Set5
	 # psnr: 32.8612	Best: 32.8979 @ 45000 iter

2024-05-17 13:58:12,724 INFO: [train..][epoch:135, iter:  60,200, lr:(1.000e-04,)] [eta: 2 days, 11:23:46, time (data): 1.097 (0.003)] l_pix: 1.8040e-02 
2024-05-17 14:02:03,650 INFO: [train..][epoch:136, iter:  60,400, lr:(1.000e-04,)] [eta: 2 days, 11:20:19, time (data): 1.098 (0.004)] l_pix: 1.5941e-02 
2024-05-17 14:05:43,931 INFO: [train..][epoch:136, iter:  60,600, lr:(1.000e-04,)] [eta: 2 days, 11:16:17, time (data): 1.100 (0.003)] l_pix: 1.3655e-02 
2024-05-17 14:09:34,756 INFO: [train..][epoch:137, iter:  60,800, lr:(1.000e-04,)] [eta: 2 days, 11:12:49, time (data): 1.088 (0.004)] l_pix: 1.9476e-02 
2024-05-17 14:13:14,457 INFO: [train..][epoch:137, iter:  61,000, lr:(1.000e-04,)] [eta: 2 days, 11:08:46, time (data): 1.101 (0.004)] l_pix: 2.2505e-02 
2024-05-17 14:17:05,543 INFO: [train..][epoch:138, iter:  61,200, lr:(1.000e-04,)] [eta: 2 days, 11:05:19, time (data): 1.214 (0.128)] l_pix: 2.0229e-02 
2024-05-17 14:20:44,927 INFO: [train..][epoch:138, iter:  61,400, lr:(1.000e-04,)] [eta: 2 days, 11:01:15, time (data): 1.103 (0.003)] l_pix: 2.2128e-02 
2024-05-17 14:24:37,178 INFO: [train..][epoch:139, iter:  61,600, lr:(1.000e-04,)] [eta: 2 days, 10:57:51, time (data): 1.224 (0.130)] l_pix: 9.8811e-03 
2024-05-17 14:28:15,586 INFO: [train..][epoch:139, iter:  61,800, lr:(1.000e-04,)] [eta: 2 days, 10:53:45, time (data): 1.095 (0.003)] l_pix: 2.6342e-02 
2024-05-17 14:31:55,939 INFO: [train..][epoch:139, iter:  62,000, lr:(1.000e-04,)] [eta: 2 days, 10:49:44, time (data): 1.105 (0.003)] l_pix: 1.5173e-02 
2024-05-17 14:35:46,702 INFO: [train..][epoch:140, iter:  62,200, lr:(1.000e-04,)] [eta: 2 days, 10:46:15, time (data): 1.098 (0.003)] l_pix: 2.1462e-02 
2024-05-17 14:39:25,644 INFO: [train..][epoch:140, iter:  62,400, lr:(1.000e-04,)] [eta: 2 days, 10:42:11, time (data): 1.093 (0.003)] l_pix: 2.4416e-02 
2024-05-17 14:43:16,316 INFO: [train..][epoch:141, iter:  62,600, lr:(1.000e-04,)] [eta: 2 days, 10:38:42, time (data): 1.096 (0.004)] l_pix: 1.6052e-02 
2024-05-17 14:46:56,207 INFO: [train..][epoch:141, iter:  62,800, lr:(1.000e-04,)] [eta: 2 days, 10:34:40, time (data): 1.098 (0.003)] l_pix: 2.4150e-02 
2024-05-17 14:50:47,163 INFO: [train..][epoch:142, iter:  63,000, lr:(1.000e-04,)] [eta: 2 days, 10:31:12, time (data): 1.092 (0.003)] l_pix: 2.7701e-02 
2024-05-17 14:54:28,079 INFO: [train..][epoch:142, iter:  63,200, lr:(1.000e-04,)] [eta: 2 days, 10:27:13, time (data): 1.101 (0.003)] l_pix: 1.3842e-02 
2024-05-17 14:58:19,002 INFO: [train..][epoch:143, iter:  63,400, lr:(1.000e-04,)] [eta: 2 days, 10:23:45, time (data): 1.230 (0.146)] l_pix: 2.3684e-02 
2024-05-17 15:01:58,624 INFO: [train..][epoch:143, iter:  63,600, lr:(1.000e-04,)] [eta: 2 days, 10:19:43, time (data): 1.103 (0.003)] l_pix: 2.8815e-02 
2024-05-17 15:05:51,071 INFO: [train..][epoch:144, iter:  63,800, lr:(1.000e-04,)] [eta: 2 days, 10:16:18, time (data): 1.247 (0.153)] l_pix: 2.9924e-02 
2024-05-17 15:09:31,281 INFO: [train..][epoch:144, iter:  64,000, lr:(1.000e-04,)] [eta: 2 days, 10:12:18, time (data): 1.109 (0.003)] l_pix: 2.4173e-02 
2024-05-17 15:13:14,402 INFO: [train..][epoch:144, iter:  64,200, lr:(1.000e-04,)] [eta: 2 days, 10:08:26, time (data): 1.110 (0.003)] l_pix: 2.1885e-02 
2024-05-17 15:17:26,228 INFO: [train..][epoch:145, iter:  64,400, lr:(1.000e-04,)] [eta: 2 days, 10:05:57, time (data): 1.096 (0.003)] l_pix: 3.4136e-02 
2024-05-17 15:21:07,923 INFO: [train..][epoch:145, iter:  64,600, lr:(1.000e-04,)] [eta: 2 days, 10:02:01, time (data): 1.107 (0.003)] l_pix: 3.2694e-02 
2024-05-17 15:25:11,703 INFO: [train..][epoch:146, iter:  64,800, lr:(1.000e-04,)] [eta: 2 days, 9:59:09, time (data): 1.096 (0.003)] l_pix: 1.4220e-02 
2024-05-17 15:28:53,093 INFO: [train..][epoch:146, iter:  65,000, lr:(1.000e-04,)] [eta: 2 days, 9:55:12, time (data): 1.110 (0.003)] l_pix: 1.5882e-02 
2024-05-17 15:28:53,133 INFO: Saving models and training states.
2024-05-17 15:28:57,226 INFO: Validation Set5
	 # psnr: 32.8785	Best: 32.8979 @ 45000 iter

2024-05-17 15:33:31,468 INFO: [train..][epoch:147, iter:  65,200, lr:(1.000e-04,)] [eta: 2 days, 9:53:56, time (data): 1.098 (0.003)] l_pix: 2.5631e-02 
2024-05-17 15:37:11,172 INFO: [train..][epoch:147, iter:  65,400, lr:(1.000e-04,)] [eta: 2 days, 9:49:54, time (data): 1.105 (0.003)] l_pix: 2.1376e-02 
2024-05-17 15:41:11,318 INFO: [train..][epoch:148, iter:  65,600, lr:(1.000e-04,)] [eta: 2 days, 9:46:50, time (data): 1.364 (0.269)] l_pix: 2.4163e-02 
2024-05-17 15:47:02,058 INFO: [train..][epoch:148, iter:  65,800, lr:(1.000e-04,)] [eta: 2 days, 9:48:54, time (data): 2.139 (0.003)] l_pix: 2.7602e-02 
2024-05-17 15:53:46,618 INFO: [train..][epoch:148, iter:  66,000, lr:(1.000e-04,)] [eta: 2 days, 9:53:26, time (data): 2.196 (0.003)] l_pix: 2.5139e-02 
2024-05-17 16:01:26,868 INFO: [train..][epoch:149, iter:  66,200, lr:(1.000e-04,)] [eta: 2 days, 10:00:29, time (data): 2.195 (0.003)] l_pix: 5.5590e-02 
2024-05-17 16:08:46,633 INFO: [train..][epoch:149, iter:  66,400, lr:(1.000e-04,)] [eta: 2 days, 10:06:29, time (data): 2.184 (0.003)] l_pix: 1.5927e-02 
2024-05-17 16:15:18,744 INFO: [train..][epoch:150, iter:  66,600, lr:(1.000e-04,)] [eta: 2 days, 10:10:13, time (data): 2.031 (0.003)] l_pix: 2.6606e-02 
2024-05-17 16:22:02,769 INFO: [train..][epoch:150, iter:  66,800, lr:(1.000e-04,)] [eta: 2 days, 10:14:27, time (data): 1.976 (0.003)] l_pix: 2.9369e-02 
2024-05-17 16:28:15,418 INFO: [train..][epoch:151, iter:  67,000, lr:(1.000e-04,)] [eta: 2 days, 10:17:10, time (data): 1.823 (0.004)] l_pix: 3.7232e-02 
2024-05-17 16:33:50,080 INFO: [train..][epoch:151, iter:  67,200, lr:(1.000e-04,)] [eta: 2 days, 10:18:08, time (data): 1.515 (0.004)] l_pix: 2.2415e-02 
2024-05-17 16:39:14,798 INFO: [train..][epoch:152, iter:  67,400, lr:(1.000e-04,)] [eta: 2 days, 10:18:36, time (data): 1.623 (0.273)] l_pix: 2.5919e-02 
2024-05-17 16:43:35,921 INFO: [train..][epoch:152, iter:  67,600, lr:(1.000e-04,)] [eta: 2 days, 10:16:10, time (data): 1.104 (0.003)] l_pix: 2.0308e-02 
2024-05-17 16:47:28,877 INFO: [train..][epoch:153, iter:  67,800, lr:(1.000e-04,)] [eta: 2 days, 10:12:28, time (data): 1.292 (0.196)] l_pix: 2.0977e-02 
2024-05-17 16:51:09,104 INFO: [train..][epoch:153, iter:  68,000, lr:(1.000e-04,)] [eta: 2 days, 10:08:11, time (data): 1.094 (0.002)] l_pix: 2.2098e-02 
2024-05-17 16:54:49,151 INFO: [train..][epoch:153, iter:  68,200, lr:(1.000e-04,)] [eta: 2 days, 10:03:55, time (data): 1.104 (0.003)] l_pix: 1.8774e-02 
2024-05-17 16:58:40,417 INFO: [train..][epoch:154, iter:  68,400, lr:(1.000e-04,)] [eta: 2 days, 10:00:08, time (data): 1.103 (0.003)] l_pix: 3.2950e-02 
2024-05-17 17:02:19,545 INFO: [train..][epoch:154, iter:  68,600, lr:(1.000e-04,)] [eta: 2 days, 9:55:50, time (data): 1.093 (0.003)] l_pix: 2.9849e-02 
2024-05-17 17:06:10,334 INFO: [train..][epoch:155, iter:  68,800, lr:(1.000e-04,)] [eta: 2 days, 9:52:02, time (data): 1.098 (0.003)] l_pix: 1.6742e-02 
2024-05-17 17:09:50,653 INFO: [train..][epoch:155, iter:  69,000, lr:(1.000e-04,)] [eta: 2 days, 9:47:47, time (data): 1.100 (0.003)] l_pix: 1.7338e-02 
2024-05-17 17:13:42,823 INFO: [train..][epoch:156, iter:  69,200, lr:(1.000e-04,)] [eta: 2 days, 9:44:03, time (data): 1.106 (0.004)] l_pix: 2.4017e-02 
2024-05-17 17:17:22,903 INFO: [train..][epoch:156, iter:  69,400, lr:(1.000e-04,)] [eta: 2 days, 9:39:47, time (data): 1.102 (0.003)] l_pix: 2.7740e-02 
2024-05-17 17:21:14,272 INFO: [train..][epoch:157, iter:  69,600, lr:(1.000e-04,)] [eta: 2 days, 9:36:01, time (data): 1.310 (0.223)] l_pix: 2.2445e-02 
2024-05-17 17:24:53,671 INFO: [train..][epoch:157, iter:  69,800, lr:(1.000e-04,)] [eta: 2 days, 9:31:44, time (data): 1.103 (0.003)] l_pix: 2.2297e-02 
2024-05-17 17:28:46,085 INFO: [train..][epoch:158, iter:  70,000, lr:(1.000e-04,)] [eta: 2 days, 9:28:01, time (data): 1.332 (0.236)] l_pix: 1.4663e-02 
2024-05-17 17:28:46,085 INFO: Saving models and training states.
2024-05-17 17:28:48,389 INFO: Validation Set5
	 # psnr: 32.8819	Best: 32.8979 @ 45000 iter

2024-05-17 17:32:27,396 INFO: [train..][epoch:158, iter:  70,200, lr:(1.000e-04,)] [eta: 2 days, 9:23:49, time (data): 1.100 (0.003)] l_pix: 2.6263e-02 
2024-05-17 17:36:08,167 INFO: [train..][epoch:158, iter:  70,400, lr:(1.000e-04,)] [eta: 2 days, 9:19:36, time (data): 1.104 (0.003)] l_pix: 1.5632e-02 
2024-05-17 17:39:58,977 INFO: [train..][epoch:159, iter:  70,600, lr:(1.000e-04,)] [eta: 2 days, 9:15:49, time (data): 1.100 (0.003)] l_pix: 2.2776e-02 
2024-05-17 17:43:39,144 INFO: [train..][epoch:159, iter:  70,800, lr:(1.000e-04,)] [eta: 2 days, 9:11:35, time (data): 1.104 (0.003)] l_pix: 1.9451e-02 
2024-05-17 17:47:30,057 INFO: [train..][epoch:160, iter:  71,000, lr:(1.000e-04,)] [eta: 2 days, 9:07:48, time (data): 1.091 (0.003)] l_pix: 3.3256e-02 
2024-05-17 17:51:09,218 INFO: [train..][epoch:160, iter:  71,200, lr:(1.000e-04,)] [eta: 2 days, 9:03:31, time (data): 1.096 (0.003)] l_pix: 1.8588e-02 
2024-05-17 17:55:00,493 INFO: [train..][epoch:161, iter:  71,400, lr:(1.000e-04,)] [eta: 2 days, 8:59:45, time (data): 1.090 (0.003)] l_pix: 2.7771e-02 
2024-05-17 17:58:40,578 INFO: [train..][epoch:161, iter:  71,600, lr:(1.000e-04,)] [eta: 2 days, 8:55:31, time (data): 1.099 (0.003)] l_pix: 1.3801e-02 
2024-05-17 18:02:32,281 INFO: [train..][epoch:162, iter:  71,800, lr:(1.000e-04,)] [eta: 2 days, 8:51:47, time (data): 1.381 (0.292)] l_pix: 3.7096e-02 
2024-05-17 18:06:12,007 INFO: [train..][epoch:162, iter:  72,000, lr:(1.000e-04,)] [eta: 2 days, 8:47:32, time (data): 1.105 (0.003)] l_pix: 2.9910e-02 
2024-05-17 18:09:52,288 INFO: [train..][epoch:162, iter:  72,200, lr:(1.000e-04,)] [eta: 2 days, 8:43:19, time (data): 1.099 (0.003)] l_pix: 2.7616e-02 
2024-05-17 18:13:45,068 INFO: [train..][epoch:163, iter:  72,400, lr:(1.000e-04,)] [eta: 2 days, 8:39:37, time (data): 1.100 (0.003)] l_pix: 2.4176e-02 
2024-05-17 18:17:26,009 INFO: [train..][epoch:163, iter:  72,600, lr:(1.000e-04,)] [eta: 2 days, 8:35:26, time (data): 1.101 (0.003)] l_pix: 3.4543e-02 
2024-05-17 18:21:17,161 INFO: [train..][epoch:164, iter:  72,800, lr:(1.000e-04,)] [eta: 2 days, 8:31:40, time (data): 1.092 (0.003)] l_pix: 3.0287e-02 
2024-05-17 18:24:57,510 INFO: [train..][epoch:164, iter:  73,000, lr:(1.000e-04,)] [eta: 2 days, 8:27:27, time (data): 1.106 (0.003)] l_pix: 1.8737e-02 
2024-05-17 18:28:49,625 INFO: [train..][epoch:165, iter:  73,200, lr:(1.000e-04,)] [eta: 2 days, 8:23:44, time (data): 1.095 (0.003)] l_pix: 2.3113e-02 
2024-05-17 18:32:29,577 INFO: [train..][epoch:165, iter:  73,400, lr:(1.000e-04,)] [eta: 2 days, 8:19:31, time (data): 1.105 (0.003)] l_pix: 2.6998e-02 
2024-05-17 18:36:22,755 INFO: [train..][epoch:166, iter:  73,600, lr:(1.000e-04,)] [eta: 2 days, 8:15:49, time (data): 1.096 (0.004)] l_pix: 1.7507e-02 
2024-05-17 18:40:02,368 INFO: [train..][epoch:166, iter:  73,800, lr:(1.000e-04,)] [eta: 2 days, 8:11:36, time (data): 1.098 (0.003)] l_pix: 3.3587e-02 
2024-05-17 18:43:55,377 INFO: [train..][epoch:167, iter:  74,000, lr:(1.000e-04,)] [eta: 2 days, 8:07:54, time (data): 1.496 (0.401)] l_pix: 2.2750e-02 
2024-05-17 18:47:35,497 INFO: [train..][epoch:167, iter:  74,200, lr:(1.000e-04,)] [eta: 2 days, 8:03:42, time (data): 1.107 (0.003)] l_pix: 2.7405e-02 
2024-05-17 18:51:15,514 INFO: [train..][epoch:167, iter:  74,400, lr:(1.000e-04,)] [eta: 2 days, 7:59:30, time (data): 1.100 (0.003)] l_pix: 2.4178e-02 
2024-05-17 18:55:07,621 INFO: [train..][epoch:168, iter:  74,600, lr:(1.000e-04,)] [eta: 2 days, 7:55:46, time (data): 1.106 (0.003)] l_pix: 2.3669e-02 
2024-05-17 18:58:47,694 INFO: [train..][epoch:168, iter:  74,800, lr:(1.000e-04,)] [eta: 2 days, 7:51:34, time (data): 1.098 (0.003)] l_pix: 3.9854e-02 
2024-05-17 19:02:39,271 INFO: [train..][epoch:169, iter:  75,000, lr:(1.000e-04,)] [eta: 2 days, 7:47:49, time (data): 1.107 (0.003)] l_pix: 2.1745e-02 
2024-05-17 19:02:39,272 INFO: Saving models and training states.
2024-05-17 19:02:40,655 INFO: Validation Set5
	 # psnr: 32.7312	Best: 32.8979 @ 45000 iter

2024-05-17 19:06:21,526 INFO: [train..][epoch:169, iter:  75,200, lr:(1.000e-04,)] [eta: 2 days, 7:43:43, time (data): 1.102 (0.004)] l_pix: 2.7672e-02 
2024-05-17 19:10:13,544 INFO: [train..][epoch:170, iter:  75,400, lr:(1.000e-04,)] [eta: 2 days, 7:39:59, time (data): 1.091 (0.004)] l_pix: 2.7244e-02 
2024-05-17 19:13:54,610 INFO: [train..][epoch:170, iter:  75,600, lr:(1.000e-04,)] [eta: 2 days, 7:35:50, time (data): 1.105 (0.004)] l_pix: 3.5299e-02 
2024-05-17 19:17:47,004 INFO: [train..][epoch:171, iter:  75,800, lr:(1.000e-04,)] [eta: 2 days, 7:32:07, time (data): 1.087 (0.004)] l_pix: 3.5527e-02 
2024-05-17 19:21:26,422 INFO: [train..][epoch:171, iter:  76,000, lr:(1.000e-04,)] [eta: 2 days, 7:27:54, time (data): 1.105 (0.004)] l_pix: 3.4261e-02 
2024-05-17 19:25:19,698 INFO: [train..][epoch:172, iter:  76,200, lr:(1.000e-04,)] [eta: 2 days, 7:24:13, time (data): 1.692 (0.583)] l_pix: 3.7811e-02 
2024-05-17 19:29:00,537 INFO: [train..][epoch:172, iter:  76,400, lr:(1.000e-04,)] [eta: 2 days, 7:20:04, time (data): 1.096 (0.003)] l_pix: 2.8788e-02 
2024-05-17 19:32:40,737 INFO: [train..][epoch:172, iter:  76,600, lr:(1.000e-04,)] [eta: 2 days, 7:15:54, time (data): 1.105 (0.003)] l_pix: 2.0237e-02 
2024-05-17 19:36:32,662 INFO: [train..][epoch:173, iter:  76,800, lr:(1.000e-04,)] [eta: 2 days, 7:12:10, time (data): 1.103 (0.004)] l_pix: 1.7511e-02 
2024-05-17 19:40:12,879 INFO: [train..][epoch:173, iter:  77,000, lr:(1.000e-04,)] [eta: 2 days, 7:07:59, time (data): 1.105 (0.004)] l_pix: 2.4062e-02 
2024-05-17 19:44:06,459 INFO: [train..][epoch:174, iter:  77,200, lr:(1.000e-04,)] [eta: 2 days, 7:04:19, time (data): 1.108 (0.003)] l_pix: 1.5954e-02 
2024-05-17 19:47:46,932 INFO: [train..][epoch:174, iter:  77,400, lr:(1.000e-04,)] [eta: 2 days, 7:00:10, time (data): 1.097 (0.003)] l_pix: 2.4806e-02 
2024-05-17 19:51:39,545 INFO: [train..][epoch:175, iter:  77,600, lr:(1.000e-04,)] [eta: 2 days, 6:56:27, time (data): 1.109 (0.004)] l_pix: 2.4824e-02 
2024-05-17 19:55:21,033 INFO: [train..][epoch:175, iter:  77,800, lr:(1.000e-04,)] [eta: 2 days, 6:52:20, time (data): 1.102 (0.003)] l_pix: 1.2448e-02 
2024-05-17 19:59:12,757 INFO: [train..][epoch:176, iter:  78,000, lr:(1.000e-04,)] [eta: 2 days, 6:48:36, time (data): 1.088 (0.003)] l_pix: 4.1493e-02 
2024-05-17 20:02:51,824 INFO: [train..][epoch:176, iter:  78,200, lr:(1.000e-04,)] [eta: 2 days, 6:44:23, time (data): 1.107 (0.003)] l_pix: 4.1863e-02 
2024-05-17 20:06:32,756 INFO: [train..][epoch:176, iter:  78,400, lr:(1.000e-04,)] [eta: 2 days, 6:40:15, time (data): 1.098 (0.003)] l_pix: 2.1296e-02 
2024-05-17 20:10:24,653 INFO: [train..][epoch:177, iter:  78,600, lr:(1.000e-04,)] [eta: 2 days, 6:36:32, time (data): 1.116 (0.004)] l_pix: 1.7616e-02 
2024-05-17 20:14:07,024 INFO: [train..][epoch:177, iter:  78,800, lr:(1.000e-04,)] [eta: 2 days, 6:32:27, time (data): 1.120 (0.004)] l_pix: 3.8820e-02 
2024-05-17 20:17:58,688 INFO: [train..][epoch:178, iter:  79,000, lr:(1.000e-04,)] [eta: 2 days, 6:28:42, time (data): 1.104 (0.003)] l_pix: 1.3788e-02 
2024-05-17 20:21:38,972 INFO: [train..][epoch:178, iter:  79,200, lr:(1.000e-04,)] [eta: 2 days, 6:24:33, time (data): 1.109 (0.003)] l_pix: 3.0807e-02 
2024-05-17 20:25:31,597 INFO: [train..][epoch:179, iter:  79,400, lr:(1.000e-04,)] [eta: 2 days, 6:20:51, time (data): 1.093 (0.003)] l_pix: 2.1617e-02 
2024-05-17 20:29:11,281 INFO: [train..][epoch:179, iter:  79,600, lr:(1.000e-04,)] [eta: 2 days, 6:16:41, time (data): 1.095 (0.003)] l_pix: 2.8205e-02 
2024-05-17 20:33:03,182 INFO: [train..][epoch:180, iter:  79,800, lr:(1.000e-04,)] [eta: 2 days, 6:12:57, time (data): 1.099 (0.005)] l_pix: 2.8315e-02 
2024-05-17 20:36:43,869 INFO: [train..][epoch:180, iter:  80,000, lr:(1.000e-04,)] [eta: 2 days, 6:08:49, time (data): 1.106 (0.003)] l_pix: 2.8508e-02 
2024-05-17 20:36:43,870 INFO: Saving models and training states.
2024-05-17 20:36:45,283 INFO: Validation Set5
	 # psnr: 32.8490	Best: 32.8979 @ 45000 iter

2024-05-17 20:40:38,057 INFO: [train..][epoch:181, iter:  80,200, lr:(1.000e-04,)] [eta: 2 days, 6:05:10, time (data): 1.086 (0.001)] l_pix: 1.4332e-02 
2024-05-17 20:44:17,557 INFO: [train..][epoch:181, iter:  80,400, lr:(1.000e-04,)] [eta: 2 days, 6:01:00, time (data): 1.097 (0.004)] l_pix: 2.3502e-02 
2024-05-17 20:47:57,654 INFO: [train..][epoch:181, iter:  80,600, lr:(1.000e-04,)] [eta: 2 days, 5:56:51, time (data): 1.100 (0.004)] l_pix: 2.4602e-02 
2024-05-17 20:51:48,119 INFO: [train..][epoch:182, iter:  80,800, lr:(1.000e-04,)] [eta: 2 days, 5:53:05, time (data): 1.152 (0.065)] l_pix: 1.5994e-02 
2024-05-17 20:55:28,402 INFO: [train..][epoch:182, iter:  81,000, lr:(1.000e-04,)] [eta: 2 days, 5:48:56, time (data): 1.101 (0.003)] l_pix: 1.9770e-02 
2024-05-17 20:59:19,230 INFO: [train..][epoch:183, iter:  81,200, lr:(1.000e-04,)] [eta: 2 days, 5:45:10, time (data): 1.155 (0.065)] l_pix: 1.6758e-02 
2024-05-17 21:02:58,677 INFO: [train..][epoch:183, iter:  81,400, lr:(1.000e-04,)] [eta: 2 days, 5:41:01, time (data): 1.097 (0.003)] l_pix: 1.7573e-02 
2024-05-17 21:06:50,196 INFO: [train..][epoch:184, iter:  81,600, lr:(1.000e-04,)] [eta: 2 days, 5:37:16, time (data): 1.159 (0.066)] l_pix: 1.9406e-02 
2024-05-17 21:10:29,776 INFO: [train..][epoch:184, iter:  81,800, lr:(1.000e-04,)] [eta: 2 days, 5:33:07, time (data): 1.098 (0.003)] l_pix: 3.7879e-02 
2024-05-17 21:14:21,524 INFO: [train..][epoch:185, iter:  82,000, lr:(1.000e-04,)] [eta: 2 days, 5:29:23, time (data): 1.161 (0.065)] l_pix: 3.7606e-02 
2024-05-17 21:18:01,295 INFO: [train..][epoch:185, iter:  82,200, lr:(1.000e-04,)] [eta: 2 days, 5:25:14, time (data): 1.099 (0.004)] l_pix: 1.9603e-02 
2024-05-17 21:21:54,732 INFO: [train..][epoch:186, iter:  82,400, lr:(1.000e-04,)] [eta: 2 days, 5:21:34, time (data): 1.170 (0.070)] l_pix: 2.3593e-02 
2024-05-17 21:25:34,723 INFO: [train..][epoch:186, iter:  82,600, lr:(1.000e-04,)] [eta: 2 days, 5:17:26, time (data): 1.101 (0.004)] l_pix: 1.8725e-02 
2024-05-17 21:29:14,995 INFO: [train..][epoch:186, iter:  82,800, lr:(1.000e-04,)] [eta: 2 days, 5:13:19, time (data): 1.101 (0.003)] l_pix: 3.6479e-02 
2024-05-17 21:33:07,552 INFO: [train..][epoch:187, iter:  83,000, lr:(1.000e-04,)] [eta: 2 days, 5:09:36, time (data): 1.167 (0.070)] l_pix: 1.7483e-02 
2024-05-17 21:36:48,117 INFO: [train..][epoch:187, iter:  83,200, lr:(1.000e-04,)] [eta: 2 days, 5:05:30, time (data): 1.102 (0.004)] l_pix: 1.5116e-02 
2024-05-17 21:40:39,225 INFO: [train..][epoch:188, iter:  83,400, lr:(1.000e-04,)] [eta: 2 days, 5:01:44, time (data): 1.160 (0.069)] l_pix: 2.0859e-02 
2024-05-17 21:44:20,498 INFO: [train..][epoch:188, iter:  83,600, lr:(1.000e-04,)] [eta: 2 days, 4:57:39, time (data): 1.106 (0.004)] l_pix: 2.4843e-02 
2024-05-17 21:48:11,822 INFO: [train..][epoch:189, iter:  83,800, lr:(1.000e-04,)] [eta: 2 days, 4:53:55, time (data): 1.162 (0.071)] l_pix: 3.0298e-02 
2024-05-17 21:51:51,940 INFO: [train..][epoch:189, iter:  84,000, lr:(1.000e-04,)] [eta: 2 days, 4:49:47, time (data): 1.102 (0.003)] l_pix: 1.5242e-02 
2024-05-17 21:55:43,926 INFO: [train..][epoch:190, iter:  84,200, lr:(1.000e-04,)] [eta: 2 days, 4:46:04, time (data): 1.165 (0.070)] l_pix: 2.7492e-02 
2024-05-17 21:59:23,329 INFO: [train..][epoch:190, iter:  84,400, lr:(1.000e-04,)] [eta: 2 days, 4:41:56, time (data): 1.097 (0.004)] l_pix: 1.3642e-02 
2024-05-17 22:03:04,057 INFO: [train..][epoch:190, iter:  84,600, lr:(1.000e-04,)] [eta: 2 days, 4:37:50, time (data): 1.104 (0.003)] l_pix: 2.8227e-02 
2024-05-17 22:06:54,874 INFO: [train..][epoch:191, iter:  84,800, lr:(1.000e-04,)] [eta: 2 days, 4:34:04, time (data): 1.092 (0.004)] l_pix: 2.4257e-02 
2024-05-17 22:10:35,261 INFO: [train..][epoch:191, iter:  85,000, lr:(1.000e-04,)] [eta: 2 days, 4:29:58, time (data): 1.103 (0.003)] l_pix: 3.1057e-02 
2024-05-17 22:10:35,262 INFO: Saving models and training states.
2024-05-17 22:10:36,637 INFO: Validation Set5
	 # psnr: 32.8850	Best: 32.8979 @ 45000 iter

2024-05-17 22:14:27,797 INFO: [train..][epoch:192, iter:  85,200, lr:(1.000e-04,)] [eta: 2 days, 4:26:16, time (data): 1.163 (0.072)] l_pix: 2.8611e-02 
2024-05-17 22:18:08,581 INFO: [train..][epoch:192, iter:  85,400, lr:(1.000e-04,)] [eta: 2 days, 4:22:11, time (data): 1.104 (0.003)] l_pix: 3.6857e-02 
2024-05-17 22:22:00,184 INFO: [train..][epoch:193, iter:  85,600, lr:(1.000e-04,)] [eta: 2 days, 4:18:26, time (data): 1.165 (0.072)] l_pix: 2.8313e-02 
2024-05-17 22:25:41,107 INFO: [train..][epoch:193, iter:  85,800, lr:(1.000e-04,)] [eta: 2 days, 4:14:22, time (data): 1.105 (0.003)] l_pix: 2.8099e-02 
2024-05-17 22:29:33,753 INFO: [train..][epoch:194, iter:  86,000, lr:(1.000e-04,)] [eta: 2 days, 4:10:40, time (data): 1.172 (0.075)] l_pix: 3.3034e-02 
2024-05-17 22:33:13,203 INFO: [train..][epoch:194, iter:  86,200, lr:(1.000e-04,)] [eta: 2 days, 4:06:32, time (data): 1.098 (0.004)] l_pix: 1.3197e-02 
2024-05-17 22:37:06,117 INFO: [train..][epoch:195, iter:  86,400, lr:(1.000e-04,)] [eta: 2 days, 4:02:50, time (data): 1.175 (0.075)] l_pix: 4.3664e-02 
2024-05-17 22:40:44,608 INFO: [train..][epoch:195, iter:  86,600, lr:(1.000e-04,)] [eta: 2 days, 3:58:41, time (data): 1.094 (0.004)] l_pix: 2.4935e-02 
2024-05-17 22:44:24,104 INFO: [train..][epoch:195, iter:  86,800, lr:(1.000e-04,)] [eta: 2 days, 3:54:34, time (data): 1.098 (0.004)] l_pix: 2.9664e-02 
2024-05-17 22:48:17,913 INFO: [train..][epoch:196, iter:  87,000, lr:(1.000e-04,)] [eta: 2 days, 3:50:54, time (data): 1.110 (0.004)] l_pix: 2.1039e-02 
2024-05-17 22:51:57,436 INFO: [train..][epoch:196, iter:  87,200, lr:(1.000e-04,)] [eta: 2 days, 3:46:48, time (data): 1.097 (0.004)] l_pix: 1.8519e-02 
2024-05-17 22:55:48,371 INFO: [train..][epoch:197, iter:  87,400, lr:(1.000e-04,)] [eta: 2 days, 3:43:02, time (data): 1.167 (0.077)] l_pix: 2.1371e-02 
2024-05-17 22:59:28,618 INFO: [train..][epoch:197, iter:  87,600, lr:(1.000e-04,)] [eta: 2 days, 3:38:57, time (data): 1.101 (0.003)] l_pix: 1.9818e-02 
2024-05-17 23:03:20,236 INFO: [train..][epoch:198, iter:  87,800, lr:(1.000e-04,)] [eta: 2 days, 3:35:13, time (data): 1.170 (0.076)] l_pix: 1.3317e-02 
2024-05-17 23:07:01,049 INFO: [train..][epoch:198, iter:  88,000, lr:(1.000e-04,)] [eta: 2 days, 3:31:09, time (data): 1.105 (0.003)] l_pix: 2.9709e-02 
2024-05-17 23:10:52,514 INFO: [train..][epoch:199, iter:  88,200, lr:(1.000e-04,)] [eta: 2 days, 3:27:24, time (data): 1.170 (0.078)] l_pix: 2.6799e-02 
2024-05-17 23:14:32,693 INFO: [train..][epoch:199, iter:  88,400, lr:(1.000e-04,)] [eta: 2 days, 3:23:19, time (data): 1.103 (0.004)] l_pix: 2.2003e-02 
2024-05-17 23:18:12,688 INFO: [train..][epoch:199, iter:  88,600, lr:(1.000e-04,)] [eta: 2 days, 3:19:14, time (data): 1.100 (0.004)] l_pix: 3.3987e-02 
2024-05-17 23:22:05,189 INFO: [train..][epoch:200, iter:  88,800, lr:(1.000e-04,)] [eta: 2 days, 3:15:32, time (data): 1.101 (0.003)] l_pix: 2.5402e-02 
2024-05-17 23:25:45,857 INFO: [train..][epoch:200, iter:  89,000, lr:(1.000e-04,)] [eta: 2 days, 3:11:28, time (data): 1.101 (0.003)] l_pix: 3.1864e-02 
2024-05-17 23:29:36,665 INFO: [train..][epoch:201, iter:  89,200, lr:(1.000e-04,)] [eta: 2 days, 3:07:42, time (data): 1.170 (0.082)] l_pix: 2.7918e-02 
2024-05-17 23:33:16,718 INFO: [train..][epoch:201, iter:  89,400, lr:(1.000e-04,)] [eta: 2 days, 3:03:37, time (data): 1.101 (0.003)] l_pix: 2.9147e-02 
2024-05-17 23:37:07,603 INFO: [train..][epoch:202, iter:  89,600, lr:(1.000e-04,)] [eta: 2 days, 2:59:52, time (data): 1.170 (0.081)] l_pix: 2.3816e-02 
2024-05-17 23:40:46,960 INFO: [train..][epoch:202, iter:  89,800, lr:(1.000e-04,)] [eta: 2 days, 2:55:46, time (data): 1.097 (0.004)] l_pix: 1.9119e-02 
2024-05-17 23:44:38,421 INFO: [train..][epoch:203, iter:  90,000, lr:(1.000e-04,)] [eta: 2 days, 2:52:01, time (data): 1.174 (0.081)] l_pix: 2.0618e-02 
2024-05-17 23:44:38,422 INFO: Saving models and training states.
2024-05-17 23:44:39,776 INFO: Validation Set5
	 # psnr: 32.8936	Best: 32.8979 @ 45000 iter

2024-05-17 23:48:19,004 INFO: [train..][epoch:203, iter:  90,200, lr:(1.000e-04,)] [eta: 2 days, 2:47:58, time (data): 1.097 (0.003)] l_pix: 4.2554e-02 
2024-05-17 23:52:11,128 INFO: [train..][epoch:204, iter:  90,400, lr:(1.000e-04,)] [eta: 2 days, 2:44:15, time (data): 1.181 (0.084)] l_pix: 2.3005e-02 
2024-05-17 23:55:50,109 INFO: [train..][epoch:204, iter:  90,600, lr:(1.000e-04,)] [eta: 2 days, 2:40:08, time (data): 1.097 (0.003)] l_pix: 1.7507e-02 
2024-05-17 23:59:30,127 INFO: [train..][epoch:204, iter:  90,800, lr:(1.000e-04,)] [eta: 2 days, 2:36:04, time (data): 1.101 (0.003)] l_pix: 3.2885e-02 
2024-05-18 00:03:21,555 INFO: [train..][epoch:205, iter:  91,000, lr:(1.000e-04,)] [eta: 2 days, 2:32:20, time (data): 1.098 (0.003)] l_pix: 3.3185e-02 
2024-05-18 00:07:01,797 INFO: [train..][epoch:205, iter:  91,200, lr:(1.000e-04,)] [eta: 2 days, 2:28:16, time (data): 1.102 (0.004)] l_pix: 2.4180e-02 
2024-05-18 00:10:53,421 INFO: [train..][epoch:206, iter:  91,400, lr:(1.000e-04,)] [eta: 2 days, 2:24:32, time (data): 1.178 (0.087)] l_pix: 2.3894e-02 
2024-05-18 00:14:33,170 INFO: [train..][epoch:206, iter:  91,600, lr:(1.000e-04,)] [eta: 2 days, 2:20:27, time (data): 1.098 (0.003)] l_pix: 2.1623e-02 
2024-05-18 00:18:24,442 INFO: [train..][epoch:207, iter:  91,800, lr:(1.000e-04,)] [eta: 2 days, 2:16:43, time (data): 1.180 (0.089)] l_pix: 2.9651e-02 
2024-05-18 00:22:05,110 INFO: [train..][epoch:207, iter:  92,000, lr:(1.000e-04,)] [eta: 2 days, 2:12:40, time (data): 1.103 (0.004)] l_pix: 2.7805e-02 
2024-05-18 00:25:56,724 INFO: [train..][epoch:208, iter:  92,200, lr:(1.000e-04,)] [eta: 2 days, 2:08:56, time (data): 1.182 (0.089)] l_pix: 3.3054e-02 
2024-05-18 00:29:37,743 INFO: [train..][epoch:208, iter:  92,400, lr:(1.000e-04,)] [eta: 2 days, 2:04:54, time (data): 1.108 (0.004)] l_pix: 2.7715e-02 
2024-05-18 00:33:30,642 INFO: [train..][epoch:209, iter:  92,600, lr:(1.000e-04,)] [eta: 2 days, 2:01:12, time (data): 1.189 (0.092)] l_pix: 2.3316e-02 
2024-05-18 00:37:10,819 INFO: [train..][epoch:209, iter:  92,800, lr:(1.000e-04,)] [eta: 2 days, 1:57:08, time (data): 1.106 (0.004)] l_pix: 2.1479e-02 
2024-05-18 00:40:51,553 INFO: [train..][epoch:209, iter:  93,000, lr:(1.000e-04,)] [eta: 2 days, 1:53:06, time (data): 1.103 (0.003)] l_pix: 3.0730e-02 
2024-05-18 00:44:43,131 INFO: [train..][epoch:210, iter:  93,200, lr:(1.000e-04,)] [eta: 2 days, 1:49:22, time (data): 1.097 (0.004)] l_pix: 1.8789e-02 
2024-05-18 00:48:24,530 INFO: [train..][epoch:210, iter:  93,400, lr:(1.000e-04,)] [eta: 2 days, 1:45:21, time (data): 1.106 (0.003)] l_pix: 1.2891e-02 
2024-05-18 00:52:15,421 INFO: [train..][epoch:211, iter:  93,600, lr:(1.000e-04,)] [eta: 2 days, 1:41:35, time (data): 1.180 (0.093)] l_pix: 1.8803e-02 
2024-05-18 00:55:55,801 INFO: [train..][epoch:211, iter:  93,800, lr:(1.000e-04,)] [eta: 2 days, 1:37:33, time (data): 1.105 (0.003)] l_pix: 2.3284e-02 
2024-05-18 00:59:47,504 INFO: [train..][epoch:212, iter:  94,000, lr:(1.000e-04,)] [eta: 2 days, 1:33:49, time (data): 1.186 (0.096)] l_pix: 2.6357e-02 
2024-05-18 01:03:27,314 INFO: [train..][epoch:212, iter:  94,200, lr:(1.000e-04,)] [eta: 2 days, 1:29:45, time (data): 1.102 (0.003)] l_pix: 1.7345e-02 
2024-05-18 01:07:19,671 INFO: [train..][epoch:213, iter:  94,400, lr:(1.000e-04,)] [eta: 2 days, 1:26:03, time (data): 1.192 (0.095)] l_pix: 2.8733e-02 
2024-05-18 01:10:58,797 INFO: [train..][epoch:213, iter:  94,600, lr:(1.000e-04,)] [eta: 2 days, 1:21:58, time (data): 1.098 (0.003)] l_pix: 2.2494e-02 
2024-05-18 01:14:39,687 INFO: [train..][epoch:213, iter:  94,800, lr:(1.000e-04,)] [eta: 2 days, 1:17:56, time (data): 1.105 (0.003)] l_pix: 2.4181e-02 
2024-05-18 01:18:30,593 INFO: [train..][epoch:214, iter:  95,000, lr:(1.000e-04,)] [eta: 2 days, 1:14:11, time (data): 1.097 (0.004)] l_pix: 2.9075e-02 
2024-05-18 01:18:30,595 INFO: Saving models and training states.
2024-05-18 01:18:31,979 INFO: Validation Set5
	 # psnr: 32.8931	Best: 32.8979 @ 45000 iter

2024-05-18 01:22:11,549 INFO: [train..][epoch:214, iter:  95,200, lr:(1.000e-04,)] [eta: 2 days, 1:10:10, time (data): 1.100 (0.003)] l_pix: 2.1225e-02 
2024-05-18 01:26:03,571 INFO: [train..][epoch:215, iter:  95,400, lr:(1.000e-04,)] [eta: 2 days, 1:06:27, time (data): 1.099 (0.004)] l_pix: 3.6239e-02 
2024-05-18 01:29:42,987 INFO: [train..][epoch:215, iter:  95,600, lr:(1.000e-04,)] [eta: 2 days, 1:02:23, time (data): 1.097 (0.003)] l_pix: 2.6433e-02 
2024-05-18 01:33:34,767 INFO: [train..][epoch:216, iter:  95,800, lr:(1.000e-04,)] [eta: 2 days, 0:58:39, time (data): 1.198 (0.103)] l_pix: 3.5656e-02 
2024-05-18 01:37:15,012 INFO: [train..][epoch:216, iter:  96,000, lr:(1.000e-04,)] [eta: 2 days, 0:54:37, time (data): 1.101 (0.003)] l_pix: 1.8141e-02 
2024-05-18 01:41:06,114 INFO: [train..][epoch:217, iter:  96,200, lr:(1.000e-04,)] [eta: 2 days, 0:50:52, time (data): 1.193 (0.104)] l_pix: 1.8201e-02 
2024-05-18 01:44:46,449 INFO: [train..][epoch:217, iter:  96,400, lr:(1.000e-04,)] [eta: 2 days, 0:46:50, time (data): 1.103 (0.003)] l_pix: 2.4310e-02 
2024-05-18 01:48:37,953 INFO: [train..][epoch:218, iter:  96,600, lr:(1.000e-04,)] [eta: 2 days, 0:43:06, time (data): 1.197 (0.105)] l_pix: 2.3662e-02 
2024-05-18 01:52:17,323 INFO: [train..][epoch:218, iter:  96,800, lr:(1.000e-04,)] [eta: 2 days, 0:39:03, time (data): 1.099 (0.003)] l_pix: 3.8683e-02 
2024-05-18 01:55:57,760 INFO: [train..][epoch:218, iter:  97,000, lr:(1.000e-04,)] [eta: 2 days, 0:35:01, time (data): 1.100 (0.003)] l_pix: 2.6453e-02 
2024-05-18 01:59:48,160 INFO: [train..][epoch:219, iter:  97,200, lr:(1.000e-04,)] [eta: 2 days, 0:31:15, time (data): 1.093 (0.003)] l_pix: 2.2652e-02 
2024-05-18 02:03:29,098 INFO: [train..][epoch:219, iter:  97,400, lr:(1.000e-04,)] [eta: 2 days, 0:27:15, time (data): 1.106 (0.003)] l_pix: 2.0395e-02 
2024-05-18 02:07:20,145 INFO: [train..][epoch:220, iter:  97,600, lr:(1.000e-04,)] [eta: 2 days, 0:23:30, time (data): 1.092 (0.003)] l_pix: 2.7555e-02 
2024-05-18 02:10:59,751 INFO: [train..][epoch:220, iter:  97,800, lr:(1.000e-04,)] [eta: 2 days, 0:19:27, time (data): 1.101 (0.003)] l_pix: 1.6307e-02 
2024-05-18 02:14:51,322 INFO: [train..][epoch:221, iter:  98,000, lr:(1.000e-04,)] [eta: 2 days, 0:15:43, time (data): 1.198 (0.110)] l_pix: 3.2108e-02 
2024-05-18 02:18:30,964 INFO: [train..][epoch:221, iter:  98,200, lr:(1.000e-04,)] [eta: 2 days, 0:11:41, time (data): 1.097 (0.003)] l_pix: 3.0712e-02 
2024-05-18 02:22:23,050 INFO: [train..][epoch:222, iter:  98,400, lr:(1.000e-04,)] [eta: 2 days, 0:07:57, time (data): 1.210 (0.113)] l_pix: 1.7857e-02 
2024-05-18 02:26:02,563 INFO: [train..][epoch:222, iter:  98,600, lr:(1.000e-04,)] [eta: 2 days, 0:03:55, time (data): 1.098 (0.003)] l_pix: 3.7257e-02 
2024-05-18 02:29:54,963 INFO: [train..][epoch:223, iter:  98,800, lr:(1.000e-04,)] [eta: 2 days, 0:00:12, time (data): 1.214 (0.115)] l_pix: 2.4006e-02 
2024-05-18 02:33:34,107 INFO: [train..][epoch:223, iter:  99,000, lr:(1.000e-04,)] [eta: 1 day, 23:56:09, time (data): 1.098 (0.003)] l_pix: 2.7042e-02 
2024-05-18 02:37:13,977 INFO: [train..][epoch:223, iter:  99,200, lr:(1.000e-04,)] [eta: 1 day, 23:52:07, time (data): 1.100 (0.003)] l_pix: 2.6626e-02 
2024-05-18 02:41:05,283 INFO: [train..][epoch:224, iter:  99,400, lr:(1.000e-04,)] [eta: 1 day, 23:48:23, time (data): 1.100 (0.004)] l_pix: 2.7195e-02 
2024-05-18 02:44:45,128 INFO: [train..][epoch:224, iter:  99,600, lr:(1.000e-04,)] [eta: 1 day, 23:44:21, time (data): 1.099 (0.003)] l_pix: 1.8611e-02 
2024-05-18 02:48:37,419 INFO: [train..][epoch:225, iter:  99,800, lr:(1.000e-04,)] [eta: 1 day, 23:40:38, time (data): 1.099 (0.004)] l_pix: 2.3153e-02 
2024-05-18 02:52:17,408 INFO: [train..][epoch:225, iter: 100,000, lr:(1.000e-04,)] [eta: 1 day, 23:36:37, time (data): 1.099 (0.003)] l_pix: 2.8227e-02 
2024-05-18 02:52:17,409 INFO: Saving models and training states.
2024-05-18 02:52:19,014 INFO: Validation Set5
	 # psnr: 32.8899	Best: 32.8979 @ 45000 iter

2024-05-18 02:56:10,927 INFO: [train..][epoch:226, iter: 100,200, lr:(1.000e-04,)] [eta: 1 day, 23:32:56, time (data): 1.218 (0.128)] l_pix: 3.2066e-02 
2024-05-18 02:59:50,994 INFO: [train..][epoch:226, iter: 100,400, lr:(1.000e-04,)] [eta: 1 day, 23:28:55, time (data): 1.100 (0.003)] l_pix: 2.2889e-02 
2024-05-18 03:03:43,756 INFO: [train..][epoch:227, iter: 100,600, lr:(1.000e-04,)] [eta: 1 day, 23:25:13, time (data): 1.228 (0.133)] l_pix: 2.8205e-02 
2024-05-18 03:07:23,235 INFO: [train..][epoch:227, iter: 100,800, lr:(1.000e-04,)] [eta: 1 day, 23:21:11, time (data): 1.099 (0.003)] l_pix: 3.4720e-02 
2024-05-18 03:11:03,193 INFO: [train..][epoch:227, iter: 101,000, lr:(1.000e-04,)] [eta: 1 day, 23:17:09, time (data): 1.101 (0.003)] l_pix: 1.6936e-02 
2024-05-18 03:14:55,972 INFO: [train..][epoch:228, iter: 101,200, lr:(1.000e-04,)] [eta: 1 day, 23:13:27, time (data): 1.101 (0.003)] l_pix: 2.5881e-02 
2024-05-18 03:18:35,556 INFO: [train..][epoch:228, iter: 101,400, lr:(1.000e-04,)] [eta: 1 day, 23:09:26, time (data): 1.098 (0.003)] l_pix: 4.5179e-02 
2024-05-18 03:22:27,802 INFO: [train..][epoch:229, iter: 101,600, lr:(1.000e-04,)] [eta: 1 day, 23:05:43, time (data): 1.099 (0.004)] l_pix: 1.7085e-02 
2024-05-18 03:26:07,726 INFO: [train..][epoch:229, iter: 101,800, lr:(1.000e-04,)] [eta: 1 day, 23:01:42, time (data): 1.099 (0.003)] l_pix: 2.6485e-02 
2024-05-18 03:29:59,136 INFO: [train..][epoch:230, iter: 102,000, lr:(1.000e-04,)] [eta: 1 day, 22:57:57, time (data): 1.093 (0.003)] l_pix: 1.8795e-02 
2024-05-18 03:33:39,011 INFO: [train..][epoch:230, iter: 102,200, lr:(1.000e-04,)] [eta: 1 day, 22:53:57, time (data): 1.098 (0.003)] l_pix: 3.0762e-02 
2024-05-18 03:37:31,833 INFO: [train..][epoch:231, iter: 102,400, lr:(1.000e-04,)] [eta: 1 day, 22:50:14, time (data): 1.236 (0.146)] l_pix: 2.0677e-02 
2024-05-18 03:41:11,612 INFO: [train..][epoch:231, iter: 102,600, lr:(1.000e-04,)] [eta: 1 day, 22:46:13, time (data): 1.099 (0.003)] l_pix: 2.1537e-02 
2024-05-18 03:45:04,111 INFO: [train..][epoch:232, iter: 102,800, lr:(1.000e-04,)] [eta: 1 day, 22:42:31, time (data): 1.237 (0.139)] l_pix: 2.0779e-02 
2024-05-18 03:48:43,455 INFO: [train..][epoch:232, iter: 103,000, lr:(1.000e-04,)] [eta: 1 day, 22:38:29, time (data): 1.099 (0.003)] l_pix: 2.5919e-02 
2024-05-18 03:52:24,441 INFO: [train..][epoch:232, iter: 103,200, lr:(1.000e-04,)] [eta: 1 day, 22:34:30, time (data): 1.108 (0.004)] l_pix: 1.8791e-02 
2024-05-18 03:56:15,777 INFO: [train..][epoch:233, iter: 103,400, lr:(1.000e-04,)] [eta: 1 day, 22:30:46, time (data): 1.100 (0.004)] l_pix: 2.0690e-02 
2024-05-18 03:59:56,145 INFO: [train..][epoch:233, iter: 103,600, lr:(1.000e-04,)] [eta: 1 day, 22:26:46, time (data): 1.104 (0.003)] l_pix: 3.3889e-02 
2024-05-18 04:03:48,262 INFO: [train..][epoch:234, iter: 103,800, lr:(1.000e-04,)] [eta: 1 day, 22:23:03, time (data): 1.096 (0.004)] l_pix: 1.5998e-02 
2024-05-18 04:07:28,785 INFO: [train..][epoch:234, iter: 104,000, lr:(1.000e-04,)] [eta: 1 day, 22:19:03, time (data): 1.105 (0.003)] l_pix: 2.1262e-02 
2024-05-18 04:11:20,878 INFO: [train..][epoch:235, iter: 104,200, lr:(1.000e-04,)] [eta: 1 day, 22:15:20, time (data): 1.091 (0.003)] l_pix: 1.8960e-02 
2024-05-18 04:15:00,821 INFO: [train..][epoch:235, iter: 104,400, lr:(1.000e-04,)] [eta: 1 day, 22:11:20, time (data): 1.101 (0.003)] l_pix: 2.4734e-02 
2024-05-18 04:18:52,957 INFO: [train..][epoch:236, iter: 104,600, lr:(1.000e-04,)] [eta: 1 day, 22:07:36, time (data): 1.243 (0.154)] l_pix: 2.3311e-02 
2024-05-18 04:22:32,483 INFO: [train..][epoch:236, iter: 104,800, lr:(1.000e-04,)] [eta: 1 day, 22:03:36, time (data): 1.097 (0.003)] l_pix: 2.6517e-02 
2024-05-18 04:26:25,115 INFO: [train..][epoch:237, iter: 105,000, lr:(1.000e-04,)] [eta: 1 day, 21:59:53, time (data): 1.261 (0.161)] l_pix: 1.1510e-02 
2024-05-18 04:26:25,116 INFO: Saving models and training states.
2024-05-18 04:26:26,530 INFO: Validation Set5
	 # psnr: 32.9223	Best: 32.9223 @ 105000 iter

2024-05-18 04:30:05,428 INFO: [train..][epoch:237, iter: 105,200, lr:(1.000e-04,)] [eta: 1 day, 21:55:54, time (data): 1.097 (0.003)] l_pix: 2.4067e-02 
2024-05-18 04:33:45,529 INFO: [train..][epoch:237, iter: 105,400, lr:(1.000e-04,)] [eta: 1 day, 21:51:54, time (data): 1.103 (0.003)] l_pix: 2.0460e-02 
2024-05-18 04:37:37,965 INFO: [train..][epoch:238, iter: 105,600, lr:(1.000e-04,)] [eta: 1 day, 21:48:11, time (data): 1.101 (0.003)] l_pix: 2.9850e-02 
2024-05-18 04:41:17,812 INFO: [train..][epoch:238, iter: 105,800, lr:(1.000e-04,)] [eta: 1 day, 21:44:11, time (data): 1.103 (0.003)] l_pix: 2.6120e-02 
2024-05-18 04:45:09,473 INFO: [train..][epoch:239, iter: 106,000, lr:(1.000e-04,)] [eta: 1 day, 21:40:27, time (data): 1.096 (0.004)] l_pix: 1.5511e-02 
2024-05-18 04:48:49,274 INFO: [train..][epoch:239, iter: 106,200, lr:(1.000e-04,)] [eta: 1 day, 21:36:27, time (data): 1.100 (0.003)] l_pix: 2.0378e-02 
2024-05-18 04:52:40,731 INFO: [train..][epoch:240, iter: 106,400, lr:(1.000e-04,)] [eta: 1 day, 21:32:43, time (data): 1.088 (0.004)] l_pix: 2.2201e-02 
2024-05-18 04:56:20,770 INFO: [train..][epoch:240, iter: 106,600, lr:(1.000e-04,)] [eta: 1 day, 21:28:43, time (data): 1.100 (0.003)] l_pix: 2.1751e-02 
2024-05-18 05:00:13,140 INFO: [train..][epoch:241, iter: 106,800, lr:(1.000e-04,)] [eta: 1 day, 21:25:00, time (data): 1.274 (0.182)] l_pix: 2.8330e-02 
2024-05-18 05:03:52,808 INFO: [train..][epoch:241, iter: 107,000, lr:(1.000e-04,)] [eta: 1 day, 21:21:00, time (data): 1.102 (0.004)] l_pix: 2.4852e-02 
2024-05-18 05:07:32,658 INFO: [train..][epoch:241, iter: 107,200, lr:(1.000e-04,)] [eta: 1 day, 21:17:01, time (data): 1.102 (0.003)] l_pix: 2.6305e-02 
2024-05-18 05:11:24,954 INFO: [train..][epoch:242, iter: 107,400, lr:(1.000e-04,)] [eta: 1 day, 21:13:18, time (data): 1.108 (0.003)] l_pix: 2.1563e-02 
2024-05-18 05:15:05,067 INFO: [train..][epoch:242, iter: 107,600, lr:(1.000e-04,)] [eta: 1 day, 21:09:19, time (data): 1.101 (0.004)] l_pix: 2.3147e-02 
2024-05-18 05:18:56,921 INFO: [train..][epoch:243, iter: 107,800, lr:(1.000e-04,)] [eta: 1 day, 21:05:35, time (data): 1.103 (0.003)] l_pix: 5.1325e-02 
2024-05-18 05:22:37,308 INFO: [train..][epoch:243, iter: 108,000, lr:(1.000e-04,)] [eta: 1 day, 21:01:36, time (data): 1.097 (0.004)] l_pix: 2.6578e-02 
2024-05-18 05:26:28,733 INFO: [train..][epoch:244, iter: 108,200, lr:(1.000e-04,)] [eta: 1 day, 20:57:52, time (data): 1.095 (0.004)] l_pix: 1.5388e-02 
2024-05-18 05:30:09,441 INFO: [train..][epoch:244, iter: 108,400, lr:(1.000e-04,)] [eta: 1 day, 20:53:54, time (data): 1.104 (0.003)] l_pix: 1.9266e-02 
2024-05-18 05:34:00,759 INFO: [train..][epoch:245, iter: 108,600, lr:(1.000e-04,)] [eta: 1 day, 20:50:09, time (data): 1.089 (0.004)] l_pix: 2.4947e-02 
2024-05-18 05:37:41,186 INFO: [train..][epoch:245, iter: 108,800, lr:(1.000e-04,)] [eta: 1 day, 20:46:11, time (data): 1.103 (0.004)] l_pix: 3.2007e-02 
2024-05-18 05:41:32,860 INFO: [train..][epoch:246, iter: 109,000, lr:(1.000e-04,)] [eta: 1 day, 20:42:27, time (data): 1.299 (0.211)] l_pix: 2.9990e-02 
2024-05-18 05:45:12,081 INFO: [train..][epoch:246, iter: 109,200, lr:(1.000e-04,)] [eta: 1 day, 20:38:27, time (data): 1.104 (0.003)] l_pix: 1.0933e-02 
2024-05-18 05:48:52,231 INFO: [train..][epoch:246, iter: 109,400, lr:(1.000e-04,)] [eta: 1 day, 20:34:28, time (data): 1.097 (0.003)] l_pix: 3.0560e-02 
2024-05-18 05:52:43,500 INFO: [train..][epoch:247, iter: 109,600, lr:(1.000e-04,)] [eta: 1 day, 20:30:44, time (data): 1.107 (0.003)] l_pix: 2.5030e-02 
2024-05-18 05:56:23,758 INFO: [train..][epoch:247, iter: 109,800, lr:(1.000e-04,)] [eta: 1 day, 20:26:45, time (data): 1.101 (0.004)] l_pix: 1.8787e-02 
2024-05-18 06:00:15,371 INFO: [train..][epoch:248, iter: 110,000, lr:(1.000e-04,)] [eta: 1 day, 20:23:01, time (data): 1.105 (0.005)] l_pix: 1.0905e-02 
2024-05-18 06:00:15,372 INFO: Saving models and training states.
2024-05-18 06:00:16,773 INFO: Validation Set5
	 # psnr: 32.9497	Best: 32.9497 @ 110000 iter

2024-05-18 06:03:57,965 INFO: [train..][epoch:248, iter: 110,200, lr:(1.000e-04,)] [eta: 1 day, 20:19:06, time (data): 1.103 (0.003)] l_pix: 1.1117e-02 
2024-05-18 06:07:48,975 INFO: [train..][epoch:249, iter: 110,400, lr:(1.000e-04,)] [eta: 1 day, 20:15:21, time (data): 1.089 (0.004)] l_pix: 1.9075e-02 
2024-05-18 06:11:27,687 INFO: [train..][epoch:249, iter: 110,600, lr:(1.000e-04,)] [eta: 1 day, 20:11:21, time (data): 1.095 (0.003)] l_pix: 2.1817e-02 
2024-05-18 06:15:19,715 INFO: [train..][epoch:250, iter: 110,800, lr:(1.000e-04,)] [eta: 1 day, 20:07:37, time (data): 1.086 (0.003)] l_pix: 1.9456e-02 
2024-05-18 06:18:58,896 INFO: [train..][epoch:250, iter: 111,000, lr:(1.000e-04,)] [eta: 1 day, 20:03:38, time (data): 1.096 (0.003)] l_pix: 2.1101e-02 
2024-05-18 06:22:51,847 INFO: [train..][epoch:251, iter: 111,200, lr:(1.000e-04,)] [eta: 1 day, 19:59:55, time (data): 1.364 (0.266)] l_pix: 2.2924e-02 
2024-05-18 06:26:31,267 INFO: [train..][epoch:251, iter: 111,400, lr:(1.000e-04,)] [eta: 1 day, 19:55:56, time (data): 1.101 (0.004)] l_pix: 2.6765e-02 
2024-05-18 06:30:10,746 INFO: [train..][epoch:251, iter: 111,600, lr:(1.000e-04,)] [eta: 1 day, 19:51:57, time (data): 1.098 (0.003)] l_pix: 3.3812e-02 
2024-05-18 06:34:02,452 INFO: [train..][epoch:252, iter: 111,800, lr:(1.000e-04,)] [eta: 1 day, 19:48:13, time (data): 1.103 (0.003)] l_pix: 3.6074e-02 
2024-05-18 06:37:42,342 INFO: [train..][epoch:252, iter: 112,000, lr:(1.000e-04,)] [eta: 1 day, 19:44:15, time (data): 1.097 (0.004)] l_pix: 3.3725e-02 
2024-05-18 06:41:32,788 INFO: [train..][epoch:253, iter: 112,200, lr:(1.000e-04,)] [eta: 1 day, 19:40:29, time (data): 1.087 (0.003)] l_pix: 2.5768e-02 
2024-05-18 06:45:13,083 INFO: [train..][epoch:253, iter: 112,400, lr:(1.000e-04,)] [eta: 1 day, 19:36:31, time (data): 1.105 (0.004)] l_pix: 2.1356e-02 
2024-05-18 06:49:04,082 INFO: [train..][epoch:254, iter: 112,600, lr:(1.000e-04,)] [eta: 1 day, 19:32:47, time (data): 1.088 (0.003)] l_pix: 3.4192e-02 
2024-05-18 06:52:43,391 INFO: [train..][epoch:254, iter: 112,800, lr:(1.000e-04,)] [eta: 1 day, 19:28:48, time (data): 1.102 (0.004)] l_pix: 2.1639e-02 
2024-05-18 06:56:35,646 INFO: [train..][epoch:255, iter: 113,000, lr:(1.000e-04,)] [eta: 1 day, 19:25:04, time (data): 1.408 (0.318)] l_pix: 3.4966e-02 
2024-05-18 07:00:14,209 INFO: [train..][epoch:255, iter: 113,200, lr:(1.000e-04,)] [eta: 1 day, 19:21:05, time (data): 1.091 (0.003)] l_pix: 2.7209e-02 
2024-05-18 07:03:53,467 INFO: [train..][epoch:255, iter: 113,400, lr:(1.000e-04,)] [eta: 1 day, 19:17:06, time (data): 1.099 (0.003)] l_pix: 1.2889e-02 
2024-05-18 07:07:44,400 INFO: [train..][epoch:256, iter: 113,600, lr:(1.000e-04,)] [eta: 1 day, 19:13:21, time (data): 1.098 (0.003)] l_pix: 1.5231e-02 
2024-05-18 07:11:23,351 INFO: [train..][epoch:256, iter: 113,800, lr:(1.000e-04,)] [eta: 1 day, 19:09:22, time (data): 1.093 (0.003)] l_pix: 1.6796e-02 
2024-05-18 07:15:14,311 INFO: [train..][epoch:257, iter: 114,000, lr:(1.000e-04,)] [eta: 1 day, 19:05:37, time (data): 1.101 (0.003)] l_pix: 2.1145e-02 
2024-05-18 07:18:54,092 INFO: [train..][epoch:257, iter: 114,200, lr:(1.000e-04,)] [eta: 1 day, 19:01:39, time (data): 1.097 (0.003)] l_pix: 2.3206e-02 
2024-05-18 07:22:44,448 INFO: [train..][epoch:258, iter: 114,400, lr:(1.000e-04,)] [eta: 1 day, 18:57:53, time (data): 1.095 (0.004)] l_pix: 2.2576e-02 
2024-05-18 07:26:25,432 INFO: [train..][epoch:258, iter: 114,600, lr:(1.000e-04,)] [eta: 1 day, 18:53:57, time (data): 1.106 (0.005)] l_pix: 4.3533e-02 
2024-05-18 07:30:17,014 INFO: [train..][epoch:259, iter: 114,800, lr:(1.000e-04,)] [eta: 1 day, 18:50:13, time (data): 1.090 (0.004)] l_pix: 1.8421e-02 
2024-05-18 07:33:55,536 INFO: [train..][epoch:259, iter: 115,000, lr:(1.000e-04,)] [eta: 1 day, 18:46:13, time (data): 1.101 (0.004)] l_pix: 1.9950e-02 
2024-05-18 07:33:55,537 INFO: Saving models and training states.
2024-05-18 07:33:56,910 INFO: Validation Set5
	 # psnr: 32.8688	Best: 32.9497 @ 110000 iter

2024-05-18 07:37:48,997 INFO: [train..][epoch:260, iter: 115,200, lr:(1.000e-04,)] [eta: 1 day, 18:42:31, time (data): 1.542 (0.452)] l_pix: 3.1032e-02 
2024-05-18 07:41:28,210 INFO: [train..][epoch:260, iter: 115,400, lr:(1.000e-04,)] [eta: 1 day, 18:38:33, time (data): 1.097 (0.004)] l_pix: 1.9111e-02 
2024-05-18 07:45:07,355 INFO: [train..][epoch:260, iter: 115,600, lr:(1.000e-04,)] [eta: 1 day, 18:34:34, time (data): 1.096 (0.004)] l_pix: 1.8932e-02 
2024-05-18 07:48:58,024 INFO: [train..][epoch:261, iter: 115,800, lr:(1.000e-04,)] [eta: 1 day, 18:30:49, time (data): 1.098 (0.003)] l_pix: 3.7467e-02 
2024-05-18 07:52:37,290 INFO: [train..][epoch:261, iter: 116,000, lr:(1.000e-04,)] [eta: 1 day, 18:26:51, time (data): 1.092 (0.004)] l_pix: 2.8427e-02 
2024-05-18 07:56:27,869 INFO: [train..][epoch:262, iter: 116,200, lr:(1.000e-04,)] [eta: 1 day, 18:23:06, time (data): 1.097 (0.003)] l_pix: 2.3805e-02 
2024-05-18 08:00:07,660 INFO: [train..][epoch:262, iter: 116,400, lr:(1.000e-04,)] [eta: 1 day, 18:19:08, time (data): 1.099 (0.003)] l_pix: 2.4730e-02 
2024-05-18 08:03:58,500 INFO: [train..][epoch:263, iter: 116,600, lr:(1.000e-04,)] [eta: 1 day, 18:15:23, time (data): 1.101 (0.004)] l_pix: 3.1541e-02 
2024-05-18 08:07:38,973 INFO: [train..][epoch:263, iter: 116,800, lr:(1.000e-04,)] [eta: 1 day, 18:11:27, time (data): 1.102 (0.005)] l_pix: 4.6527e-02 
2024-05-18 08:11:30,187 INFO: [train..][epoch:264, iter: 117,000, lr:(1.000e-04,)] [eta: 1 day, 18:07:42, time (data): 1.087 (0.003)] l_pix: 1.3560e-02 
2024-05-18 08:15:09,150 INFO: [train..][epoch:264, iter: 117,200, lr:(1.000e-04,)] [eta: 1 day, 18:03:44, time (data): 1.102 (0.003)] l_pix: 1.6996e-02 
2024-05-18 08:19:01,268 INFO: [train..][epoch:265, iter: 117,400, lr:(1.000e-04,)] [eta: 1 day, 18:00:00, time (data): 1.857 (0.765)] l_pix: 1.4964e-02 
2024-05-18 08:22:39,162 INFO: [train..][epoch:265, iter: 117,600, lr:(1.000e-04,)] [eta: 1 day, 17:56:01, time (data): 1.092 (0.003)] l_pix: 2.1860e-02 
2024-05-18 08:26:18,841 INFO: [train..][epoch:265, iter: 117,800, lr:(1.000e-04,)] [eta: 1 day, 17:52:03, time (data): 1.104 (0.003)] l_pix: 1.1408e-02 
2024-05-18 08:30:09,882 INFO: [train..][epoch:266, iter: 118,000, lr:(1.000e-04,)] [eta: 1 day, 17:48:19, time (data): 1.099 (0.004)] l_pix: 2.9521e-02 
2024-05-18 08:33:49,474 INFO: [train..][epoch:266, iter: 118,200, lr:(1.000e-04,)] [eta: 1 day, 17:44:21, time (data): 1.098 (0.003)] l_pix: 2.5609e-02 
2024-05-18 08:37:40,780 INFO: [train..][epoch:267, iter: 118,400, lr:(1.000e-04,)] [eta: 1 day, 17:40:37, time (data): 1.096 (0.005)] l_pix: 1.9789e-02 
2024-05-18 08:41:19,823 INFO: [train..][epoch:267, iter: 118,600, lr:(1.000e-04,)] [eta: 1 day, 17:36:39, time (data): 1.104 (0.003)] l_pix: 1.3586e-02 
2024-05-18 08:45:11,520 INFO: [train..][epoch:268, iter: 118,800, lr:(1.000e-04,)] [eta: 1 day, 17:32:55, time (data): 1.091 (0.003)] l_pix: 2.2677e-02 
2024-05-18 08:48:51,386 INFO: [train..][epoch:268, iter: 119,000, lr:(1.000e-04,)] [eta: 1 day, 17:28:58, time (data): 1.097 (0.003)] l_pix: 1.7173e-02 
2024-05-18 08:52:43,156 INFO: [train..][epoch:269, iter: 119,200, lr:(1.000e-04,)] [eta: 1 day, 17:25:14, time (data): 1.088 (0.003)] l_pix: 2.3580e-02 
2024-05-18 08:56:22,364 INFO: [train..][epoch:269, iter: 119,400, lr:(1.000e-04,)] [eta: 1 day, 17:21:17, time (data): 1.098 (0.003)] l_pix: 2.1707e-02 
2024-05-18 09:00:01,725 INFO: [train..][epoch:269, iter: 119,600, lr:(1.000e-04,)] [eta: 1 day, 17:17:19, time (data): 1.095 (0.003)] l_pix: 3.3367e-02 
2024-05-18 09:03:53,421 INFO: [train..][epoch:270, iter: 119,800, lr:(1.000e-04,)] [eta: 1 day, 17:13:35, time (data): 1.107 (0.003)] l_pix: 1.7243e-02 
2024-05-18 09:07:34,483 INFO: [train..][epoch:270, iter: 120,000, lr:(1.000e-04,)] [eta: 1 day, 17:09:40, time (data): 1.116 (0.005)] l_pix: 2.7815e-02 
2024-05-18 09:07:34,485 INFO: Saving models and training states.
2024-05-18 09:07:35,999 INFO: Validation Set5
	 # psnr: 32.9082	Best: 32.9497 @ 110000 iter

2024-05-18 09:11:27,057 INFO: [train..][epoch:271, iter: 120,200, lr:(1.000e-04,)] [eta: 1 day, 17:05:57, time (data): 1.101 (0.002)] l_pix: 3.3838e-02 
2024-05-18 09:15:07,000 INFO: [train..][epoch:271, iter: 120,400, lr:(1.000e-04,)] [eta: 1 day, 17:02:00, time (data): 1.091 (0.003)] l_pix: 1.9378e-02 
2024-05-18 09:18:57,616 INFO: [train..][epoch:272, iter: 120,600, lr:(1.000e-04,)] [eta: 1 day, 16:58:15, time (data): 1.153 (0.065)] l_pix: 2.2707e-02 
2024-05-18 09:22:38,064 INFO: [train..][epoch:272, iter: 120,800, lr:(1.000e-04,)] [eta: 1 day, 16:54:19, time (data): 1.102 (0.003)] l_pix: 2.0209e-02 
2024-05-18 09:26:29,030 INFO: [train..][epoch:273, iter: 121,000, lr:(1.000e-04,)] [eta: 1 day, 16:50:34, time (data): 1.155 (0.064)] l_pix: 2.5448e-02 
2024-05-18 09:30:08,163 INFO: [train..][epoch:273, iter: 121,200, lr:(1.000e-04,)] [eta: 1 day, 16:46:37, time (data): 1.096 (0.003)] l_pix: 2.3318e-02 
2024-05-18 09:34:00,160 INFO: [train..][epoch:274, iter: 121,400, lr:(1.000e-04,)] [eta: 1 day, 16:42:53, time (data): 1.161 (0.064)] l_pix: 2.5804e-02 
2024-05-18 09:37:38,593 INFO: [train..][epoch:274, iter: 121,600, lr:(1.000e-04,)] [eta: 1 day, 16:38:55, time (data): 1.092 (0.003)] l_pix: 1.9840e-02 
2024-05-18 09:41:18,015 INFO: [train..][epoch:274, iter: 121,800, lr:(1.000e-04,)] [eta: 1 day, 16:34:58, time (data): 1.097 (0.003)] l_pix: 1.8078e-02 
2024-05-18 09:45:08,967 INFO: [train..][epoch:275, iter: 122,000, lr:(1.000e-04,)] [eta: 1 day, 16:31:14, time (data): 1.157 (0.065)] l_pix: 3.8788e-02 
2024-05-18 09:48:48,503 INFO: [train..][epoch:275, iter: 122,200, lr:(1.000e-04,)] [eta: 1 day, 16:27:17, time (data): 1.097 (0.004)] l_pix: 1.6275e-02 
2024-05-18 09:52:39,593 INFO: [train..][epoch:276, iter: 122,400, lr:(1.000e-04,)] [eta: 1 day, 16:23:32, time (data): 1.158 (0.065)] l_pix: 2.7657e-02 
2024-05-18 09:56:19,168 INFO: [train..][epoch:276, iter: 122,600, lr:(1.000e-04,)] [eta: 1 day, 16:19:36, time (data): 1.098 (0.003)] l_pix: 2.0869e-02 
2024-05-18 10:00:09,735 INFO: [train..][epoch:277, iter: 122,800, lr:(1.000e-04,)] [eta: 1 day, 16:15:51, time (data): 1.156 (0.067)] l_pix: 1.6993e-02 
2024-05-18 10:03:49,410 INFO: [train..][epoch:277, iter: 123,000, lr:(1.000e-04,)] [eta: 1 day, 16:11:54, time (data): 1.099 (0.003)] l_pix: 1.6574e-02 
2024-05-18 10:07:41,358 INFO: [train..][epoch:278, iter: 123,200, lr:(1.000e-04,)] [eta: 1 day, 16:08:10, time (data): 1.164 (0.070)] l_pix: 2.1772e-02 
2024-05-18 10:11:21,413 INFO: [train..][epoch:278, iter: 123,400, lr:(1.000e-04,)] [eta: 1 day, 16:04:14, time (data): 1.101 (0.003)] l_pix: 2.5395e-02 
2024-05-18 10:15:13,925 INFO: [train..][epoch:279, iter: 123,600, lr:(1.000e-04,)] [eta: 1 day, 16:00:31, time (data): 1.167 (0.069)] l_pix: 3.2743e-02 
2024-05-18 10:18:53,409 INFO: [train..][epoch:279, iter: 123,800, lr:(1.000e-04,)] [eta: 1 day, 15:56:35, time (data): 1.097 (0.003)] l_pix: 3.4227e-02 
2024-05-18 10:22:34,189 INFO: [train..][epoch:279, iter: 124,000, lr:(1.000e-04,)] [eta: 1 day, 15:52:40, time (data): 1.104 (0.003)] l_pix: 2.5504e-02 
2024-05-18 10:26:24,605 INFO: [train..][epoch:280, iter: 124,200, lr:(1.000e-04,)] [eta: 1 day, 15:48:54, time (data): 1.157 (0.070)] l_pix: 1.9740e-02 
2024-05-18 10:30:04,296 INFO: [train..][epoch:280, iter: 124,400, lr:(1.000e-04,)] [eta: 1 day, 15:44:58, time (data): 1.099 (0.003)] l_pix: 2.3719e-02 
2024-05-18 10:33:55,251 INFO: [train..][epoch:281, iter: 124,600, lr:(1.000e-04,)] [eta: 1 day, 15:41:13, time (data): 1.160 (0.069)] l_pix: 2.4892e-02 
2024-05-18 10:37:34,821 INFO: [train..][epoch:281, iter: 124,800, lr:(1.000e-04,)] [eta: 1 day, 15:37:17, time (data): 1.098 (0.003)] l_pix: 2.3194e-02 
2024-05-18 10:41:26,357 INFO: [train..][epoch:282, iter: 125,000, lr:(1.000e-04,)] [eta: 1 day, 15:33:33, time (data): 1.164 (0.071)] l_pix: 2.7149e-02 
2024-05-18 10:41:26,358 INFO: Saving models and training states.
2024-05-18 10:41:27,797 INFO: Validation Set5
	 # psnr: 32.8977	Best: 32.9497 @ 110000 iter

2024-05-18 10:45:07,140 INFO: [train..][epoch:282, iter: 125,200, lr:(5.000e-05,)] [eta: 1 day, 15:29:38, time (data): 1.097 (0.003)] l_pix: 3.2542e-02 
2024-05-18 10:48:58,967 INFO: [train..][epoch:283, iter: 125,400, lr:(5.000e-05,)] [eta: 1 day, 15:25:54, time (data): 1.167 (0.073)] l_pix: 1.2593e-02 
2024-05-18 10:52:38,608 INFO: [train..][epoch:283, iter: 125,600, lr:(5.000e-05,)] [eta: 1 day, 15:21:58, time (data): 1.099 (0.003)] l_pix: 3.2556e-02 
2024-05-18 10:56:18,284 INFO: [train..][epoch:283, iter: 125,800, lr:(5.000e-05,)] [eta: 1 day, 15:18:02, time (data): 1.098 (0.003)] l_pix: 2.1314e-02 
2024-05-18 11:00:09,009 INFO: [train..][epoch:284, iter: 126,000, lr:(5.000e-05,)] [eta: 1 day, 15:14:17, time (data): 1.092 (0.003)] l_pix: 2.4198e-02 
2024-05-18 11:03:49,240 INFO: [train..][epoch:284, iter: 126,200, lr:(5.000e-05,)] [eta: 1 day, 15:10:22, time (data): 1.101 (0.003)] l_pix: 3.4634e-02 
2024-05-18 11:07:39,584 INFO: [train..][epoch:285, iter: 126,400, lr:(5.000e-05,)] [eta: 1 day, 15:06:37, time (data): 1.160 (0.072)] l_pix: 4.0013e-02 
2024-05-18 11:11:20,033 INFO: [train..][epoch:285, iter: 126,600, lr:(5.000e-05,)] [eta: 1 day, 15:02:42, time (data): 1.103 (0.003)] l_pix: 2.7648e-02 
2024-05-18 11:15:10,711 INFO: [train..][epoch:286, iter: 126,800, lr:(5.000e-05,)] [eta: 1 day, 14:58:57, time (data): 1.163 (0.075)] l_pix: 9.5243e-03 
2024-05-18 11:18:50,543 INFO: [train..][epoch:286, iter: 127,000, lr:(5.000e-05,)] [eta: 1 day, 14:55:01, time (data): 1.100 (0.003)] l_pix: 2.4462e-02 
2024-05-18 11:22:42,749 INFO: [train..][epoch:287, iter: 127,200, lr:(5.000e-05,)] [eta: 1 day, 14:51:17, time (data): 1.172 (0.078)] l_pix: 3.6398e-02 
2024-05-18 11:26:21,472 INFO: [train..][epoch:287, iter: 127,400, lr:(5.000e-05,)] [eta: 1 day, 14:47:21, time (data): 1.094 (0.003)] l_pix: 2.5369e-02 
2024-05-18 11:30:12,737 INFO: [train..][epoch:288, iter: 127,600, lr:(5.000e-05,)] [eta: 1 day, 14:43:36, time (data): 1.169 (0.076)] l_pix: 1.8993e-02 
2024-05-18 11:33:51,899 INFO: [train..][epoch:288, iter: 127,800, lr:(5.000e-05,)] [eta: 1 day, 14:39:40, time (data): 1.098 (0.004)] l_pix: 1.4346e-02 
2024-05-18 11:37:31,453 INFO: [train..][epoch:288, iter: 128,000, lr:(5.000e-05,)] [eta: 1 day, 14:35:45, time (data): 1.097 (0.004)] l_pix: 2.1092e-02 
2024-05-18 11:41:21,586 INFO: [train..][epoch:289, iter: 128,200, lr:(5.000e-05,)] [eta: 1 day, 14:31:59, time (data): 1.089 (0.003)] l_pix: 2.1631e-02 
2024-05-18 11:45:02,325 INFO: [train..][epoch:289, iter: 128,400, lr:(5.000e-05,)] [eta: 1 day, 14:28:05, time (data): 1.104 (0.004)] l_pix: 2.1507e-02 
2024-05-18 11:48:52,917 INFO: [train..][epoch:290, iter: 128,600, lr:(5.000e-05,)] [eta: 1 day, 14:24:20, time (data): 1.166 (0.079)] l_pix: 1.6145e-02 
2024-05-18 11:52:31,847 INFO: [train..][epoch:290, iter: 128,800, lr:(5.000e-05,)] [eta: 1 day, 14:20:24, time (data): 1.096 (0.003)] l_pix: 1.6720e-02 
2024-05-18 11:56:22,888 INFO: [train..][epoch:291, iter: 129,000, lr:(5.000e-05,)] [eta: 1 day, 14:16:39, time (data): 1.170 (0.079)] l_pix: 1.7058e-02 
2024-05-18 12:00:02,118 INFO: [train..][epoch:291, iter: 129,200, lr:(5.000e-05,)] [eta: 1 day, 14:12:43, time (data): 1.097 (0.003)] l_pix: 2.7496e-02 
2024-05-18 12:03:53,664 INFO: [train..][epoch:292, iter: 129,400, lr:(5.000e-05,)] [eta: 1 day, 14:08:59, time (data): 1.174 (0.081)] l_pix: 1.6730e-02 
2024-05-18 12:07:33,288 INFO: [train..][epoch:292, iter: 129,600, lr:(5.000e-05,)] [eta: 1 day, 14:05:04, time (data): 1.100 (0.003)] l_pix: 2.5097e-02 
2024-05-18 12:11:24,875 INFO: [train..][epoch:293, iter: 129,800, lr:(5.000e-05,)] [eta: 1 day, 14:01:19, time (data): 1.176 (0.082)] l_pix: 2.0471e-02 
2024-05-18 12:15:02,737 INFO: [train..][epoch:293, iter: 130,000, lr:(5.000e-05,)] [eta: 1 day, 13:57:22, time (data): 1.090 (0.004)] l_pix: 2.4452e-02 
2024-05-18 12:15:02,738 INFO: Saving models and training states.
2024-05-18 12:15:04,210 INFO: Validation Set5
	 # psnr: 32.8928	Best: 32.9497 @ 110000 iter

2024-05-18 12:18:43,536 INFO: [train..][epoch:293, iter: 130,200, lr:(5.000e-05,)] [eta: 1 day, 13:53:28, time (data): 1.097 (0.003)] l_pix: 1.3408e-02 
2024-05-18 12:22:33,893 INFO: [train..][epoch:294, iter: 130,400, lr:(5.000e-05,)] [eta: 1 day, 13:49:43, time (data): 1.090 (0.003)] l_pix: 1.9776e-02 
2024-05-18 12:26:12,622 INFO: [train..][epoch:294, iter: 130,600, lr:(5.000e-05,)] [eta: 1 day, 13:45:47, time (data): 1.093 (0.003)] l_pix: 3.0710e-02 
2024-05-18 12:30:02,452 INFO: [train..][epoch:295, iter: 130,800, lr:(5.000e-05,)] [eta: 1 day, 13:42:01, time (data): 1.168 (0.082)] l_pix: 2.3805e-02 
2024-05-18 12:33:40,960 INFO: [train..][epoch:295, iter: 131,000, lr:(5.000e-05,)] [eta: 1 day, 13:38:05, time (data): 1.094 (0.003)] l_pix: 3.6908e-02 
2024-05-18 12:37:32,339 INFO: [train..][epoch:296, iter: 131,200, lr:(5.000e-05,)] [eta: 1 day, 13:34:21, time (data): 1.175 (0.085)] l_pix: 3.6621e-02 
2024-05-18 12:41:10,867 INFO: [train..][epoch:296, iter: 131,400, lr:(5.000e-05,)] [eta: 1 day, 13:30:25, time (data): 1.093 (0.003)] l_pix: 2.3117e-02 
2024-05-18 12:45:01,580 INFO: [train..][epoch:297, iter: 131,600, lr:(5.000e-05,)] [eta: 1 day, 13:26:40, time (data): 1.176 (0.085)] l_pix: 2.6983e-02 
2024-05-18 12:48:39,594 INFO: [train..][epoch:297, iter: 131,800, lr:(5.000e-05,)] [eta: 1 day, 13:22:43, time (data): 1.090 (0.003)] l_pix: 2.5587e-02 
2024-05-18 12:52:18,487 INFO: [train..][epoch:297, iter: 132,000, lr:(5.000e-05,)] [eta: 1 day, 13:18:48, time (data): 1.095 (0.003)] l_pix: 1.0532e-02 
2024-05-18 12:56:09,071 INFO: [train..][epoch:298, iter: 132,200, lr:(5.000e-05,)] [eta: 1 day, 13:15:03, time (data): 1.094 (0.003)] l_pix: 3.9154e-02 
2024-05-18 12:59:48,315 INFO: [train..][epoch:298, iter: 132,400, lr:(5.000e-05,)] [eta: 1 day, 13:11:08, time (data): 1.095 (0.003)] l_pix: 2.1640e-02 
2024-05-18 13:03:38,431 INFO: [train..][epoch:299, iter: 132,600, lr:(5.000e-05,)] [eta: 1 day, 13:07:22, time (data): 1.088 (0.003)] l_pix: 1.5309e-02 
2024-05-18 13:07:17,091 INFO: [train..][epoch:299, iter: 132,800, lr:(5.000e-05,)] [eta: 1 day, 13:03:26, time (data): 1.093 (0.003)] l_pix: 2.1741e-02 
2024-05-18 13:11:07,365 INFO: [train..][epoch:300, iter: 133,000, lr:(5.000e-05,)] [eta: 1 day, 12:59:41, time (data): 1.177 (0.090)] l_pix: 3.6831e-02 
2024-05-18 13:14:46,730 INFO: [train..][epoch:300, iter: 133,200, lr:(5.000e-05,)] [eta: 1 day, 12:55:46, time (data): 1.097 (0.003)] l_pix: 2.5887e-02 
2024-05-18 13:18:37,114 INFO: [train..][epoch:301, iter: 133,400, lr:(5.000e-05,)] [eta: 1 day, 12:52:01, time (data): 1.179 (0.091)] l_pix: 2.1329e-02 
2024-05-18 13:22:15,489 INFO: [train..][epoch:301, iter: 133,600, lr:(5.000e-05,)] [eta: 1 day, 12:48:05, time (data): 1.094 (0.003)] l_pix: 1.9162e-02 
2024-05-18 13:26:07,068 INFO: [train..][epoch:302, iter: 133,800, lr:(5.000e-05,)] [eta: 1 day, 12:44:21, time (data): 1.186 (0.092)] l_pix: 1.6017e-02 
2024-05-18 13:29:45,406 INFO: [train..][epoch:302, iter: 134,000, lr:(5.000e-05,)] [eta: 1 day, 12:40:25, time (data): 1.092 (0.004)] l_pix: 2.4444e-02 
2024-05-18 13:33:24,550 INFO: [train..][epoch:302, iter: 134,200, lr:(5.000e-05,)] [eta: 1 day, 12:36:30, time (data): 1.096 (0.003)] l_pix: 3.3934e-02 
2024-05-18 13:37:14,874 INFO: [train..][epoch:303, iter: 134,400, lr:(5.000e-05,)] [eta: 1 day, 12:32:45, time (data): 1.092 (0.003)] l_pix: 1.7295e-02 
2024-05-18 13:40:54,108 INFO: [train..][epoch:303, iter: 134,600, lr:(5.000e-05,)] [eta: 1 day, 12:28:50, time (data): 1.096 (0.004)] l_pix: 1.6218e-02 
2024-05-18 13:44:44,177 INFO: [train..][epoch:304, iter: 134,800, lr:(5.000e-05,)] [eta: 1 day, 12:25:05, time (data): 1.181 (0.095)] l_pix: 1.6564e-02 
2024-05-18 13:48:23,358 INFO: [train..][epoch:304, iter: 135,000, lr:(5.000e-05,)] [eta: 1 day, 12:21:10, time (data): 1.097 (0.003)] l_pix: 2.6876e-02 
2024-05-18 13:48:23,358 INFO: Saving models and training states.
2024-05-18 13:48:24,724 INFO: Validation Set5
	 # psnr: 32.9149	Best: 32.9497 @ 110000 iter

2024-05-18 13:52:15,093 INFO: [train..][epoch:305, iter: 135,200, lr:(5.000e-05,)] [eta: 1 day, 12:17:26, time (data): 1.184 (0.097)] l_pix: 2.1727e-02 
2024-05-18 13:55:53,130 INFO: [train..][epoch:305, iter: 135,400, lr:(5.000e-05,)] [eta: 1 day, 12:13:30, time (data): 1.093 (0.003)] l_pix: 2.6595e-02 
2024-05-18 13:59:44,676 INFO: [train..][epoch:306, iter: 135,600, lr:(5.000e-05,)] [eta: 1 day, 12:09:46, time (data): 1.193 (0.101)] l_pix: 3.3370e-02 
2024-05-18 14:03:23,125 INFO: [train..][epoch:306, iter: 135,800, lr:(5.000e-05,)] [eta: 1 day, 12:05:50, time (data): 1.094 (0.003)] l_pix: 4.3495e-02 
2024-05-18 14:07:01,972 INFO: [train..][epoch:306, iter: 136,000, lr:(5.000e-05,)] [eta: 1 day, 12:01:56, time (data): 1.094 (0.003)] l_pix: 2.3797e-02 
2024-05-18 14:10:52,605 INFO: [train..][epoch:307, iter: 136,200, lr:(5.000e-05,)] [eta: 1 day, 11:58:11, time (data): 1.093 (0.003)] l_pix: 1.7961e-02 
2024-05-18 14:14:31,134 INFO: [train..][epoch:307, iter: 136,400, lr:(5.000e-05,)] [eta: 1 day, 11:54:15, time (data): 1.092 (0.003)] l_pix: 2.6581e-02 
2024-05-18 14:18:21,184 INFO: [train..][epoch:308, iter: 136,600, lr:(5.000e-05,)] [eta: 1 day, 11:50:30, time (data): 1.090 (0.004)] l_pix: 2.7949e-02 
2024-05-18 14:22:00,504 INFO: [train..][epoch:308, iter: 136,800, lr:(5.000e-05,)] [eta: 1 day, 11:46:36, time (data): 1.099 (0.003)] l_pix: 2.7608e-02 
2024-05-18 14:25:50,929 INFO: [train..][epoch:309, iter: 137,000, lr:(5.000e-05,)] [eta: 1 day, 11:42:50, time (data): 1.192 (0.106)] l_pix: 2.0975e-02 
2024-05-18 14:29:29,470 INFO: [train..][epoch:309, iter: 137,200, lr:(5.000e-05,)] [eta: 1 day, 11:38:55, time (data): 1.094 (0.003)] l_pix: 2.0239e-02 
2024-05-18 14:33:20,479 INFO: [train..][epoch:310, iter: 137,400, lr:(5.000e-05,)] [eta: 1 day, 11:35:11, time (data): 1.195 (0.107)] l_pix: 2.3930e-02 
2024-05-18 14:36:59,008 INFO: [train..][epoch:310, iter: 137,600, lr:(5.000e-05,)] [eta: 1 day, 11:31:16, time (data): 1.094 (0.003)] l_pix: 2.4808e-02 
2024-05-18 14:40:49,627 INFO: [train..][epoch:311, iter: 137,800, lr:(5.000e-05,)] [eta: 1 day, 11:27:31, time (data): 1.198 (0.107)] l_pix: 2.0043e-02 
2024-05-18 14:44:28,330 INFO: [train..][epoch:311, iter: 138,000, lr:(5.000e-05,)] [eta: 1 day, 11:23:36, time (data): 1.096 (0.003)] l_pix: 1.8647e-02 
2024-05-18 14:48:07,145 INFO: [train..][epoch:311, iter: 138,200, lr:(5.000e-05,)] [eta: 1 day, 11:19:41, time (data): 1.094 (0.003)] l_pix: 1.5628e-02 
2024-05-18 14:51:57,549 INFO: [train..][epoch:312, iter: 138,400, lr:(5.000e-05,)] [eta: 1 day, 11:15:56, time (data): 1.094 (0.003)] l_pix: 2.2486e-02 
2024-05-18 14:55:37,078 INFO: [train..][epoch:312, iter: 138,600, lr:(5.000e-05,)] [eta: 1 day, 11:12:02, time (data): 1.097 (0.003)] l_pix: 2.1888e-02 
2024-05-18 14:59:26,888 INFO: [train..][epoch:313, iter: 138,800, lr:(5.000e-05,)] [eta: 1 day, 11:08:17, time (data): 1.088 (0.004)] l_pix: 2.8783e-02 
2024-05-18 15:03:06,060 INFO: [train..][epoch:313, iter: 139,000, lr:(5.000e-05,)] [eta: 1 day, 11:04:22, time (data): 1.097 (0.003)] l_pix: 2.8153e-02 
2024-05-18 15:06:56,867 INFO: [train..][epoch:314, iter: 139,200, lr:(5.000e-05,)] [eta: 1 day, 11:00:38, time (data): 1.201 (0.117)] l_pix: 1.9254e-02 
2024-05-18 15:10:35,105 INFO: [train..][epoch:314, iter: 139,400, lr:(5.000e-05,)] [eta: 1 day, 10:56:43, time (data): 1.091 (0.003)] l_pix: 1.2809e-02 
2024-05-18 15:14:25,833 INFO: [train..][epoch:315, iter: 139,600, lr:(5.000e-05,)] [eta: 1 day, 10:52:58, time (data): 1.207 (0.119)] l_pix: 1.5409e-02 
2024-05-18 15:18:04,423 INFO: [train..][epoch:315, iter: 139,800, lr:(5.000e-05,)] [eta: 1 day, 10:49:03, time (data): 1.094 (0.003)] l_pix: 2.1778e-02 
2024-05-18 15:21:54,875 INFO: [train..][epoch:316, iter: 140,000, lr:(5.000e-05,)] [eta: 1 day, 10:45:18, time (data): 1.207 (0.118)] l_pix: 2.7671e-02 
2024-05-18 15:21:54,876 INFO: Saving models and training states.
2024-05-18 15:21:56,225 INFO: Validation Set5
	 # psnr: 32.9492	Best: 32.9497 @ 110000 iter

2024-05-18 15:25:34,398 INFO: [train..][epoch:316, iter: 140,200, lr:(5.000e-05,)] [eta: 1 day, 10:41:24, time (data): 1.093 (0.003)] l_pix: 1.9841e-02 
2024-05-18 15:29:13,808 INFO: [train..][epoch:316, iter: 140,400, lr:(5.000e-05,)] [eta: 1 day, 10:37:31, time (data): 1.095 (0.003)] l_pix: 1.9007e-02 
2024-05-18 15:33:03,651 INFO: [train..][epoch:317, iter: 140,600, lr:(5.000e-05,)] [eta: 1 day, 10:33:45, time (data): 1.089 (0.003)] l_pix: 2.5511e-02 
2024-05-18 15:36:42,921 INFO: [train..][epoch:317, iter: 140,800, lr:(5.000e-05,)] [eta: 1 day, 10:29:51, time (data): 1.099 (0.003)] l_pix: 2.4665e-02 
2024-05-18 15:40:33,294 INFO: [train..][epoch:318, iter: 141,000, lr:(5.000e-05,)] [eta: 1 day, 10:26:06, time (data): 1.089 (0.004)] l_pix: 2.8344e-02 
2024-05-18 15:44:12,315 INFO: [train..][epoch:318, iter: 141,200, lr:(5.000e-05,)] [eta: 1 day, 10:22:12, time (data): 1.096 (0.004)] l_pix: 2.9964e-02 
2024-05-18 15:48:03,452 INFO: [train..][epoch:319, iter: 141,400, lr:(5.000e-05,)] [eta: 1 day, 10:18:27, time (data): 1.217 (0.130)] l_pix: 2.9306e-02 
2024-05-18 15:51:42,688 INFO: [train..][epoch:319, iter: 141,600, lr:(5.000e-05,)] [eta: 1 day, 10:14:34, time (data): 1.095 (0.003)] l_pix: 2.0714e-02 
2024-05-18 15:55:33,774 INFO: [train..][epoch:320, iter: 141,800, lr:(5.000e-05,)] [eta: 1 day, 10:10:49, time (data): 1.225 (0.138)] l_pix: 2.9297e-02 
2024-05-18 15:59:12,751 INFO: [train..][epoch:320, iter: 142,000, lr:(5.000e-05,)] [eta: 1 day, 10:06:55, time (data): 1.098 (0.003)] l_pix: 3.1065e-02 
2024-05-18 16:02:51,742 INFO: [train..][epoch:320, iter: 142,200, lr:(5.000e-05,)] [eta: 1 day, 10:03:01, time (data): 1.095 (0.003)] l_pix: 4.1203e-02 
2024-05-18 16:06:41,736 INFO: [train..][epoch:321, iter: 142,400, lr:(5.000e-05,)] [eta: 1 day, 9:59:16, time (data): 1.091 (0.003)] l_pix: 1.4032e-02 
2024-05-18 16:10:21,473 INFO: [train..][epoch:321, iter: 142,600, lr:(5.000e-05,)] [eta: 1 day, 9:55:22, time (data): 1.099 (0.003)] l_pix: 2.4465e-02 
2024-05-18 16:14:12,714 INFO: [train..][epoch:322, iter: 142,800, lr:(5.000e-05,)] [eta: 1 day, 9:51:38, time (data): 1.090 (0.004)] l_pix: 3.1138e-02 
2024-05-18 16:17:52,239 INFO: [train..][epoch:322, iter: 143,000, lr:(5.000e-05,)] [eta: 1 day, 9:47:45, time (data): 1.100 (0.003)] l_pix: 2.5265e-02 
2024-05-18 16:21:43,595 INFO: [train..][epoch:323, iter: 143,200, lr:(5.000e-05,)] [eta: 1 day, 9:44:00, time (data): 1.091 (0.003)] l_pix: 2.6226e-02 
2024-05-18 16:25:22,389 INFO: [train..][epoch:323, iter: 143,400, lr:(5.000e-05,)] [eta: 1 day, 9:40:06, time (data): 1.094 (0.003)] l_pix: 3.5179e-02 
2024-05-18 16:29:13,314 INFO: [train..][epoch:324, iter: 143,600, lr:(5.000e-05,)] [eta: 1 day, 9:36:21, time (data): 1.234 (0.147)] l_pix: 1.6336e-02 
2024-05-18 16:32:52,112 INFO: [train..][epoch:324, iter: 143,800, lr:(5.000e-05,)] [eta: 1 day, 9:32:28, time (data): 1.094 (0.003)] l_pix: 2.5401e-02 
2024-05-18 16:36:42,651 INFO: [train..][epoch:325, iter: 144,000, lr:(5.000e-05,)] [eta: 1 day, 9:28:43, time (data): 1.235 (0.146)] l_pix: 3.3540e-02 
2024-05-18 16:40:21,428 INFO: [train..][epoch:325, iter: 144,200, lr:(5.000e-05,)] [eta: 1 day, 9:24:49, time (data): 1.098 (0.003)] l_pix: 1.9392e-02 
2024-05-18 16:44:00,586 INFO: [train..][epoch:325, iter: 144,400, lr:(5.000e-05,)] [eta: 1 day, 9:20:55, time (data): 1.096 (0.003)] l_pix: 1.7995e-02 
2024-05-18 16:47:50,579 INFO: [train..][epoch:326, iter: 144,600, lr:(5.000e-05,)] [eta: 1 day, 9:17:10, time (data): 1.093 (0.004)] l_pix: 2.6119e-02 
2024-05-18 16:51:30,465 INFO: [train..][epoch:326, iter: 144,800, lr:(5.000e-05,)] [eta: 1 day, 9:13:17, time (data): 1.100 (0.003)] l_pix: 1.9563e-02 
2024-05-18 16:55:21,892 INFO: [train..][epoch:327, iter: 145,000, lr:(5.000e-05,)] [eta: 1 day, 9:09:33, time (data): 1.100 (0.003)] l_pix: 3.3713e-02 
2024-05-18 16:55:21,893 INFO: Saving models and training states.
2024-05-18 16:55:23,327 INFO: Validation Set5
	 # psnr: 32.9645	Best: 32.9645 @ 145000 iter

2024-05-18 16:59:03,531 INFO: [train..][epoch:327, iter: 145,200, lr:(5.000e-05,)] [eta: 1 day, 9:05:41, time (data): 1.100 (0.004)] l_pix: 3.5702e-02 
2024-05-18 17:02:54,928 INFO: [train..][epoch:328, iter: 145,400, lr:(5.000e-05,)] [eta: 1 day, 9:01:57, time (data): 1.090 (0.004)] l_pix: 3.1145e-02 
2024-05-18 17:06:33,730 INFO: [train..][epoch:328, iter: 145,600, lr:(5.000e-05,)] [eta: 1 day, 8:58:03, time (data): 1.093 (0.003)] l_pix: 1.6241e-02 
2024-05-18 17:10:25,064 INFO: [train..][epoch:329, iter: 145,800, lr:(5.000e-05,)] [eta: 1 day, 8:54:19, time (data): 1.252 (0.167)] l_pix: 2.7579e-02 
2024-05-18 17:14:04,127 INFO: [train..][epoch:329, iter: 146,000, lr:(5.000e-05,)] [eta: 1 day, 8:50:25, time (data): 1.094 (0.003)] l_pix: 2.2934e-02 
2024-05-18 17:17:55,219 INFO: [train..][epoch:330, iter: 146,200, lr:(5.000e-05,)] [eta: 1 day, 8:46:41, time (data): 1.260 (0.168)] l_pix: 2.2562e-02 
2024-05-18 17:21:34,150 INFO: [train..][epoch:330, iter: 146,400, lr:(5.000e-05,)] [eta: 1 day, 8:42:47, time (data): 1.103 (0.003)] l_pix: 1.9583e-02 
2024-05-18 17:25:13,659 INFO: [train..][epoch:330, iter: 146,600, lr:(5.000e-05,)] [eta: 1 day, 8:38:54, time (data): 1.093 (0.003)] l_pix: 2.4715e-02 
2024-05-18 17:29:03,699 INFO: [train..][epoch:331, iter: 146,800, lr:(5.000e-05,)] [eta: 1 day, 8:35:09, time (data): 1.087 (0.003)] l_pix: 3.1058e-02 
2024-05-18 17:32:42,785 INFO: [train..][epoch:331, iter: 147,000, lr:(5.000e-05,)] [eta: 1 day, 8:31:16, time (data): 1.099 (0.003)] l_pix: 2.7900e-02 
2024-05-18 17:36:33,717 INFO: [train..][epoch:332, iter: 147,200, lr:(5.000e-05,)] [eta: 1 day, 8:27:31, time (data): 1.091 (0.003)] l_pix: 2.4304e-02 
2024-05-18 17:40:12,308 INFO: [train..][epoch:332, iter: 147,400, lr:(5.000e-05,)] [eta: 1 day, 8:23:38, time (data): 1.092 (0.003)] l_pix: 2.2302e-02 
2024-05-18 17:44:02,870 INFO: [train..][epoch:333, iter: 147,600, lr:(5.000e-05,)] [eta: 1 day, 8:19:52, time (data): 1.090 (0.004)] l_pix: 2.0669e-02 
2024-05-18 17:47:42,238 INFO: [train..][epoch:333, iter: 147,800, lr:(5.000e-05,)] [eta: 1 day, 8:16:00, time (data): 1.097 (0.004)] l_pix: 2.2250e-02 
2024-05-18 17:51:32,852 INFO: [train..][epoch:334, iter: 148,000, lr:(5.000e-05,)] [eta: 1 day, 8:12:15, time (data): 1.279 (0.192)] l_pix: 2.0550e-02 
2024-05-18 17:55:14,800 INFO: [train..][epoch:334, iter: 148,200, lr:(5.000e-05,)] [eta: 1 day, 8:08:24, time (data): 1.118 (0.003)] l_pix: 3.0037e-02 
2024-05-18 17:58:54,162 INFO: [train..][epoch:334, iter: 148,400, lr:(5.000e-05,)] [eta: 1 day, 8:04:31, time (data): 1.094 (0.003)] l_pix: 1.5083e-02 
2024-05-18 18:02:44,055 INFO: [train..][epoch:335, iter: 148,600, lr:(5.000e-05,)] [eta: 1 day, 8:00:45, time (data): 1.091 (0.003)] l_pix: 1.1414e-02 
2024-05-18 18:06:24,029 INFO: [train..][epoch:335, iter: 148,800, lr:(5.000e-05,)] [eta: 1 day, 7:56:53, time (data): 1.099 (0.003)] l_pix: 2.4427e-02 
2024-05-18 18:10:14,428 INFO: [train..][epoch:336, iter: 149,000, lr:(5.000e-05,)] [eta: 1 day, 7:53:08, time (data): 1.091 (0.003)] l_pix: 2.9037e-02 
2024-05-18 18:13:53,843 INFO: [train..][epoch:336, iter: 149,200, lr:(5.000e-05,)] [eta: 1 day, 7:49:15, time (data): 1.100 (0.004)] l_pix: 2.7111e-02 
2024-05-18 18:17:44,810 INFO: [train..][epoch:337, iter: 149,400, lr:(5.000e-05,)] [eta: 1 day, 7:45:30, time (data): 1.090 (0.003)] l_pix: 2.2122e-02 
2024-05-18 18:21:23,433 INFO: [train..][epoch:337, iter: 149,600, lr:(5.000e-05,)] [eta: 1 day, 7:41:37, time (data): 1.093 (0.003)] l_pix: 1.9807e-02 
2024-05-18 18:25:14,335 INFO: [train..][epoch:338, iter: 149,800, lr:(5.000e-05,)] [eta: 1 day, 7:37:52, time (data): 1.088 (0.003)] l_pix: 2.5060e-02 
2024-05-18 18:28:53,855 INFO: [train..][epoch:338, iter: 150,000, lr:(5.000e-05,)] [eta: 1 day, 7:34:00, time (data): 1.096 (0.003)] l_pix: 2.4174e-02 
2024-05-18 18:28:53,857 INFO: Saving models and training states.
2024-05-18 18:28:55,243 INFO: Validation Set5
	 # psnr: 32.9413	Best: 32.9645 @ 145000 iter

2024-05-18 18:32:46,555 INFO: [train..][epoch:339, iter: 150,200, lr:(5.000e-05,)] [eta: 1 day, 7:30:16, time (data): 1.319 (0.232)] l_pix: 2.3547e-02 
2024-05-18 18:36:25,597 INFO: [train..][epoch:339, iter: 150,400, lr:(5.000e-05,)] [eta: 1 day, 7:26:23, time (data): 1.099 (0.003)] l_pix: 2.1410e-02 
2024-05-18 18:40:05,528 INFO: [train..][epoch:339, iter: 150,600, lr:(5.000e-05,)] [eta: 1 day, 7:22:31, time (data): 1.099 (0.004)] l_pix: 2.6014e-02 
2024-05-18 18:43:55,907 INFO: [train..][epoch:340, iter: 150,800, lr:(5.000e-05,)] [eta: 1 day, 7:18:46, time (data): 1.089 (0.003)] l_pix: 2.0319e-02 
2024-05-18 18:47:35,426 INFO: [train..][epoch:340, iter: 151,000, lr:(5.000e-05,)] [eta: 1 day, 7:14:54, time (data): 1.102 (0.004)] l_pix: 2.5000e-02 
2024-05-18 18:51:26,149 INFO: [train..][epoch:341, iter: 151,200, lr:(5.000e-05,)] [eta: 1 day, 7:11:09, time (data): 1.091 (0.003)] l_pix: 1.4975e-02 
2024-05-18 18:55:05,084 INFO: [train..][epoch:341, iter: 151,400, lr:(5.000e-05,)] [eta: 1 day, 7:07:16, time (data): 1.097 (0.003)] l_pix: 9.7312e-03 
2024-05-18 18:58:55,790 INFO: [train..][epoch:342, iter: 151,600, lr:(5.000e-05,)] [eta: 1 day, 7:03:31, time (data): 1.090 (0.004)] l_pix: 2.3651e-02 
2024-05-18 19:02:34,763 INFO: [train..][epoch:342, iter: 151,800, lr:(5.000e-05,)] [eta: 1 day, 6:59:38, time (data): 1.093 (0.003)] l_pix: 2.5186e-02 
2024-05-18 19:06:25,748 INFO: [train..][epoch:343, iter: 152,000, lr:(5.000e-05,)] [eta: 1 day, 6:55:54, time (data): 1.090 (0.003)] l_pix: 2.1515e-02 
2024-05-18 19:10:05,448 INFO: [train..][epoch:343, iter: 152,200, lr:(5.000e-05,)] [eta: 1 day, 6:52:01, time (data): 1.100 (0.004)] l_pix: 2.2837e-02 
2024-05-18 19:13:57,463 INFO: [train..][epoch:344, iter: 152,400, lr:(5.000e-05,)] [eta: 1 day, 6:48:17, time (data): 1.391 (0.301)] l_pix: 2.0476e-02 
2024-05-18 19:17:35,898 INFO: [train..][epoch:344, iter: 152,600, lr:(5.000e-05,)] [eta: 1 day, 6:44:24, time (data): 1.097 (0.003)] l_pix: 1.2992e-02 
2024-05-18 19:21:15,893 INFO: [train..][epoch:344, iter: 152,800, lr:(5.000e-05,)] [eta: 1 day, 6:40:32, time (data): 1.098 (0.003)] l_pix: 2.4792e-02 
2024-05-18 19:25:06,526 INFO: [train..][epoch:345, iter: 153,000, lr:(5.000e-05,)] [eta: 1 day, 6:36:47, time (data): 1.095 (0.003)] l_pix: 1.9007e-02 
2024-05-18 19:28:45,660 INFO: [train..][epoch:345, iter: 153,200, lr:(5.000e-05,)] [eta: 1 day, 6:32:55, time (data): 1.101 (0.003)] l_pix: 2.8865e-02 
2024-05-18 19:32:36,591 INFO: [train..][epoch:346, iter: 153,400, lr:(5.000e-05,)] [eta: 1 day, 6:29:10, time (data): 1.088 (0.003)] l_pix: 1.8472e-02 
2024-05-18 19:36:16,118 INFO: [train..][epoch:346, iter: 153,600, lr:(5.000e-05,)] [eta: 1 day, 6:25:18, time (data): 1.097 (0.004)] l_pix: 2.1889e-02 
2024-05-18 19:40:07,629 INFO: [train..][epoch:347, iter: 153,800, lr:(5.000e-05,)] [eta: 1 day, 6:21:34, time (data): 1.093 (0.004)] l_pix: 1.4677e-02 
2024-05-18 19:43:46,691 INFO: [train..][epoch:347, iter: 154,000, lr:(5.000e-05,)] [eta: 1 day, 6:17:41, time (data): 1.096 (0.003)] l_pix: 2.3946e-02 
2024-05-18 19:47:37,446 INFO: [train..][epoch:348, iter: 154,200, lr:(5.000e-05,)] [eta: 1 day, 6:13:56, time (data): 1.090 (0.003)] l_pix: 2.4958e-02 
2024-05-18 19:51:16,967 INFO: [train..][epoch:348, iter: 154,400, lr:(5.000e-05,)] [eta: 1 day, 6:10:04, time (data): 1.103 (0.003)] l_pix: 2.0241e-02 
2024-05-18 19:54:56,567 INFO: [train..][epoch:348, iter: 154,600, lr:(5.000e-05,)] [eta: 1 day, 6:06:12, time (data): 1.098 (0.003)] l_pix: 2.1562e-02 
2024-05-18 19:58:47,354 INFO: [train..][epoch:349, iter: 154,800, lr:(5.000e-05,)] [eta: 1 day, 6:02:27, time (data): 1.096 (0.003)] l_pix: 1.4932e-02 
2024-05-18 20:02:26,939 INFO: [train..][epoch:349, iter: 155,000, lr:(5.000e-05,)] [eta: 1 day, 5:58:35, time (data): 1.106 (0.003)] l_pix: 2.6234e-02 
2024-05-18 20:02:26,940 INFO: Saving models and training states.
2024-05-18 20:02:28,304 INFO: Validation Set5
	 # psnr: 32.9411	Best: 32.9645 @ 145000 iter

2024-05-18 20:06:19,228 INFO: [train..][epoch:350, iter: 155,200, lr:(5.000e-05,)] [eta: 1 day, 5:54:51, time (data): 1.096 (0.004)] l_pix: 3.2412e-02 
2024-05-18 20:09:58,034 INFO: [train..][epoch:350, iter: 155,400, lr:(5.000e-05,)] [eta: 1 day, 5:50:59, time (data): 1.096 (0.003)] l_pix: 1.6643e-02 
2024-05-18 20:13:49,561 INFO: [train..][epoch:351, iter: 155,600, lr:(5.000e-05,)] [eta: 1 day, 5:47:15, time (data): 1.087 (0.003)] l_pix: 1.2601e-02 
2024-05-18 20:17:28,408 INFO: [train..][epoch:351, iter: 155,800, lr:(5.000e-05,)] [eta: 1 day, 5:43:22, time (data): 1.094 (0.003)] l_pix: 3.8117e-02 
2024-05-18 20:21:19,578 INFO: [train..][epoch:352, iter: 156,000, lr:(5.000e-05,)] [eta: 1 day, 5:39:37, time (data): 1.092 (0.004)] l_pix: 1.9712e-02 
2024-05-18 20:24:58,507 INFO: [train..][epoch:352, iter: 156,200, lr:(5.000e-05,)] [eta: 1 day, 5:35:45, time (data): 1.091 (0.004)] l_pix: 2.2983e-02 
2024-05-18 20:28:50,118 INFO: [train..][epoch:353, iter: 156,400, lr:(5.000e-05,)] [eta: 1 day, 5:32:01, time (data): 1.654 (0.563)] l_pix: 2.8617e-02 
2024-05-18 20:32:29,330 INFO: [train..][epoch:353, iter: 156,600, lr:(5.000e-05,)] [eta: 1 day, 5:28:09, time (data): 1.105 (0.004)] l_pix: 1.9899e-02 
2024-05-18 20:36:08,609 INFO: [train..][epoch:353, iter: 156,800, lr:(5.000e-05,)] [eta: 1 day, 5:24:17, time (data): 1.095 (0.004)] l_pix: 2.7962e-02 
2024-05-18 20:39:58,992 INFO: [train..][epoch:354, iter: 157,000, lr:(5.000e-05,)] [eta: 1 day, 5:20:32, time (data): 1.092 (0.003)] l_pix: 1.5153e-02 
2024-05-18 20:43:38,597 INFO: [train..][epoch:354, iter: 157,200, lr:(5.000e-05,)] [eta: 1 day, 5:16:40, time (data): 1.097 (0.003)] l_pix: 2.3995e-02 
2024-05-18 20:47:29,496 INFO: [train..][epoch:355, iter: 157,400, lr:(5.000e-05,)] [eta: 1 day, 5:12:55, time (data): 1.094 (0.004)] l_pix: 2.4813e-02 
2024-05-18 20:51:08,611 INFO: [train..][epoch:355, iter: 157,600, lr:(5.000e-05,)] [eta: 1 day, 5:09:03, time (data): 1.090 (0.003)] l_pix: 1.3630e-02 
2024-05-18 20:54:59,385 INFO: [train..][epoch:356, iter: 157,800, lr:(5.000e-05,)] [eta: 1 day, 5:05:18, time (data): 1.088 (0.003)] l_pix: 1.9207e-02 
2024-05-18 20:58:38,869 INFO: [train..][epoch:356, iter: 158,000, lr:(5.000e-05,)] [eta: 1 day, 5:01:27, time (data): 1.092 (0.003)] l_pix: 1.9753e-02 
2024-05-18 21:02:29,887 INFO: [train..][epoch:357, iter: 158,200, lr:(5.000e-05,)] [eta: 1 day, 4:57:42, time (data): 1.087 (0.003)] l_pix: 3.0330e-02 
2024-05-18 21:06:08,874 INFO: [train..][epoch:357, iter: 158,400, lr:(5.000e-05,)] [eta: 1 day, 4:53:50, time (data): 1.107 (0.003)] l_pix: 1.5904e-02 
2024-05-18 21:10:00,312 INFO: [train..][epoch:358, iter: 158,600, lr:(5.000e-05,)] [eta: 1 day, 4:50:05, time (data): 2.202 (1.109)] l_pix: 2.2096e-02 
2024-05-18 21:13:38,394 INFO: [train..][epoch:358, iter: 158,800, lr:(5.000e-05,)] [eta: 1 day, 4:46:13, time (data): 1.094 (0.003)] l_pix: 3.1073e-02 
2024-05-18 21:17:18,712 INFO: [train..][epoch:358, iter: 159,000, lr:(5.000e-05,)] [eta: 1 day, 4:42:22, time (data): 1.095 (0.003)] l_pix: 2.2569e-02 
2024-05-18 21:21:09,346 INFO: [train..][epoch:359, iter: 159,200, lr:(5.000e-05,)] [eta: 1 day, 4:38:37, time (data): 1.092 (0.003)] l_pix: 1.4036e-02 
2024-05-18 21:24:48,009 INFO: [train..][epoch:359, iter: 159,400, lr:(5.000e-05,)] [eta: 1 day, 4:34:45, time (data): 1.092 (0.004)] l_pix: 2.9045e-02 
2024-05-18 21:28:39,146 INFO: [train..][epoch:360, iter: 159,600, lr:(5.000e-05,)] [eta: 1 day, 4:31:00, time (data): 1.092 (0.002)] l_pix: 2.3040e-02 
2024-05-18 21:32:18,672 INFO: [train..][epoch:360, iter: 159,800, lr:(5.000e-05,)] [eta: 1 day, 4:27:08, time (data): 1.098 (0.003)] l_pix: 2.1257e-02 
2024-05-18 21:36:10,054 INFO: [train..][epoch:361, iter: 160,000, lr:(5.000e-05,)] [eta: 1 day, 4:23:24, time (data): 1.096 (0.004)] l_pix: 3.2238e-02 
2024-05-18 21:36:10,054 INFO: Saving models and training states.
2024-05-18 21:36:11,420 INFO: Validation Set5
	 # psnr: 32.9141	Best: 32.9645 @ 145000 iter

2024-05-18 21:39:51,216 INFO: [train..][epoch:361, iter: 160,200, lr:(5.000e-05,)] [eta: 1 day, 4:19:33, time (data): 1.098 (0.003)] l_pix: 1.5053e-02 
2024-05-18 21:43:42,486 INFO: [train..][epoch:362, iter: 160,400, lr:(5.000e-05,)] [eta: 1 day, 4:15:48, time (data): 1.079 (0.004)] l_pix: 2.3872e-02 
2024-05-18 21:47:20,829 INFO: [train..][epoch:362, iter: 160,600, lr:(5.000e-05,)] [eta: 1 day, 4:11:56, time (data): 1.095 (0.003)] l_pix: 1.6049e-02 
2024-05-18 21:51:00,665 INFO: [train..][epoch:362, iter: 160,800, lr:(5.000e-05,)] [eta: 1 day, 4:08:05, time (data): 1.099 (0.004)] l_pix: 2.6998e-02 
2024-05-18 21:54:50,884 INFO: [train..][epoch:363, iter: 161,000, lr:(5.000e-05,)] [eta: 1 day, 4:04:20, time (data): 1.151 (0.064)] l_pix: 2.5652e-02 
2024-05-18 21:58:29,737 INFO: [train..][epoch:363, iter: 161,200, lr:(5.000e-05,)] [eta: 1 day, 4:00:28, time (data): 1.094 (0.003)] l_pix: 2.1025e-02 
2024-05-18 22:02:20,675 INFO: [train..][epoch:364, iter: 161,400, lr:(5.000e-05,)] [eta: 1 day, 3:56:43, time (data): 1.155 (0.065)] l_pix: 2.2482e-02 
2024-05-18 22:05:59,579 INFO: [train..][epoch:364, iter: 161,600, lr:(5.000e-05,)] [eta: 1 day, 3:52:52, time (data): 1.094 (0.003)] l_pix: 2.5929e-02 
2024-05-18 22:09:49,855 INFO: [train..][epoch:365, iter: 161,800, lr:(5.000e-05,)] [eta: 1 day, 3:49:06, time (data): 1.153 (0.066)] l_pix: 1.9916e-02 
2024-05-18 22:13:29,203 INFO: [train..][epoch:365, iter: 162,000, lr:(5.000e-05,)] [eta: 1 day, 3:45:15, time (data): 1.097 (0.004)] l_pix: 1.7121e-02 
2024-05-18 22:17:19,728 INFO: [train..][epoch:366, iter: 162,200, lr:(5.000e-05,)] [eta: 1 day, 3:41:30, time (data): 1.154 (0.065)] l_pix: 1.6602e-02 
2024-05-18 22:20:59,117 INFO: [train..][epoch:366, iter: 162,400, lr:(5.000e-05,)] [eta: 1 day, 3:37:39, time (data): 1.097 (0.004)] l_pix: 1.7929e-02 
2024-05-18 22:24:51,468 INFO: [train..][epoch:367, iter: 162,600, lr:(5.000e-05,)] [eta: 1 day, 3:33:54, time (data): 1.165 (0.067)] l_pix: 3.5173e-02 
2024-05-18 22:28:30,228 INFO: [train..][epoch:367, iter: 162,800, lr:(5.000e-05,)] [eta: 1 day, 3:30:03, time (data): 1.093 (0.003)] l_pix: 1.2093e-02 
2024-05-18 22:32:10,638 INFO: [train..][epoch:367, iter: 163,000, lr:(5.000e-05,)] [eta: 1 day, 3:26:12, time (data): 1.103 (0.003)] l_pix: 3.0406e-02 
2024-05-18 22:36:01,169 INFO: [train..][epoch:368, iter: 163,200, lr:(5.000e-05,)] [eta: 1 day, 3:22:27, time (data): 1.156 (0.069)] l_pix: 2.3423e-02 
2024-05-18 22:39:39,656 INFO: [train..][epoch:368, iter: 163,400, lr:(5.000e-05,)] [eta: 1 day, 3:18:35, time (data): 1.092 (0.003)] l_pix: 2.7408e-02 
2024-05-18 22:43:29,772 INFO: [train..][epoch:369, iter: 163,600, lr:(5.000e-05,)] [eta: 1 day, 3:14:50, time (data): 1.155 (0.068)] l_pix: 3.6381e-02 
2024-05-18 22:47:08,921 INFO: [train..][epoch:369, iter: 163,800, lr:(5.000e-05,)] [eta: 1 day, 3:10:59, time (data): 1.096 (0.004)] l_pix: 2.1356e-02 
2024-05-18 22:50:59,317 INFO: [train..][epoch:370, iter: 164,000, lr:(5.000e-05,)] [eta: 1 day, 3:07:13, time (data): 1.157 (0.069)] l_pix: 2.0842e-02 
2024-05-18 22:54:38,444 INFO: [train..][epoch:370, iter: 164,200, lr:(5.000e-05,)] [eta: 1 day, 3:03:22, time (data): 1.096 (0.003)] l_pix: 3.6138e-02 
2024-05-18 22:58:29,226 INFO: [train..][epoch:371, iter: 164,400, lr:(5.000e-05,)] [eta: 1 day, 2:59:37, time (data): 1.159 (0.068)] l_pix: 1.4183e-02 
2024-05-18 23:02:07,644 INFO: [train..][epoch:371, iter: 164,600, lr:(5.000e-05,)] [eta: 1 day, 2:55:46, time (data): 1.092 (0.004)] l_pix: 2.9511e-02 
2024-05-18 23:05:59,086 INFO: [train..][epoch:372, iter: 164,800, lr:(5.000e-05,)] [eta: 1 day, 2:52:01, time (data): 1.164 (0.070)] l_pix: 2.5932e-02 
2024-05-18 23:09:37,229 INFO: [train..][epoch:372, iter: 165,000, lr:(5.000e-05,)] [eta: 1 day, 2:48:09, time (data): 1.091 (0.004)] l_pix: 2.2082e-02 
2024-05-18 23:09:37,231 INFO: Saving models and training states.
2024-05-18 23:09:38,726 INFO: Validation Set5
	 # psnr: 32.9642	Best: 32.9645 @ 145000 iter

2024-05-18 23:13:17,940 INFO: [train..][epoch:372, iter: 165,200, lr:(5.000e-05,)] [eta: 1 day, 2:44:19, time (data): 1.096 (0.003)] l_pix: 2.7798e-02 
2024-05-18 23:17:08,505 INFO: [train..][epoch:373, iter: 165,400, lr:(5.000e-05,)] [eta: 1 day, 2:40:34, time (data): 1.159 (0.070)] l_pix: 2.4761e-02 
2024-05-18 23:20:47,365 INFO: [train..][epoch:373, iter: 165,600, lr:(5.000e-05,)] [eta: 1 day, 2:36:42, time (data): 1.094 (0.003)] l_pix: 2.0725e-02 
2024-05-18 23:24:37,709 INFO: [train..][epoch:374, iter: 165,800, lr:(5.000e-05,)] [eta: 1 day, 2:32:57, time (data): 1.160 (0.072)] l_pix: 2.0935e-02 
2024-05-18 23:28:17,018 INFO: [train..][epoch:374, iter: 166,000, lr:(5.000e-05,)] [eta: 1 day, 2:29:06, time (data): 1.096 (0.003)] l_pix: 3.0764e-02 
2024-05-18 23:32:06,906 INFO: [train..][epoch:375, iter: 166,200, lr:(5.000e-05,)] [eta: 1 day, 2:25:21, time (data): 1.158 (0.072)] l_pix: 2.3190e-02 
2024-05-18 23:35:45,619 INFO: [train..][epoch:375, iter: 166,400, lr:(5.000e-05,)] [eta: 1 day, 2:21:29, time (data): 1.094 (0.003)] l_pix: 1.2261e-02 
2024-05-18 23:39:36,607 INFO: [train..][epoch:376, iter: 166,600, lr:(5.000e-05,)] [eta: 1 day, 2:17:44, time (data): 1.165 (0.074)] l_pix: 2.4083e-02 
2024-05-18 23:43:15,012 INFO: [train..][epoch:376, iter: 166,800, lr:(5.000e-05,)] [eta: 1 day, 2:13:53, time (data): 1.093 (0.004)] l_pix: 2.8080e-02 
2024-05-18 23:46:54,178 INFO: [train..][epoch:376, iter: 167,000, lr:(5.000e-05,)] [eta: 1 day, 2:10:02, time (data): 1.096 (0.003)] l_pix: 3.4515e-02 
2024-05-18 23:50:44,235 INFO: [train..][epoch:377, iter: 167,200, lr:(5.000e-05,)] [eta: 1 day, 2:06:17, time (data): 1.088 (0.003)] l_pix: 1.8897e-02 
2024-05-18 23:54:23,393 INFO: [train..][epoch:377, iter: 167,400, lr:(5.000e-05,)] [eta: 1 day, 2:02:26, time (data): 1.096 (0.003)] l_pix: 1.5813e-02 
2024-05-18 23:58:13,843 INFO: [train..][epoch:378, iter: 167,600, lr:(5.000e-05,)] [eta: 1 day, 1:58:40, time (data): 1.163 (0.075)] l_pix: 1.6369e-02 
2024-05-19 00:01:52,584 INFO: [train..][epoch:378, iter: 167,800, lr:(5.000e-05,)] [eta: 1 day, 1:54:49, time (data): 1.094 (0.003)] l_pix: 3.3515e-02 
2024-05-19 00:05:43,356 INFO: [train..][epoch:379, iter: 168,000, lr:(5.000e-05,)] [eta: 1 day, 1:51:04, time (data): 1.166 (0.077)] l_pix: 2.5569e-02 
2024-05-19 00:09:22,231 INFO: [train..][epoch:379, iter: 168,200, lr:(5.000e-05,)] [eta: 1 day, 1:47:13, time (data): 1.094 (0.003)] l_pix: 1.8408e-02 
2024-05-19 00:13:12,450 INFO: [train..][epoch:380, iter: 168,400, lr:(5.000e-05,)] [eta: 1 day, 1:43:28, time (data): 1.164 (0.077)] l_pix: 2.2538e-02 
2024-05-19 00:16:51,868 INFO: [train..][epoch:380, iter: 168,600, lr:(5.000e-05,)] [eta: 1 day, 1:39:37, time (data): 1.098 (0.004)] l_pix: 3.5304e-02 
2024-05-19 00:20:43,249 INFO: [train..][epoch:381, iter: 168,800, lr:(5.000e-05,)] [eta: 1 day, 1:35:52, time (data): 1.172 (0.079)] l_pix: 2.2459e-02 
2024-05-19 00:24:22,376 INFO: [train..][epoch:381, iter: 169,000, lr:(5.000e-05,)] [eta: 1 day, 1:32:02, time (data): 1.098 (0.004)] l_pix: 4.2584e-02 
2024-05-19 00:28:01,618 INFO: [train..][epoch:381, iter: 169,200, lr:(5.000e-05,)] [eta: 1 day, 1:28:11, time (data): 1.097 (0.003)] l_pix: 2.8165e-02 
2024-05-19 00:31:51,714 INFO: [train..][epoch:382, iter: 169,400, lr:(5.000e-05,)] [eta: 1 day, 1:24:26, time (data): 1.090 (0.004)] l_pix: 2.2584e-02 
2024-05-19 00:35:30,512 INFO: [train..][epoch:382, iter: 169,600, lr:(5.000e-05,)] [eta: 1 day, 1:20:35, time (data): 1.094 (0.004)] l_pix: 2.0146e-02 
2024-05-19 00:39:20,967 INFO: [train..][epoch:383, iter: 169,800, lr:(5.000e-05,)] [eta: 1 day, 1:16:49, time (data): 1.168 (0.080)] l_pix: 2.1310e-02 
2024-05-19 00:42:59,783 INFO: [train..][epoch:383, iter: 170,000, lr:(5.000e-05,)] [eta: 1 day, 1:12:59, time (data): 1.094 (0.004)] l_pix: 1.9738e-02 
2024-05-19 00:42:59,784 INFO: Saving models and training states.
2024-05-19 00:43:01,168 INFO: Validation Set5
	 # psnr: 32.9450	Best: 32.9645 @ 145000 iter

2024-05-19 00:46:51,647 INFO: [train..][epoch:384, iter: 170,200, lr:(5.000e-05,)] [eta: 1 day, 1:09:14, time (data): 1.170 (0.083)] l_pix: 1.5828e-02 
2024-05-19 00:50:30,593 INFO: [train..][epoch:384, iter: 170,400, lr:(5.000e-05,)] [eta: 1 day, 1:05:23, time (data): 1.095 (0.003)] l_pix: 2.0074e-02 
2024-05-19 00:54:21,060 INFO: [train..][epoch:385, iter: 170,600, lr:(5.000e-05,)] [eta: 1 day, 1:01:38, time (data): 1.171 (0.082)] l_pix: 1.5774e-02 
2024-05-19 00:57:59,580 INFO: [train..][epoch:385, iter: 170,800, lr:(5.000e-05,)] [eta: 1 day, 0:57:47, time (data): 1.094 (0.004)] l_pix: 1.9025e-02 
2024-05-19 01:01:51,034 INFO: [train..][epoch:386, iter: 171,000, lr:(5.000e-05,)] [eta: 1 day, 0:54:02, time (data): 1.178 (0.086)] l_pix: 1.2894e-02 
2024-05-19 01:05:28,558 INFO: [train..][epoch:386, iter: 171,200, lr:(5.000e-05,)] [eta: 1 day, 0:50:11, time (data): 1.087 (0.003)] l_pix: 1.7257e-02 
2024-05-19 01:09:08,104 INFO: [train..][epoch:386, iter: 171,400, lr:(5.000e-05,)] [eta: 1 day, 0:46:21, time (data): 1.099 (0.004)] l_pix: 2.6094e-02 
2024-05-19 01:12:59,134 INFO: [train..][epoch:387, iter: 171,600, lr:(5.000e-05,)] [eta: 1 day, 0:42:36, time (data): 1.094 (0.004)] l_pix: 3.4462e-02 
2024-05-19 01:16:37,773 INFO: [train..][epoch:387, iter: 171,800, lr:(5.000e-05,)] [eta: 1 day, 0:38:45, time (data): 1.092 (0.003)] l_pix: 1.8982e-02 
2024-05-19 01:20:28,212 INFO: [train..][epoch:388, iter: 172,000, lr:(5.000e-05,)] [eta: 1 day, 0:35:00, time (data): 1.174 (0.087)] l_pix: 2.3382e-02 
2024-05-19 01:24:07,059 INFO: [train..][epoch:388, iter: 172,200, lr:(5.000e-05,)] [eta: 1 day, 0:31:09, time (data): 1.095 (0.003)] l_pix: 1.2678e-02 
2024-05-19 01:27:57,811 INFO: [train..][epoch:389, iter: 172,400, lr:(5.000e-05,)] [eta: 1 day, 0:27:24, time (data): 1.177 (0.089)] l_pix: 3.1168e-02 
2024-05-19 01:31:36,817 INFO: [train..][epoch:389, iter: 172,600, lr:(5.000e-05,)] [eta: 1 day, 0:23:33, time (data): 1.097 (0.003)] l_pix: 1.5096e-02 
2024-05-19 01:35:27,858 INFO: [train..][epoch:390, iter: 172,800, lr:(5.000e-05,)] [eta: 1 day, 0:19:48, time (data): 1.180 (0.089)] l_pix: 3.6137e-02 
2024-05-19 01:39:05,834 INFO: [train..][epoch:390, iter: 173,000, lr:(5.000e-05,)] [eta: 1 day, 0:15:57, time (data): 1.089 (0.003)] l_pix: 5.2948e-02 
2024-05-19 01:42:45,513 INFO: [train..][epoch:390, iter: 173,200, lr:(5.000e-05,)] [eta: 1 day, 0:12:07, time (data): 1.100 (0.004)] l_pix: 4.3435e-02 
2024-05-19 01:46:35,627 INFO: [train..][epoch:391, iter: 173,400, lr:(5.000e-05,)] [eta: 1 day, 0:08:22, time (data): 1.089 (0.004)] l_pix: 2.5087e-02 
2024-05-19 01:50:14,037 INFO: [train..][epoch:391, iter: 173,600, lr:(5.000e-05,)] [eta: 1 day, 0:04:31, time (data): 1.092 (0.003)] l_pix: 2.1797e-02 
2024-05-19 01:54:04,295 INFO: [train..][epoch:392, iter: 173,800, lr:(5.000e-05,)] [eta: 1 day, 0:00:46, time (data): 1.090 (0.004)] l_pix: 1.9921e-02 
2024-05-19 01:57:43,075 INFO: [train..][epoch:392, iter: 174,000, lr:(5.000e-05,)] [eta: 23:56:55, time (data): 1.093 (0.003)] l_pix: 2.2982e-02 
2024-05-19 02:01:34,281 INFO: [train..][epoch:393, iter: 174,200, lr:(5.000e-05,)] [eta: 23:53:10, time (data): 1.185 (0.096)] l_pix: 2.5895e-02 
2024-05-19 02:05:13,410 INFO: [train..][epoch:393, iter: 174,400, lr:(5.000e-05,)] [eta: 23:49:20, time (data): 1.096 (0.003)] l_pix: 1.9730e-02 
2024-05-19 02:09:04,235 INFO: [train..][epoch:394, iter: 174,600, lr:(5.000e-05,)] [eta: 23:45:35, time (data): 1.185 (0.095)] l_pix: 1.6865e-02 
2024-05-19 02:12:43,603 INFO: [train..][epoch:394, iter: 174,800, lr:(5.000e-05,)] [eta: 23:41:45, time (data): 1.099 (0.004)] l_pix: 2.0049e-02 
2024-05-19 02:16:34,602 INFO: [train..][epoch:395, iter: 175,000, lr:(5.000e-05,)] [eta: 23:38:00, time (data): 1.187 (0.097)] l_pix: 1.3594e-02 
2024-05-19 02:16:34,604 INFO: Saving models and training states.
2024-05-19 02:16:35,998 INFO: Validation Set5
	 # psnr: 32.9486	Best: 32.9645 @ 145000 iter

2024-05-19 02:20:14,009 INFO: [train..][epoch:395, iter: 175,200, lr:(5.000e-05,)] [eta: 23:34:10, time (data): 1.090 (0.003)] l_pix: 2.0969e-02 
2024-05-19 02:23:53,669 INFO: [train..][epoch:395, iter: 175,400, lr:(5.000e-05,)] [eta: 23:30:20, time (data): 1.099 (0.004)] l_pix: 2.7209e-02 
2024-05-19 02:27:43,520 INFO: [train..][epoch:396, iter: 175,600, lr:(5.000e-05,)] [eta: 23:26:34, time (data): 1.087 (0.003)] l_pix: 1.8085e-02 
2024-05-19 02:31:22,973 INFO: [train..][epoch:396, iter: 175,800, lr:(5.000e-05,)] [eta: 23:22:44, time (data): 1.100 (0.003)] l_pix: 1.9176e-02 
2024-05-19 02:35:14,099 INFO: [train..][epoch:397, iter: 176,000, lr:(5.000e-05,)] [eta: 23:18:59, time (data): 1.092 (0.004)] l_pix: 1.7429e-02 
2024-05-19 02:38:54,447 INFO: [train..][epoch:397, iter: 176,200, lr:(5.000e-05,)] [eta: 23:15:09, time (data): 1.104 (0.003)] l_pix: 3.4196e-02 
2024-05-19 02:42:46,225 INFO: [train..][epoch:398, iter: 176,400, lr:(5.000e-05,)] [eta: 23:11:25, time (data): 1.194 (0.105)] l_pix: 2.6831e-02 
2024-05-19 02:46:24,805 INFO: [train..][epoch:398, iter: 176,600, lr:(5.000e-05,)] [eta: 23:07:34, time (data): 1.095 (0.003)] l_pix: 2.8664e-02 
2024-05-19 02:50:15,833 INFO: [train..][epoch:399, iter: 176,800, lr:(5.000e-05,)] [eta: 23:03:49, time (data): 1.195 (0.103)] l_pix: 2.0567e-02 
2024-05-19 02:53:54,601 INFO: [train..][epoch:399, iter: 177,000, lr:(5.000e-05,)] [eta: 22:59:59, time (data): 1.095 (0.003)] l_pix: 4.3553e-02 
2024-05-19 02:57:33,238 INFO: [train..][epoch:399, iter: 177,200, lr:(5.000e-05,)] [eta: 22:56:09, time (data): 1.093 (0.003)] l_pix: 2.4416e-02 
2024-05-19 03:01:24,000 INFO: [train..][epoch:400, iter: 177,400, lr:(5.000e-05,)] [eta: 22:52:23, time (data): 1.094 (0.003)] l_pix: 2.3688e-02 
2024-05-19 03:05:03,063 INFO: [train..][epoch:400, iter: 177,600, lr:(5.000e-05,)] [eta: 22:48:33, time (data): 1.094 (0.003)] l_pix: 2.5621e-02 
2024-05-19 03:08:53,123 INFO: [train..][epoch:401, iter: 177,800, lr:(5.000e-05,)] [eta: 22:44:48, time (data): 1.090 (0.003)] l_pix: 2.5922e-02 
2024-05-19 03:12:32,702 INFO: [train..][epoch:401, iter: 178,000, lr:(5.000e-05,)] [eta: 22:40:58, time (data): 1.098 (0.003)] l_pix: 2.8869e-02 
2024-05-19 03:16:23,071 INFO: [train..][epoch:402, iter: 178,200, lr:(5.000e-05,)] [eta: 22:37:13, time (data): 1.194 (0.110)] l_pix: 1.1415e-02 
2024-05-19 03:20:02,690 INFO: [train..][epoch:402, iter: 178,400, lr:(5.000e-05,)] [eta: 22:33:23, time (data): 1.101 (0.003)] l_pix: 2.5720e-02 
2024-05-19 03:23:53,233 INFO: [train..][epoch:403, iter: 178,600, lr:(5.000e-05,)] [eta: 22:29:38, time (data): 1.199 (0.110)] l_pix: 3.1081e-02 
2024-05-19 03:27:32,099 INFO: [train..][epoch:403, iter: 178,800, lr:(5.000e-05,)] [eta: 22:25:48, time (data): 1.095 (0.003)] l_pix: 2.7553e-02 
2024-05-19 03:31:23,604 INFO: [train..][epoch:404, iter: 179,000, lr:(5.000e-05,)] [eta: 22:22:03, time (data): 1.206 (0.113)] l_pix: 2.2971e-02 
2024-05-19 03:35:02,779 INFO: [train..][epoch:404, iter: 179,200, lr:(5.000e-05,)] [eta: 22:18:13, time (data): 1.097 (0.004)] l_pix: 2.5965e-02 
2024-05-19 03:38:42,516 INFO: [train..][epoch:404, iter: 179,400, lr:(5.000e-05,)] [eta: 22:14:23, time (data): 1.100 (0.004)] l_pix: 1.9214e-02 
2024-05-19 03:42:32,734 INFO: [train..][epoch:405, iter: 179,600, lr:(5.000e-05,)] [eta: 22:10:38, time (data): 1.089 (0.003)] l_pix: 3.1168e-02 
2024-05-19 03:46:11,778 INFO: [train..][epoch:405, iter: 179,800, lr:(5.000e-05,)] [eta: 22:06:48, time (data): 1.097 (0.003)] l_pix: 2.5163e-02 
2024-05-19 03:50:02,464 INFO: [train..][epoch:406, iter: 180,000, lr:(5.000e-05,)] [eta: 22:03:03, time (data): 1.091 (0.004)] l_pix: 1.5985e-02 
2024-05-19 03:50:02,464 INFO: Saving models and training states.
2024-05-19 03:50:03,833 INFO: Validation Set5
	 # psnr: 32.8874	Best: 32.9645 @ 145000 iter

2024-05-19 03:53:42,544 INFO: [train..][epoch:406, iter: 180,200, lr:(5.000e-05,)] [eta: 21:59:13, time (data): 1.093 (0.003)] l_pix: 3.4618e-02 
2024-05-19 03:57:33,008 INFO: [train..][epoch:407, iter: 180,400, lr:(5.000e-05,)] [eta: 21:55:28, time (data): 1.206 (0.120)] l_pix: 2.7283e-02 
2024-05-19 04:01:12,358 INFO: [train..][epoch:407, iter: 180,600, lr:(5.000e-05,)] [eta: 21:51:38, time (data): 1.097 (0.003)] l_pix: 1.8648e-02 
2024-05-19 04:05:02,909 INFO: [train..][epoch:408, iter: 180,800, lr:(5.000e-05,)] [eta: 21:47:53, time (data): 1.212 (0.124)] l_pix: 2.8662e-02 
2024-05-19 04:08:42,044 INFO: [train..][epoch:408, iter: 181,000, lr:(5.000e-05,)] [eta: 21:44:03, time (data): 1.098 (0.003)] l_pix: 4.2868e-02 
2024-05-19 04:12:33,229 INFO: [train..][epoch:409, iter: 181,200, lr:(5.000e-05,)] [eta: 21:40:18, time (data): 1.219 (0.129)] l_pix: 1.6160e-02 
2024-05-19 04:16:11,621 INFO: [train..][epoch:409, iter: 181,400, lr:(5.000e-05,)] [eta: 21:36:28, time (data): 1.097 (0.003)] l_pix: 1.5035e-02 
2024-05-19 04:19:50,782 INFO: [train..][epoch:409, iter: 181,600, lr:(5.000e-05,)] [eta: 21:32:38, time (data): 1.095 (0.003)] l_pix: 1.8100e-02 
2024-05-19 04:23:41,045 INFO: [train..][epoch:410, iter: 181,800, lr:(5.000e-05,)] [eta: 21:28:53, time (data): 1.093 (0.003)] l_pix: 3.2363e-02 
2024-05-19 04:27:20,836 INFO: [train..][epoch:410, iter: 182,000, lr:(5.000e-05,)] [eta: 21:25:03, time (data): 1.099 (0.003)] l_pix: 2.8577e-02 
2024-05-19 04:31:11,099 INFO: [train..][epoch:411, iter: 182,200, lr:(5.000e-05,)] [eta: 21:21:18, time (data): 1.090 (0.004)] l_pix: 5.7773e-02 
2024-05-19 04:34:50,587 INFO: [train..][epoch:411, iter: 182,400, lr:(5.000e-05,)] [eta: 21:17:28, time (data): 1.098 (0.003)] l_pix: 3.8914e-02 
2024-05-19 04:38:41,026 INFO: [train..][epoch:412, iter: 182,600, lr:(5.000e-05,)] [eta: 21:13:43, time (data): 1.218 (0.133)] l_pix: 2.0239e-02 
2024-05-19 04:42:19,345 INFO: [train..][epoch:412, iter: 182,800, lr:(5.000e-05,)] [eta: 21:09:53, time (data): 1.095 (0.003)] l_pix: 2.8063e-02 
2024-05-19 04:46:11,096 INFO: [train..][epoch:413, iter: 183,000, lr:(5.000e-05,)] [eta: 21:06:08, time (data): 1.231 (0.138)] l_pix: 2.3500e-02 
2024-05-19 04:49:49,367 INFO: [train..][epoch:413, iter: 183,200, lr:(5.000e-05,)] [eta: 21:02:18, time (data): 1.092 (0.003)] l_pix: 3.6973e-02 
2024-05-19 04:53:28,204 INFO: [train..][epoch:413, iter: 183,400, lr:(5.000e-05,)] [eta: 20:58:29, time (data): 1.096 (0.003)] l_pix: 2.1040e-02 
2024-05-19 04:57:18,480 INFO: [train..][epoch:414, iter: 183,600, lr:(5.000e-05,)] [eta: 20:54:43, time (data): 1.094 (0.003)] l_pix: 1.7174e-02 
2024-05-19 05:00:57,257 INFO: [train..][epoch:414, iter: 183,800, lr:(5.000e-05,)] [eta: 20:50:53, time (data): 1.093 (0.003)] l_pix: 2.1353e-02 
2024-05-19 05:04:48,059 INFO: [train..][epoch:415, iter: 184,000, lr:(5.000e-05,)] [eta: 20:47:08, time (data): 1.096 (0.004)] l_pix: 2.0715e-02 
2024-05-19 05:08:27,510 INFO: [train..][epoch:415, iter: 184,200, lr:(5.000e-05,)] [eta: 20:43:19, time (data): 1.095 (0.004)] l_pix: 1.5633e-02 
2024-05-19 05:12:18,124 INFO: [train..][epoch:416, iter: 184,400, lr:(5.000e-05,)] [eta: 20:39:33, time (data): 1.092 (0.003)] l_pix: 2.6849e-02 
2024-05-19 05:15:57,300 INFO: [train..][epoch:416, iter: 184,600, lr:(5.000e-05,)] [eta: 20:35:44, time (data): 1.092 (0.003)] l_pix: 1.4380e-02 
2024-05-19 05:19:48,080 INFO: [train..][epoch:417, iter: 184,800, lr:(5.000e-05,)] [eta: 20:31:59, time (data): 1.240 (0.153)] l_pix: 3.0267e-02 
2024-05-19 05:23:26,855 INFO: [train..][epoch:417, iter: 185,000, lr:(5.000e-05,)] [eta: 20:28:09, time (data): 1.097 (0.003)] l_pix: 1.7301e-02 
2024-05-19 05:23:26,855 INFO: Saving models and training states.
2024-05-19 05:23:28,219 INFO: Validation Set5
	 # psnr: 32.9349	Best: 32.9645 @ 145000 iter

2024-05-19 05:27:19,049 INFO: [train..][epoch:418, iter: 185,200, lr:(5.000e-05,)] [eta: 20:24:24, time (data): 1.244 (0.156)] l_pix: 1.0935e-02 
2024-05-19 05:30:58,249 INFO: [train..][epoch:418, iter: 185,400, lr:(5.000e-05,)] [eta: 20:20:35, time (data): 1.101 (0.003)] l_pix: 2.7592e-02 
2024-05-19 05:34:37,607 INFO: [train..][epoch:418, iter: 185,600, lr:(5.000e-05,)] [eta: 20:16:46, time (data): 1.096 (0.003)] l_pix: 9.7986e-03 
2024-05-19 05:38:28,033 INFO: [train..][epoch:419, iter: 185,800, lr:(5.000e-05,)] [eta: 20:13:00, time (data): 1.093 (0.003)] l_pix: 1.6087e-02 
2024-05-19 05:42:07,998 INFO: [train..][epoch:419, iter: 186,000, lr:(5.000e-05,)] [eta: 20:09:11, time (data): 1.100 (0.004)] l_pix: 1.9827e-02 
2024-05-19 05:45:57,988 INFO: [train..][epoch:420, iter: 186,200, lr:(5.000e-05,)] [eta: 20:05:25, time (data): 1.086 (0.003)] l_pix: 3.0176e-02 
2024-05-19 05:49:37,514 INFO: [train..][epoch:420, iter: 186,400, lr:(5.000e-05,)] [eta: 20:01:36, time (data): 1.102 (0.003)] l_pix: 2.0770e-02 
2024-05-19 05:53:28,089 INFO: [train..][epoch:421, iter: 186,600, lr:(5.000e-05,)] [eta: 19:57:51, time (data): 1.088 (0.004)] l_pix: 1.9061e-02 
2024-05-19 05:57:06,614 INFO: [train..][epoch:421, iter: 186,800, lr:(5.000e-05,)] [eta: 19:54:01, time (data): 1.097 (0.003)] l_pix: 1.9003e-02 
2024-05-19 06:00:57,792 INFO: [train..][epoch:422, iter: 187,000, lr:(5.000e-05,)] [eta: 19:50:16, time (data): 1.266 (0.177)] l_pix: 2.4601e-02 
2024-05-19 06:04:36,295 INFO: [train..][epoch:422, iter: 187,200, lr:(5.000e-05,)] [eta: 19:46:27, time (data): 1.093 (0.003)] l_pix: 1.6408e-02 
2024-05-19 06:08:27,968 INFO: [train..][epoch:423, iter: 187,400, lr:(5.000e-05,)] [eta: 19:42:42, time (data): 1.273 (0.180)] l_pix: 1.7954e-02 
2024-05-19 06:12:06,161 INFO: [train..][epoch:423, iter: 187,600, lr:(5.000e-05,)] [eta: 19:38:52, time (data): 1.094 (0.004)] l_pix: 2.4198e-02 
2024-05-19 06:15:45,878 INFO: [train..][epoch:423, iter: 187,800, lr:(5.000e-05,)] [eta: 19:35:03, time (data): 1.102 (0.004)] l_pix: 1.6366e-02 
2024-05-19 06:19:37,279 INFO: [train..][epoch:424, iter: 188,000, lr:(5.000e-05,)] [eta: 19:31:18, time (data): 1.107 (0.003)] l_pix: 3.6357e-02 
2024-05-19 06:23:16,195 INFO: [train..][epoch:424, iter: 188,200, lr:(5.000e-05,)] [eta: 19:27:29, time (data): 1.093 (0.003)] l_pix: 1.1080e-02 
2024-05-19 06:27:06,746 INFO: [train..][epoch:425, iter: 188,400, lr:(5.000e-05,)] [eta: 19:23:43, time (data): 1.091 (0.004)] l_pix: 3.2112e-02 
2024-05-19 06:30:45,678 INFO: [train..][epoch:425, iter: 188,600, lr:(5.000e-05,)] [eta: 19:19:54, time (data): 1.095 (0.003)] l_pix: 2.0759e-02 
2024-05-19 06:34:36,164 INFO: [train..][epoch:426, iter: 188,800, lr:(5.000e-05,)] [eta: 19:16:08, time (data): 1.089 (0.003)] l_pix: 1.6179e-02 
2024-05-19 06:38:15,485 INFO: [train..][epoch:426, iter: 189,000, lr:(5.000e-05,)] [eta: 19:12:19, time (data): 1.099 (0.003)] l_pix: 1.7937e-02 
2024-05-19 06:42:06,621 INFO: [train..][epoch:427, iter: 189,200, lr:(5.000e-05,)] [eta: 19:08:34, time (data): 1.301 (0.212)] l_pix: 2.6542e-02 
2024-05-19 06:45:45,189 INFO: [train..][epoch:427, iter: 189,400, lr:(5.000e-05,)] [eta: 19:04:45, time (data): 1.099 (0.003)] l_pix: 1.7383e-02 
2024-05-19 06:49:24,468 INFO: [train..][epoch:427, iter: 189,600, lr:(5.000e-05,)] [eta: 19:00:56, time (data): 1.094 (0.003)] l_pix: 2.3162e-02 
2024-05-19 06:53:15,108 INFO: [train..][epoch:428, iter: 189,800, lr:(5.000e-05,)] [eta: 18:57:10, time (data): 1.093 (0.004)] l_pix: 3.5580e-02 
2024-05-19 06:56:54,980 INFO: [train..][epoch:428, iter: 190,000, lr:(5.000e-05,)] [eta: 18:53:22, time (data): 1.101 (0.004)] l_pix: 1.5910e-02 
2024-05-19 06:56:54,981 INFO: Saving models and training states.
2024-05-19 06:56:56,355 INFO: Validation Set5
	 # psnr: 32.9367	Best: 32.9645 @ 145000 iter

2024-05-19 07:00:47,321 INFO: [train..][epoch:429, iter: 190,200, lr:(5.000e-05,)] [eta: 18:49:37, time (data): 1.103 (0.004)] l_pix: 2.6460e-02 
2024-05-19 07:04:27,049 INFO: [train..][epoch:429, iter: 190,400, lr:(5.000e-05,)] [eta: 18:45:48, time (data): 1.100 (0.004)] l_pix: 1.9732e-02 
2024-05-19 07:08:17,913 INFO: [train..][epoch:430, iter: 190,600, lr:(5.000e-05,)] [eta: 18:42:02, time (data): 1.088 (0.004)] l_pix: 3.1420e-02 
2024-05-19 07:11:57,937 INFO: [train..][epoch:430, iter: 190,800, lr:(5.000e-05,)] [eta: 18:38:14, time (data): 1.099 (0.005)] l_pix: 2.1283e-02 
2024-05-19 07:15:49,187 INFO: [train..][epoch:431, iter: 191,000, lr:(5.000e-05,)] [eta: 18:34:28, time (data): 1.087 (0.004)] l_pix: 2.5105e-02 
2024-05-19 07:19:29,632 INFO: [train..][epoch:431, iter: 191,200, lr:(5.000e-05,)] [eta: 18:30:40, time (data): 1.098 (0.004)] l_pix: 1.3276e-02 
2024-05-19 07:23:20,683 INFO: [train..][epoch:432, iter: 191,400, lr:(5.000e-05,)] [eta: 18:26:54, time (data): 1.346 (0.256)] l_pix: 1.5648e-02 
2024-05-19 07:26:59,638 INFO: [train..][epoch:432, iter: 191,600, lr:(5.000e-05,)] [eta: 18:23:05, time (data): 1.097 (0.003)] l_pix: 3.1363e-02 
2024-05-19 07:30:38,514 INFO: [train..][epoch:432, iter: 191,800, lr:(5.000e-05,)] [eta: 18:19:16, time (data): 1.094 (0.003)] l_pix: 2.3352e-02 
2024-05-19 07:34:29,095 INFO: [train..][epoch:433, iter: 192,000, lr:(5.000e-05,)] [eta: 18:15:31, time (data): 1.099 (0.006)] l_pix: 2.8983e-02 
2024-05-19 07:38:08,596 INFO: [train..][epoch:433, iter: 192,200, lr:(5.000e-05,)] [eta: 18:11:42, time (data): 1.097 (0.003)] l_pix: 1.4697e-02 
2024-05-19 07:41:59,117 INFO: [train..][epoch:434, iter: 192,400, lr:(5.000e-05,)] [eta: 18:07:57, time (data): 1.089 (0.004)] l_pix: 4.2041e-02 
2024-05-19 07:45:38,682 INFO: [train..][epoch:434, iter: 192,600, lr:(5.000e-05,)] [eta: 18:04:08, time (data): 1.099 (0.003)] l_pix: 2.3964e-02 
2024-05-19 07:49:29,156 INFO: [train..][epoch:435, iter: 192,800, lr:(5.000e-05,)] [eta: 18:00:22, time (data): 1.090 (0.004)] l_pix: 2.8477e-02 
2024-05-19 07:53:08,151 INFO: [train..][epoch:435, iter: 193,000, lr:(5.000e-05,)] [eta: 17:56:33, time (data): 1.099 (0.003)] l_pix: 2.8545e-02 
2024-05-19 07:56:59,166 INFO: [train..][epoch:436, iter: 193,200, lr:(5.000e-05,)] [eta: 17:52:48, time (data): 1.085 (0.002)] l_pix: 1.6886e-02 
2024-05-19 08:00:37,549 INFO: [train..][epoch:436, iter: 193,400, lr:(5.000e-05,)] [eta: 17:48:59, time (data): 1.099 (0.003)] l_pix: 3.3217e-02 
2024-05-19 08:04:29,598 INFO: [train..][epoch:437, iter: 193,600, lr:(5.000e-05,)] [eta: 17:45:14, time (data): 1.428 (0.337)] l_pix: 1.6517e-02 
2024-05-19 08:08:07,432 INFO: [train..][epoch:437, iter: 193,800, lr:(5.000e-05,)] [eta: 17:41:25, time (data): 1.092 (0.004)] l_pix: 2.5373e-02 
2024-05-19 08:11:46,336 INFO: [train..][epoch:437, iter: 194,000, lr:(5.000e-05,)] [eta: 17:37:36, time (data): 1.100 (0.004)] l_pix: 1.9261e-02 
2024-05-19 08:15:37,075 INFO: [train..][epoch:438, iter: 194,200, lr:(5.000e-05,)] [eta: 17:33:50, time (data): 1.102 (0.004)] l_pix: 4.0038e-02 
2024-05-19 08:19:17,168 INFO: [train..][epoch:438, iter: 194,400, lr:(5.000e-05,)] [eta: 17:30:02, time (data): 1.095 (0.004)] l_pix: 1.7893e-02 
2024-05-19 08:23:07,081 INFO: [train..][epoch:439, iter: 194,600, lr:(5.000e-05,)] [eta: 17:26:16, time (data): 1.089 (0.004)] l_pix: 1.5032e-02 
2024-05-19 08:26:46,595 INFO: [train..][epoch:439, iter: 194,800, lr:(5.000e-05,)] [eta: 17:22:27, time (data): 1.099 (0.003)] l_pix: 2.3527e-02 
2024-05-19 08:30:37,039 INFO: [train..][epoch:440, iter: 195,000, lr:(5.000e-05,)] [eta: 17:18:42, time (data): 1.088 (0.004)] l_pix: 1.2653e-02 
2024-05-19 08:30:37,041 INFO: Saving models and training states.
2024-05-19 08:30:38,444 INFO: Validation Set5
	 # psnr: 32.9774	Best: 32.9774 @ 195000 iter

2024-05-19 08:34:17,698 INFO: [train..][epoch:440, iter: 195,200, lr:(5.000e-05,)] [eta: 17:14:54, time (data): 1.100 (0.004)] l_pix: 2.1127e-02 
2024-05-19 08:38:08,664 INFO: [train..][epoch:441, iter: 195,400, lr:(5.000e-05,)] [eta: 17:11:08, time (data): 1.085 (0.002)] l_pix: 2.6678e-02 
2024-05-19 08:41:46,729 INFO: [train..][epoch:441, iter: 195,600, lr:(5.000e-05,)] [eta: 17:07:19, time (data): 1.096 (0.003)] l_pix: 2.4942e-02 
2024-05-19 08:45:26,285 INFO: [train..][epoch:441, iter: 195,800, lr:(5.000e-05,)] [eta: 17:03:31, time (data): 1.096 (0.003)] l_pix: 2.4785e-02 
2024-05-19 08:49:16,050 INFO: [train..][epoch:442, iter: 196,000, lr:(5.000e-05,)] [eta: 16:59:45, time (data): 1.089 (0.003)] l_pix: 2.2895e-02 
2024-05-19 08:52:55,433 INFO: [train..][epoch:442, iter: 196,200, lr:(5.000e-05,)] [eta: 16:55:56, time (data): 1.096 (0.003)] l_pix: 3.0691e-02 
2024-05-19 08:56:45,795 INFO: [train..][epoch:443, iter: 196,400, lr:(5.000e-05,)] [eta: 16:52:11, time (data): 1.093 (0.003)] l_pix: 1.8613e-02 
2024-05-19 09:00:25,145 INFO: [train..][epoch:443, iter: 196,600, lr:(5.000e-05,)] [eta: 16:48:22, time (data): 1.096 (0.003)] l_pix: 2.1311e-02 
2024-05-19 09:04:15,784 INFO: [train..][epoch:444, iter: 196,800, lr:(5.000e-05,)] [eta: 16:44:37, time (data): 1.088 (0.003)] l_pix: 2.2904e-02 
2024-05-19 09:07:54,189 INFO: [train..][epoch:444, iter: 197,000, lr:(5.000e-05,)] [eta: 16:40:48, time (data): 1.093 (0.003)] l_pix: 1.3741e-02 
2024-05-19 09:11:44,751 INFO: [train..][epoch:445, iter: 197,200, lr:(5.000e-05,)] [eta: 16:37:02, time (data): 1.086 (0.003)] l_pix: 3.9067e-02 
2024-05-19 09:15:23,583 INFO: [train..][epoch:445, iter: 197,400, lr:(5.000e-05,)] [eta: 16:33:14, time (data): 1.092 (0.003)] l_pix: 3.3026e-02 
2024-05-19 09:19:14,135 INFO: [train..][epoch:446, iter: 197,600, lr:(5.000e-05,)] [eta: 16:29:28, time (data): 1.087 (0.003)] l_pix: 2.8115e-02 
2024-05-19 09:22:53,266 INFO: [train..][epoch:446, iter: 197,800, lr:(5.000e-05,)] [eta: 16:25:39, time (data): 1.104 (0.003)] l_pix: 3.0213e-02 
2024-05-19 09:26:32,505 INFO: [train..][epoch:446, iter: 198,000, lr:(5.000e-05,)] [eta: 16:21:51, time (data): 1.102 (0.003)] l_pix: 1.8341e-02 
2024-05-19 09:30:23,270 INFO: [train..][epoch:447, iter: 198,200, lr:(5.000e-05,)] [eta: 16:18:05, time (data): 1.097 (0.003)] l_pix: 2.2836e-02 
2024-05-19 09:34:02,196 INFO: [train..][epoch:447, iter: 198,400, lr:(5.000e-05,)] [eta: 16:14:17, time (data): 1.093 (0.003)] l_pix: 2.3969e-02 
2024-05-19 09:37:52,809 INFO: [train..][epoch:448, iter: 198,600, lr:(5.000e-05,)] [eta: 16:10:31, time (data): 1.099 (0.004)] l_pix: 2.5281e-02 
2024-05-19 09:41:32,922 INFO: [train..][epoch:448, iter: 198,800, lr:(5.000e-05,)] [eta: 16:06:43, time (data): 1.102 (0.004)] l_pix: 1.1299e-02 
2024-05-19 09:45:23,295 INFO: [train..][epoch:449, iter: 199,000, lr:(5.000e-05,)] [eta: 16:02:57, time (data): 1.087 (0.004)] l_pix: 2.0409e-02 
2024-05-19 09:49:02,787 INFO: [train..][epoch:449, iter: 199,200, lr:(5.000e-05,)] [eta: 15:59:09, time (data): 1.106 (0.003)] l_pix: 2.0906e-02 
2024-05-19 09:52:53,602 INFO: [train..][epoch:450, iter: 199,400, lr:(5.000e-05,)] [eta: 15:55:24, time (data): 1.086 (0.003)] l_pix: 2.6201e-02 
2024-05-19 09:56:31,800 INFO: [train..][epoch:450, iter: 199,600, lr:(5.000e-05,)] [eta: 15:51:35, time (data): 1.091 (0.003)] l_pix: 3.7983e-02 
2024-05-19 10:00:23,446 INFO: [train..][epoch:451, iter: 199,800, lr:(5.000e-05,)] [eta: 15:47:50, time (data): 1.085 (0.003)] l_pix: 2.0873e-02 
2024-05-19 10:04:01,548 INFO: [train..][epoch:451, iter: 200,000, lr:(5.000e-05,)] [eta: 15:44:01, time (data): 1.093 (0.003)] l_pix: 1.8716e-02 
2024-05-19 10:04:01,548 INFO: Saving models and training states.
2024-05-19 10:04:02,987 INFO: Validation Set5
	 # psnr: 32.9435	Best: 32.9774 @ 195000 iter

2024-05-19 10:07:41,621 INFO: [train..][epoch:451, iter: 200,200, lr:(2.500e-05,)] [eta: 15:40:13, time (data): 1.109 (0.003)] l_pix: 3.6350e-02 
2024-05-19 10:11:32,323 INFO: [train..][epoch:452, iter: 200,400, lr:(2.500e-05,)] [eta: 15:36:27, time (data): 1.086 (0.003)] l_pix: 2.6075e-02 
2024-05-19 10:15:10,972 INFO: [train..][epoch:452, iter: 200,600, lr:(2.500e-05,)] [eta: 15:32:39, time (data): 1.098 (0.003)] l_pix: 2.2869e-02 
2024-05-19 10:19:01,086 INFO: [train..][epoch:453, iter: 200,800, lr:(2.500e-05,)] [eta: 15:28:53, time (data): 1.094 (0.002)] l_pix: 2.9940e-02 
2024-05-19 10:22:40,669 INFO: [train..][epoch:453, iter: 201,000, lr:(2.500e-05,)] [eta: 15:25:05, time (data): 1.098 (0.003)] l_pix: 1.9709e-02 
2024-05-19 10:26:31,457 INFO: [train..][epoch:454, iter: 201,200, lr:(2.500e-05,)] [eta: 15:21:19, time (data): 1.154 (0.064)] l_pix: 1.8320e-02 
2024-05-19 10:30:10,707 INFO: [train..][epoch:454, iter: 201,400, lr:(2.500e-05,)] [eta: 15:17:31, time (data): 1.096 (0.003)] l_pix: 2.0986e-02 
2024-05-19 10:34:01,862 INFO: [train..][epoch:455, iter: 201,600, lr:(2.500e-05,)] [eta: 15:13:45, time (data): 1.156 (0.064)] l_pix: 1.6954e-02 
2024-05-19 10:37:39,831 INFO: [train..][epoch:455, iter: 201,800, lr:(2.500e-05,)] [eta: 15:09:57, time (data): 1.090 (0.003)] l_pix: 1.8957e-02 
2024-05-19 10:41:19,640 INFO: [train..][epoch:455, iter: 202,000, lr:(2.500e-05,)] [eta: 15:06:09, time (data): 1.099 (0.004)] l_pix: 2.8346e-02 
2024-05-19 10:45:09,864 INFO: [train..][epoch:456, iter: 202,200, lr:(2.500e-05,)] [eta: 15:02:23, time (data): 1.152 (0.065)] l_pix: 2.1081e-02 
2024-05-19 10:48:48,432 INFO: [train..][epoch:456, iter: 202,400, lr:(2.500e-05,)] [eta: 14:58:34, time (data): 1.093 (0.003)] l_pix: 2.1536e-02 
2024-05-19 10:52:38,778 INFO: [train..][epoch:457, iter: 202,600, lr:(2.500e-05,)] [eta: 14:54:49, time (data): 1.154 (0.065)] l_pix: 1.3750e-02 
2024-05-19 10:56:17,769 INFO: [train..][epoch:457, iter: 202,800, lr:(2.500e-05,)] [eta: 14:51:01, time (data): 1.095 (0.003)] l_pix: 3.4653e-02 
2024-05-19 11:00:08,118 INFO: [train..][epoch:458, iter: 203,000, lr:(2.500e-05,)] [eta: 14:47:15, time (data): 1.155 (0.065)] l_pix: 2.5423e-02 
2024-05-19 11:03:47,746 INFO: [train..][epoch:458, iter: 203,200, lr:(2.500e-05,)] [eta: 14:43:27, time (data): 1.098 (0.003)] l_pix: 1.7823e-02 
2024-05-19 11:07:38,617 INFO: [train..][epoch:459, iter: 203,400, lr:(2.500e-05,)] [eta: 14:39:41, time (data): 1.158 (0.068)] l_pix: 1.4661e-02 
2024-05-19 11:11:17,144 INFO: [train..][epoch:459, iter: 203,600, lr:(2.500e-05,)] [eta: 14:35:53, time (data): 1.093 (0.003)] l_pix: 2.8487e-02 
2024-05-19 11:15:08,617 INFO: [train..][epoch:460, iter: 203,800, lr:(2.500e-05,)] [eta: 14:32:07, time (data): 1.161 (0.067)] l_pix: 2.0153e-02 
2024-05-19 11:18:46,536 INFO: [train..][epoch:460, iter: 204,000, lr:(2.500e-05,)] [eta: 14:28:19, time (data): 1.090 (0.003)] l_pix: 1.7749e-02 
2024-05-19 11:22:26,389 INFO: [train..][epoch:460, iter: 204,200, lr:(2.500e-05,)] [eta: 14:24:31, time (data): 1.100 (0.003)] l_pix: 2.9757e-02 
2024-05-19 11:26:16,696 INFO: [train..][epoch:461, iter: 204,400, lr:(2.500e-05,)] [eta: 14:20:45, time (data): 1.156 (0.069)] l_pix: 1.5854e-02 
2024-05-19 11:29:55,232 INFO: [train..][epoch:461, iter: 204,600, lr:(2.500e-05,)] [eta: 14:16:57, time (data): 1.093 (0.003)] l_pix: 1.5383e-02 
2024-05-19 11:33:45,311 INFO: [train..][epoch:462, iter: 204,800, lr:(2.500e-05,)] [eta: 14:13:11, time (data): 1.156 (0.068)] l_pix: 2.1877e-02 
2024-05-19 11:37:24,497 INFO: [train..][epoch:462, iter: 205,000, lr:(2.500e-05,)] [eta: 14:09:23, time (data): 1.095 (0.003)] l_pix: 2.4889e-02 
2024-05-19 11:37:24,497 INFO: Saving models and training states.
2024-05-19 11:37:25,891 INFO: Validation Set5
	 # psnr: 32.9503	Best: 32.9774 @ 195000 iter

2024-05-19 11:41:16,300 INFO: [train..][epoch:463, iter: 205,200, lr:(2.500e-05,)] [eta: 14:05:38, time (data): 1.158 (0.070)] l_pix: 2.5032e-02 
2024-05-19 11:44:55,810 INFO: [train..][epoch:463, iter: 205,400, lr:(2.500e-05,)] [eta: 14:01:50, time (data): 1.098 (0.003)] l_pix: 1.5605e-02 
2024-05-19 11:48:47,062 INFO: [train..][epoch:464, iter: 205,600, lr:(2.500e-05,)] [eta: 13:58:04, time (data): 1.164 (0.073)] l_pix: 2.0473e-02 
2024-05-19 11:52:25,273 INFO: [train..][epoch:464, iter: 205,800, lr:(2.500e-05,)] [eta: 13:54:16, time (data): 1.091 (0.003)] l_pix: 2.2482e-02 
2024-05-19 11:56:16,695 INFO: [train..][epoch:465, iter: 206,000, lr:(2.500e-05,)] [eta: 13:50:31, time (data): 1.165 (0.071)] l_pix: 1.6003e-02 
2024-05-19 11:59:54,599 INFO: [train..][epoch:465, iter: 206,200, lr:(2.500e-05,)] [eta: 13:46:42, time (data): 1.090 (0.003)] l_pix: 1.9363e-02 
2024-05-19 12:03:33,954 INFO: [train..][epoch:465, iter: 206,400, lr:(2.500e-05,)] [eta: 13:42:54, time (data): 1.097 (0.003)] l_pix: 1.8076e-02 
2024-05-19 12:07:24,280 INFO: [train..][epoch:466, iter: 206,600, lr:(2.500e-05,)] [eta: 13:39:08, time (data): 1.160 (0.073)] l_pix: 2.9604e-02 
2024-05-19 12:11:02,708 INFO: [train..][epoch:466, iter: 206,800, lr:(2.500e-05,)] [eta: 13:35:20, time (data): 1.092 (0.003)] l_pix: 2.1434e-02 
2024-05-19 12:14:52,777 INFO: [train..][epoch:467, iter: 207,000, lr:(2.500e-05,)] [eta: 13:31:35, time (data): 1.161 (0.074)] l_pix: 1.4570e-02 
2024-05-19 12:18:32,601 INFO: [train..][epoch:467, iter: 207,200, lr:(2.500e-05,)] [eta: 13:27:47, time (data): 1.100 (0.004)] l_pix: 2.6165e-02 
2024-05-19 12:22:23,277 INFO: [train..][epoch:468, iter: 207,400, lr:(2.500e-05,)] [eta: 13:24:01, time (data): 1.164 (0.075)] l_pix: 1.4062e-02 
2024-05-19 12:26:02,203 INFO: [train..][epoch:468, iter: 207,600, lr:(2.500e-05,)] [eta: 13:20:13, time (data): 1.096 (0.003)] l_pix: 2.2467e-02 
2024-05-19 12:29:53,661 INFO: [train..][epoch:469, iter: 207,800, lr:(2.500e-05,)] [eta: 13:16:28, time (data): 1.168 (0.076)] l_pix: 2.6056e-02 
2024-05-19 12:33:31,706 INFO: [train..][epoch:469, iter: 208,000, lr:(2.500e-05,)] [eta: 13:12:39, time (data): 1.091 (0.003)] l_pix: 1.0719e-02 
2024-05-19 12:37:10,857 INFO: [train..][epoch:469, iter: 208,200, lr:(2.500e-05,)] [eta: 13:08:51, time (data): 1.097 (0.003)] l_pix: 2.2168e-02 
2024-05-19 12:41:01,190 INFO: [train..][epoch:470, iter: 208,400, lr:(2.500e-05,)] [eta: 13:05:06, time (data): 1.091 (0.003)] l_pix: 2.2025e-02 
2024-05-19 12:44:40,280 INFO: [train..][epoch:470, iter: 208,600, lr:(2.500e-05,)] [eta: 13:01:18, time (data): 1.095 (0.003)] l_pix: 2.1330e-02 
2024-05-19 12:48:30,845 INFO: [train..][epoch:471, iter: 208,800, lr:(2.500e-05,)] [eta: 12:57:32, time (data): 1.166 (0.080)] l_pix: 2.3140e-02 
2024-05-19 12:52:09,668 INFO: [train..][epoch:471, iter: 209,000, lr:(2.500e-05,)] [eta: 12:53:44, time (data): 1.094 (0.003)] l_pix: 2.8085e-02 
2024-05-19 12:55:59,753 INFO: [train..][epoch:472, iter: 209,200, lr:(2.500e-05,)] [eta: 12:49:58, time (data): 1.165 (0.078)] l_pix: 1.7703e-02 
2024-05-19 12:59:38,464 INFO: [train..][epoch:472, iter: 209,400, lr:(2.500e-05,)] [eta: 12:46:10, time (data): 1.096 (0.003)] l_pix: 2.9626e-02 
2024-05-19 13:03:29,897 INFO: [train..][epoch:473, iter: 209,600, lr:(2.500e-05,)] [eta: 12:42:25, time (data): 1.173 (0.081)] l_pix: 2.7525e-02 
2024-05-19 13:07:07,996 INFO: [train..][epoch:473, iter: 209,800, lr:(2.500e-05,)] [eta: 12:38:37, time (data): 1.091 (0.003)] l_pix: 1.8178e-02 
2024-05-19 13:10:59,645 INFO: [train..][epoch:474, iter: 210,000, lr:(2.500e-05,)] [eta: 12:34:51, time (data): 1.176 (0.081)] l_pix: 1.4543e-02 
2024-05-19 13:10:59,645 INFO: Saving models and training states.
2024-05-19 13:11:00,997 INFO: Validation Set5
	 # psnr: 32.9417	Best: 32.9774 @ 195000 iter

2024-05-19 13:14:39,199 INFO: [train..][epoch:474, iter: 210,200, lr:(2.500e-05,)] [eta: 12:31:04, time (data): 1.092 (0.004)] l_pix: 1.3230e-02 
2024-05-19 13:18:18,094 INFO: [train..][epoch:474, iter: 210,400, lr:(2.500e-05,)] [eta: 12:27:16, time (data): 1.094 (0.003)] l_pix: 2.0159e-02 
2024-05-19 13:22:08,400 INFO: [train..][epoch:475, iter: 210,600, lr:(2.500e-05,)] [eta: 12:23:30, time (data): 1.091 (0.003)] l_pix: 2.8414e-02 
2024-05-19 13:25:47,733 INFO: [train..][epoch:475, iter: 210,800, lr:(2.500e-05,)] [eta: 12:19:42, time (data): 1.097 (0.003)] l_pix: 2.0653e-02 
2024-05-19 13:29:37,835 INFO: [train..][epoch:476, iter: 211,000, lr:(2.500e-05,)] [eta: 12:15:56, time (data): 1.169 (0.083)] l_pix: 2.7269e-02 
2024-05-19 13:33:16,923 INFO: [train..][epoch:476, iter: 211,200, lr:(2.500e-05,)] [eta: 12:12:09, time (data): 1.096 (0.003)] l_pix: 1.0536e-02 
2024-05-19 13:37:07,287 INFO: [train..][epoch:477, iter: 211,400, lr:(2.500e-05,)] [eta: 12:08:23, time (data): 1.171 (0.084)] l_pix: 2.2271e-02 
2024-05-19 13:40:45,882 INFO: [train..][epoch:477, iter: 211,600, lr:(2.500e-05,)] [eta: 12:04:35, time (data): 1.095 (0.003)] l_pix: 3.4801e-02 
2024-05-19 13:44:36,965 INFO: [train..][epoch:478, iter: 211,800, lr:(2.500e-05,)] [eta: 12:00:49, time (data): 1.176 (0.085)] l_pix: 3.5918e-02 
2024-05-19 13:48:15,334 INFO: [train..][epoch:478, iter: 212,000, lr:(2.500e-05,)] [eta: 11:57:01, time (data): 1.093 (0.003)] l_pix: 4.8026e-02 
2024-05-19 13:53:35,241 INFO: [train..][epoch:479, iter: 212,200, lr:(2.500e-05,)] [eta: 11:53:32, time (data): 1.789 (0.115)] l_pix: 1.2560e-02 
2024-05-19 13:57:28,607 INFO: [train..][epoch:479, iter: 212,400, lr:(2.500e-05,)] [eta: 11:49:46, time (data): 1.101 (0.004)] l_pix: 2.9798e-02 
2024-05-19 14:01:08,847 INFO: [train..][epoch:479, iter: 212,600, lr:(2.500e-05,)] [eta: 11:45:59, time (data): 1.102 (0.003)] l_pix: 2.1177e-02 
2024-05-19 14:04:59,640 INFO: [train..][epoch:480, iter: 212,800, lr:(2.500e-05,)] [eta: 11:42:13, time (data): 1.091 (0.003)] l_pix: 2.5438e-02 
2024-05-19 14:08:38,574 INFO: [train..][epoch:480, iter: 213,000, lr:(2.500e-05,)] [eta: 11:38:25, time (data): 1.095 (0.003)] l_pix: 2.6271e-02 
2024-05-19 14:12:29,724 INFO: [train..][epoch:481, iter: 213,200, lr:(2.500e-05,)] [eta: 11:34:39, time (data): 1.181 (0.091)] l_pix: 2.4980e-02 
2024-05-19 14:16:11,594 INFO: [train..][epoch:481, iter: 213,400, lr:(2.500e-05,)] [eta: 11:30:52, time (data): 1.114 (0.003)] l_pix: 2.0834e-02 
2024-05-19 14:20:17,826 INFO: [train..][epoch:482, iter: 213,600, lr:(2.500e-05,)] [eta: 11:27:09, time (data): 1.281 (0.167)] l_pix: 2.2802e-02 
2024-05-19 14:24:32,783 INFO: [train..][epoch:482, iter: 213,800, lr:(2.500e-05,)] [eta: 11:23:27, time (data): 1.321 (0.003)] l_pix: 4.4460e-02 
2024-05-19 14:30:28,544 INFO: [train..][epoch:483, iter: 214,000, lr:(2.500e-05,)] [eta: 11:20:02, time (data): 1.921 (0.147)] l_pix: 3.3617e-02 
2024-05-19 14:35:53,252 INFO: [train..][epoch:483, iter: 214,200, lr:(2.500e-05,)] [eta: 11:16:32, time (data): 1.509 (0.004)] l_pix: 1.9730e-02 
2024-05-19 14:39:33,636 INFO: [train..][epoch:483, iter: 214,400, lr:(2.500e-05,)] [eta: 11:12:44, time (data): 1.100 (0.003)] l_pix: 1.8531e-02 
2024-05-19 14:43:24,934 INFO: [train..][epoch:484, iter: 214,600, lr:(2.500e-05,)] [eta: 11:08:58, time (data): 1.095 (0.003)] l_pix: 2.5416e-02 
2024-05-19 14:47:04,316 INFO: [train..][epoch:484, iter: 214,800, lr:(2.500e-05,)] [eta: 11:05:10, time (data): 1.096 (0.003)] l_pix: 2.2672e-02 
2024-05-19 14:50:54,483 INFO: [train..][epoch:485, iter: 215,000, lr:(2.500e-05,)] [eta: 11:01:24, time (data): 1.090 (0.003)] l_pix: 2.9744e-02 
2024-05-19 14:50:54,484 INFO: Saving models and training states.
2024-05-19 14:50:56,802 INFO: Validation Set5
	 # psnr: 32.9767	Best: 32.9774 @ 195000 iter

2024-05-19 14:54:36,523 INFO: [train..][epoch:485, iter: 215,200, lr:(2.500e-05,)] [eta: 10:57:36, time (data): 1.099 (0.003)] l_pix: 1.2451e-02 
2024-05-19 14:58:29,319 INFO: [train..][epoch:486, iter: 215,400, lr:(2.500e-05,)] [eta: 10:53:51, time (data): 1.200 (0.113)] l_pix: 5.2062e-02 
2024-05-19 15:02:10,238 INFO: [train..][epoch:486, iter: 215,600, lr:(2.500e-05,)] [eta: 10:50:03, time (data): 1.109 (0.004)] l_pix: 2.8916e-02 
2024-05-19 15:06:03,562 INFO: [train..][epoch:487, iter: 215,800, lr:(2.500e-05,)] [eta: 10:46:17, time (data): 1.199 (0.102)] l_pix: 2.7918e-02 
2024-05-19 15:09:41,752 INFO: [train..][epoch:487, iter: 216,000, lr:(2.500e-05,)] [eta: 10:42:29, time (data): 1.091 (0.003)] l_pix: 4.6497e-02 
2024-05-19 15:13:33,570 INFO: [train..][epoch:488, iter: 216,200, lr:(2.500e-05,)] [eta: 10:38:43, time (data): 1.196 (0.100)] l_pix: 3.0627e-02 
2024-05-19 15:17:11,814 INFO: [train..][epoch:488, iter: 216,400, lr:(2.500e-05,)] [eta: 10:34:55, time (data): 1.093 (0.003)] l_pix: 2.1340e-02 
2024-05-19 15:20:51,426 INFO: [train..][epoch:488, iter: 216,600, lr:(2.500e-05,)] [eta: 10:31:07, time (data): 1.100 (0.003)] l_pix: 1.6418e-02 
2024-05-19 15:24:42,504 INFO: [train..][epoch:489, iter: 216,800, lr:(2.500e-05,)] [eta: 10:27:21, time (data): 1.097 (0.004)] l_pix: 3.1985e-02 
2024-05-19 15:28:21,522 INFO: [train..][epoch:489, iter: 217,000, lr:(2.500e-05,)] [eta: 10:23:33, time (data): 1.094 (0.003)] l_pix: 2.3970e-02 
2024-05-19 15:32:12,121 INFO: [train..][epoch:490, iter: 217,200, lr:(2.500e-05,)] [eta: 10:19:47, time (data): 1.091 (0.003)] l_pix: 1.8004e-02 
2024-05-19 15:35:52,748 INFO: [train..][epoch:490, iter: 217,400, lr:(2.500e-05,)] [eta: 10:15:59, time (data): 1.102 (0.003)] l_pix: 2.5903e-02 
2024-05-19 15:39:43,216 INFO: [train..][epoch:491, iter: 217,600, lr:(2.500e-05,)] [eta: 10:12:13, time (data): 1.192 (0.106)] l_pix: 1.2680e-02 
2024-05-19 15:43:22,493 INFO: [train..][epoch:491, iter: 217,800, lr:(2.500e-05,)] [eta: 10:08:25, time (data): 1.096 (0.003)] l_pix: 1.6957e-02 
2024-05-19 15:47:13,415 INFO: [train..][epoch:492, iter: 218,000, lr:(2.500e-05,)] [eta: 10:04:39, time (data): 1.197 (0.108)] l_pix: 3.7639e-02 
2024-05-19 15:50:52,726 INFO: [train..][epoch:492, iter: 218,200, lr:(2.500e-05,)] [eta: 10:00:51, time (data): 1.099 (0.003)] l_pix: 1.9638e-02 
2024-05-19 15:54:43,849 INFO: [train..][epoch:493, iter: 218,400, lr:(2.500e-05,)] [eta: 9:57:05, time (data): 1.201 (0.110)] l_pix: 1.8813e-02 
2024-05-19 15:58:22,039 INFO: [train..][epoch:493, iter: 218,600, lr:(2.500e-05,)] [eta: 9:53:17, time (data): 1.093 (0.003)] l_pix: 1.8106e-02 
2024-05-19 16:02:01,515 INFO: [train..][epoch:493, iter: 218,800, lr:(2.500e-05,)] [eta: 9:49:29, time (data): 1.096 (0.003)] l_pix: 2.0762e-02 
2024-05-19 16:05:51,686 INFO: [train..][epoch:494, iter: 219,000, lr:(2.500e-05,)] [eta: 9:45:43, time (data): 1.090 (0.004)] l_pix: 2.7084e-02 
2024-05-19 16:09:31,648 INFO: [train..][epoch:494, iter: 219,200, lr:(2.500e-05,)] [eta: 9:41:55, time (data): 1.099 (0.003)] l_pix: 4.3207e-02 
2024-05-19 16:13:21,887 INFO: [train..][epoch:495, iter: 219,400, lr:(2.500e-05,)] [eta: 9:38:09, time (data): 1.086 (0.003)] l_pix: 2.9997e-02 
2024-05-19 16:17:01,806 INFO: [train..][epoch:495, iter: 219,600, lr:(2.500e-05,)] [eta: 9:34:21, time (data): 1.105 (0.003)] l_pix: 4.2130e-02 
2024-05-19 16:20:53,672 INFO: [train..][epoch:496, iter: 219,800, lr:(2.500e-05,)] [eta: 9:30:35, time (data): 1.210 (0.115)] l_pix: 3.7126e-02 
2024-05-19 16:24:32,040 INFO: [train..][epoch:496, iter: 220,000, lr:(2.500e-05,)] [eta: 9:26:48, time (data): 1.094 (0.004)] l_pix: 1.8280e-02 
2024-05-19 16:24:32,041 INFO: Saving models and training states.
2024-05-19 16:24:33,419 INFO: Validation Set5
	 # psnr: 32.9336	Best: 32.9774 @ 195000 iter

2024-05-19 16:28:25,013 INFO: [train..][epoch:497, iter: 220,200, lr:(2.500e-05,)] [eta: 9:23:02, time (data): 1.214 (0.120)] l_pix: 2.0912e-02 
2024-05-19 16:32:04,071 INFO: [train..][epoch:497, iter: 220,400, lr:(2.500e-05,)] [eta: 9:19:14, time (data): 1.094 (0.003)] l_pix: 2.0251e-02 
2024-05-19 16:35:42,704 INFO: [train..][epoch:497, iter: 220,600, lr:(2.500e-05,)] [eta: 9:15:26, time (data): 1.094 (0.003)] l_pix: 2.8146e-02 
2024-05-19 16:39:33,618 INFO: [train..][epoch:498, iter: 220,800, lr:(2.500e-05,)] [eta: 9:11:40, time (data): 1.097 (0.003)] l_pix: 3.9708e-02 
2024-05-19 16:43:12,818 INFO: [train..][epoch:498, iter: 221,000, lr:(2.500e-05,)] [eta: 9:07:52, time (data): 1.095 (0.004)] l_pix: 1.1963e-02 
2024-05-19 16:47:03,182 INFO: [train..][epoch:499, iter: 221,200, lr:(2.500e-05,)] [eta: 9:04:06, time (data): 1.090 (0.003)] l_pix: 2.1856e-02 
2024-05-19 16:50:42,755 INFO: [train..][epoch:499, iter: 221,400, lr:(2.500e-05,)] [eta: 9:00:18, time (data): 1.097 (0.003)] l_pix: 2.1723e-02 
2024-05-19 16:54:32,962 INFO: [train..][epoch:500, iter: 221,600, lr:(2.500e-05,)] [eta: 8:56:32, time (data): 1.087 (0.003)] l_pix: 2.2959e-02 
2024-05-19 16:58:11,744 INFO: [train..][epoch:500, iter: 221,800, lr:(2.500e-05,)] [eta: 8:52:44, time (data): 1.098 (0.003)] l_pix: 2.5946e-02 
2024-05-19 17:02:02,769 INFO: [train..][epoch:501, iter: 222,000, lr:(2.500e-05,)] [eta: 8:48:58, time (data): 1.216 (0.129)] l_pix: 2.0958e-02 
2024-05-19 17:05:41,117 INFO: [train..][epoch:501, iter: 222,200, lr:(2.500e-05,)] [eta: 8:45:10, time (data): 1.096 (0.003)] l_pix: 2.1945e-02 
2024-05-19 17:09:32,824 INFO: [train..][epoch:502, iter: 222,400, lr:(2.500e-05,)] [eta: 8:41:24, time (data): 1.226 (0.132)] l_pix: 2.6367e-02 
2024-05-19 17:13:12,152 INFO: [train..][epoch:502, iter: 222,600, lr:(2.500e-05,)] [eta: 8:37:37, time (data): 1.101 (0.003)] l_pix: 2.3090e-02 
2024-05-19 17:16:51,267 INFO: [train..][epoch:502, iter: 222,800, lr:(2.500e-05,)] [eta: 8:33:49, time (data): 1.097 (0.003)] l_pix: 1.6335e-02 
2024-05-19 17:20:41,568 INFO: [train..][epoch:503, iter: 223,000, lr:(2.500e-05,)] [eta: 8:30:03, time (data): 1.092 (0.003)] l_pix: 2.6422e-02 
2024-05-19 17:24:20,641 INFO: [train..][epoch:503, iter: 223,200, lr:(2.500e-05,)] [eta: 8:26:15, time (data): 1.096 (0.003)] l_pix: 2.3224e-02 
2024-05-19 17:28:11,883 INFO: [train..][epoch:504, iter: 223,400, lr:(2.500e-05,)] [eta: 8:22:29, time (data): 1.094 (0.004)] l_pix: 2.3527e-02 
2024-05-19 17:31:51,263 INFO: [train..][epoch:504, iter: 223,600, lr:(2.500e-05,)] [eta: 8:18:41, time (data): 1.096 (0.004)] l_pix: 1.5977e-02 
2024-05-19 17:35:41,738 INFO: [train..][epoch:505, iter: 223,800, lr:(2.500e-05,)] [eta: 8:14:55, time (data): 1.227 (0.142)] l_pix: 2.5903e-02 
2024-05-19 17:39:21,800 INFO: [train..][epoch:505, iter: 224,000, lr:(2.500e-05,)] [eta: 8:11:08, time (data): 1.102 (0.003)] l_pix: 2.3407e-02 
2024-05-19 17:43:18,040 INFO: [train..][epoch:506, iter: 224,200, lr:(2.500e-05,)] [eta: 8:07:22, time (data): 1.282 (0.184)] l_pix: 2.1294e-02 
2024-05-19 17:46:59,392 INFO: [train..][epoch:506, iter: 224,400, lr:(2.500e-05,)] [eta: 8:03:35, time (data): 1.115 (0.003)] l_pix: 1.0464e-02 
2024-05-19 17:50:41,189 INFO: [train..][epoch:506, iter: 224,600, lr:(2.500e-05,)] [eta: 7:59:48, time (data): 1.104 (0.003)] l_pix: 3.3349e-02 
2024-05-19 17:54:38,442 INFO: [train..][epoch:507, iter: 224,800, lr:(2.500e-05,)] [eta: 7:56:02, time (data): 1.101 (0.004)] l_pix: 1.9752e-02 
2024-05-19 17:58:20,123 INFO: [train..][epoch:507, iter: 225,000, lr:(2.500e-05,)] [eta: 7:52:15, time (data): 1.109 (0.004)] l_pix: 4.2509e-02 
2024-05-19 17:58:20,126 INFO: Saving models and training states.
2024-05-19 17:58:23,432 INFO: Validation Set5
	 # psnr: 32.9670	Best: 32.9774 @ 195000 iter

2024-05-19 18:02:26,145 INFO: [train..][epoch:508, iter: 225,200, lr:(1.250e-05,)] [eta: 7:48:30, time (data): 1.101 (0.003)] l_pix: 1.5385e-02 
2024-05-19 18:06:07,641 INFO: [train..][epoch:508, iter: 225,400, lr:(1.250e-05,)] [eta: 7:44:43, time (data): 1.112 (0.003)] l_pix: 2.8727e-02 
2024-05-19 18:10:12,539 INFO: [train..][epoch:509, iter: 225,600, lr:(1.250e-05,)] [eta: 7:40:58, time (data): 1.107 (0.005)] l_pix: 3.2511e-02 
2024-05-19 18:13:52,796 INFO: [train..][epoch:509, iter: 225,800, lr:(1.250e-05,)] [eta: 7:37:11, time (data): 1.103 (0.004)] l_pix: 2.7623e-02 
2024-05-19 18:17:51,122 INFO: [train..][epoch:510, iter: 226,000, lr:(1.250e-05,)] [eta: 7:33:25, time (data): 1.339 (0.249)] l_pix: 3.0010e-02 
2024-05-19 18:21:30,095 INFO: [train..][epoch:510, iter: 226,200, lr:(1.250e-05,)] [eta: 7:29:38, time (data): 1.097 (0.003)] l_pix: 2.9461e-02 
2024-05-19 18:25:22,350 INFO: [train..][epoch:511, iter: 226,400, lr:(1.250e-05,)] [eta: 7:25:52, time (data): 1.268 (0.177)] l_pix: 1.4036e-02 
2024-05-19 18:29:01,460 INFO: [train..][epoch:511, iter: 226,600, lr:(1.250e-05,)] [eta: 7:22:04, time (data): 1.097 (0.003)] l_pix: 1.4607e-02 
2024-05-19 18:32:40,880 INFO: [train..][epoch:511, iter: 226,800, lr:(1.250e-05,)] [eta: 7:18:17, time (data): 1.095 (0.003)] l_pix: 1.4544e-02 
2024-05-19 18:36:31,703 INFO: [train..][epoch:512, iter: 227,000, lr:(1.250e-05,)] [eta: 7:14:30, time (data): 1.095 (0.003)] l_pix: 2.6786e-02 
2024-05-19 18:40:11,334 INFO: [train..][epoch:512, iter: 227,200, lr:(1.250e-05,)] [eta: 7:10:43, time (data): 1.096 (0.003)] l_pix: 1.6492e-02 
2024-05-19 18:44:01,767 INFO: [train..][epoch:513, iter: 227,400, lr:(1.250e-05,)] [eta: 7:06:57, time (data): 1.089 (0.004)] l_pix: 1.9273e-02 
2024-05-19 18:47:40,786 INFO: [train..][epoch:513, iter: 227,600, lr:(1.250e-05,)] [eta: 7:03:09, time (data): 1.099 (0.003)] l_pix: 1.6340e-02 
2024-05-19 18:51:31,271 INFO: [train..][epoch:514, iter: 227,800, lr:(1.250e-05,)] [eta: 6:59:23, time (data): 1.085 (0.004)] l_pix: 1.4985e-02 
2024-05-19 18:55:09,670 INFO: [train..][epoch:514, iter: 228,000, lr:(1.250e-05,)] [eta: 6:55:35, time (data): 1.094 (0.003)] l_pix: 1.4293e-02 
2024-05-19 18:59:00,902 INFO: [train..][epoch:515, iter: 228,200, lr:(1.250e-05,)] [eta: 6:51:49, time (data): 1.277 (0.193)] l_pix: 2.1852e-02 
2024-05-19 19:02:38,904 INFO: [train..][epoch:515, iter: 228,400, lr:(1.250e-05,)] [eta: 6:48:02, time (data): 1.091 (0.003)] l_pix: 2.0869e-02 
2024-05-19 19:06:29,760 INFO: [train..][epoch:516, iter: 228,600, lr:(1.250e-05,)] [eta: 6:44:15, time (data): 1.286 (0.193)] l_pix: 1.2480e-02 
2024-05-19 19:10:07,855 INFO: [train..][epoch:516, iter: 228,800, lr:(1.250e-05,)] [eta: 6:40:28, time (data): 1.093 (0.003)] l_pix: 1.9349e-02 
2024-05-19 19:13:46,542 INFO: [train..][epoch:516, iter: 229,000, lr:(1.250e-05,)] [eta: 6:36:40, time (data): 1.095 (0.004)] l_pix: 2.3568e-02 
2024-05-19 19:17:37,277 INFO: [train..][epoch:517, iter: 229,200, lr:(1.250e-05,)] [eta: 6:32:54, time (data): 1.103 (0.004)] l_pix: 1.9335e-02 
2024-05-19 19:21:17,306 INFO: [train..][epoch:517, iter: 229,400, lr:(1.250e-05,)] [eta: 6:29:07, time (data): 1.092 (0.003)] l_pix: 1.3355e-02 
2024-05-19 19:25:07,987 INFO: [train..][epoch:518, iter: 229,600, lr:(1.250e-05,)] [eta: 6:25:20, time (data): 1.104 (0.004)] l_pix: 2.8496e-02 
2024-05-19 19:28:46,922 INFO: [train..][epoch:518, iter: 229,800, lr:(1.250e-05,)] [eta: 6:21:33, time (data): 1.094 (0.003)] l_pix: 1.4632e-02 
2024-05-19 19:32:36,913 INFO: [train..][epoch:519, iter: 230,000, lr:(1.250e-05,)] [eta: 6:17:47, time (data): 1.090 (0.005)] l_pix: 1.2525e-02 
2024-05-19 19:32:36,914 INFO: Saving models and training states.
2024-05-19 19:32:39,198 INFO: Validation Set5
	 # psnr: 32.9701	Best: 32.9774 @ 195000 iter

2024-05-19 19:36:18,120 INFO: [train..][epoch:519, iter: 230,200, lr:(1.250e-05,)] [eta: 6:13:59, time (data): 1.096 (0.003)] l_pix: 3.2021e-02 
2024-05-19 19:40:08,975 INFO: [train..][epoch:520, iter: 230,400, lr:(1.250e-05,)] [eta: 6:10:13, time (data): 1.315 (0.231)] l_pix: 3.4346e-02 
2024-05-19 19:43:47,114 INFO: [train..][epoch:520, iter: 230,600, lr:(1.250e-05,)] [eta: 6:06:26, time (data): 1.096 (0.003)] l_pix: 2.5317e-02 
2024-05-19 19:47:26,465 INFO: [train..][epoch:520, iter: 230,800, lr:(1.250e-05,)] [eta: 6:02:38, time (data): 1.093 (0.003)] l_pix: 2.7379e-02 
2024-05-19 19:51:17,209 INFO: [train..][epoch:521, iter: 231,000, lr:(1.250e-05,)] [eta: 5:58:52, time (data): 1.094 (0.003)] l_pix: 5.1122e-02 
2024-05-19 19:54:56,631 INFO: [train..][epoch:521, iter: 231,200, lr:(1.250e-05,)] [eta: 5:55:05, time (data): 1.099 (0.003)] l_pix: 3.1680e-02 
2024-05-19 19:58:46,422 INFO: [train..][epoch:522, iter: 231,400, lr:(1.250e-05,)] [eta: 5:51:18, time (data): 1.089 (0.003)] l_pix: 3.0338e-02 
2024-05-19 20:02:25,473 INFO: [train..][epoch:522, iter: 231,600, lr:(1.250e-05,)] [eta: 5:47:31, time (data): 1.099 (0.003)] l_pix: 2.6592e-02 
2024-05-19 20:06:16,449 INFO: [train..][epoch:523, iter: 231,800, lr:(1.250e-05,)] [eta: 5:43:45, time (data): 1.091 (0.004)] l_pix: 1.9208e-02 
2024-05-19 20:09:55,093 INFO: [train..][epoch:523, iter: 232,000, lr:(1.250e-05,)] [eta: 5:39:58, time (data): 1.096 (0.003)] l_pix: 2.5152e-02 
2024-05-19 20:13:46,426 INFO: [train..][epoch:524, iter: 232,200, lr:(1.250e-05,)] [eta: 5:36:11, time (data): 1.086 (0.004)] l_pix: 2.8256e-02 
2024-05-19 20:17:25,013 INFO: [train..][epoch:524, iter: 232,400, lr:(1.250e-05,)] [eta: 5:32:24, time (data): 1.097 (0.004)] l_pix: 1.9154e-02 
2024-05-19 20:21:16,035 INFO: [train..][epoch:525, iter: 232,600, lr:(1.250e-05,)] [eta: 5:28:38, time (data): 1.372 (0.284)] l_pix: 3.1967e-02 
2024-05-19 20:24:54,397 INFO: [train..][epoch:525, iter: 232,800, lr:(1.250e-05,)] [eta: 5:24:50, time (data): 1.093 (0.003)] l_pix: 1.5047e-02 
2024-05-19 20:28:33,067 INFO: [train..][epoch:525, iter: 233,000, lr:(1.250e-05,)] [eta: 5:21:03, time (data): 1.092 (0.003)] l_pix: 1.9257e-02 
2024-05-19 20:32:23,209 INFO: [train..][epoch:526, iter: 233,200, lr:(1.250e-05,)] [eta: 5:17:17, time (data): 1.097 (0.003)] l_pix: 3.8331e-02 
2024-05-19 20:36:02,524 INFO: [train..][epoch:526, iter: 233,400, lr:(1.250e-05,)] [eta: 5:13:30, time (data): 1.094 (0.003)] l_pix: 1.6352e-02 
2024-05-19 20:39:52,510 INFO: [train..][epoch:527, iter: 233,600, lr:(1.250e-05,)] [eta: 5:09:43, time (data): 1.094 (0.003)] l_pix: 2.0246e-02 
2024-05-19 20:43:31,802 INFO: [train..][epoch:527, iter: 233,800, lr:(1.250e-05,)] [eta: 5:05:56, time (data): 1.094 (0.003)] l_pix: 1.7080e-02 
2024-05-19 20:47:22,147 INFO: [train..][epoch:528, iter: 234,000, lr:(1.250e-05,)] [eta: 5:02:10, time (data): 1.084 (0.003)] l_pix: 1.6950e-02 
2024-05-19 20:51:00,510 INFO: [train..][epoch:528, iter: 234,200, lr:(1.250e-05,)] [eta: 4:58:22, time (data): 1.094 (0.003)] l_pix: 2.4247e-02 
2024-05-19 20:54:51,378 INFO: [train..][epoch:529, iter: 234,400, lr:(1.250e-05,)] [eta: 4:54:36, time (data): 1.085 (0.003)] l_pix: 2.4771e-02 
2024-05-19 20:58:29,655 INFO: [train..][epoch:529, iter: 234,600, lr:(1.250e-05,)] [eta: 4:50:49, time (data): 1.095 (0.003)] l_pix: 2.2420e-02 
2024-05-19 21:02:21,243 INFO: [train..][epoch:530, iter: 234,800, lr:(1.250e-05,)] [eta: 4:47:03, time (data): 1.471 (0.380)] l_pix: 3.2380e-02 
2024-05-19 21:05:58,893 INFO: [train..][epoch:530, iter: 235,000, lr:(1.250e-05,)] [eta: 4:43:15, time (data): 1.093 (0.003)] l_pix: 1.7899e-02 
2024-05-19 21:05:58,894 INFO: Saving models and training states.
2024-05-19 21:06:00,288 INFO: Validation Set5
	 # psnr: 32.9705	Best: 32.9774 @ 195000 iter

2024-05-19 21:09:40,070 INFO: [train..][epoch:530, iter: 235,200, lr:(1.250e-05,)] [eta: 4:39:28, time (data): 1.100 (0.004)] l_pix: 1.9318e-02 
2024-05-19 21:13:29,909 INFO: [train..][epoch:531, iter: 235,400, lr:(1.250e-05,)] [eta: 4:35:42, time (data): 1.090 (0.003)] l_pix: 1.8684e-02 
2024-05-19 21:17:09,005 INFO: [train..][epoch:531, iter: 235,600, lr:(1.250e-05,)] [eta: 4:31:55, time (data): 1.103 (0.003)] l_pix: 1.7491e-02 
2024-05-19 21:20:59,599 INFO: [train..][epoch:532, iter: 235,800, lr:(1.250e-05,)] [eta: 4:28:09, time (data): 1.090 (0.004)] l_pix: 1.8474e-02 
2024-05-19 21:24:38,112 INFO: [train..][epoch:532, iter: 236,000, lr:(1.250e-05,)] [eta: 4:24:21, time (data): 1.090 (0.003)] l_pix: 2.4227e-02 
2024-05-19 21:28:28,142 INFO: [train..][epoch:533, iter: 236,200, lr:(1.250e-05,)] [eta: 4:20:35, time (data): 1.086 (0.004)] l_pix: 3.8808e-02 
2024-05-19 21:32:07,105 INFO: [train..][epoch:533, iter: 236,400, lr:(1.250e-05,)] [eta: 4:16:48, time (data): 1.093 (0.003)] l_pix: 2.0928e-02 
2024-05-19 21:35:57,219 INFO: [train..][epoch:534, iter: 236,600, lr:(1.250e-05,)] [eta: 4:13:02, time (data): 1.082 (0.003)] l_pix: 2.4245e-02 
2024-05-19 21:39:35,746 INFO: [train..][epoch:534, iter: 236,800, lr:(1.250e-05,)] [eta: 4:09:15, time (data): 1.098 (0.003)] l_pix: 3.4773e-02 
2024-05-19 21:43:14,336 INFO: [train..][epoch:534, iter: 237,000, lr:(1.250e-05,)] [eta: 4:05:27, time (data): 1.089 (0.003)] l_pix: 3.6118e-02 
2024-05-19 21:47:08,616 INFO: [train..][epoch:535, iter: 237,200, lr:(1.250e-05,)] [eta: 4:01:41, time (data): 1.096 (0.004)] l_pix: 1.9183e-02 
2024-05-19 21:50:47,609 INFO: [train..][epoch:535, iter: 237,400, lr:(1.250e-05,)] [eta: 3:57:54, time (data): 1.092 (0.004)] l_pix: 2.9470e-02 
2024-05-19 21:54:37,114 INFO: [train..][epoch:536, iter: 237,600, lr:(6.250e-06,)] [eta: 3:54:08, time (data): 1.086 (0.003)] l_pix: 3.6520e-02 
2024-05-19 21:58:16,703 INFO: [train..][epoch:536, iter: 237,800, lr:(6.250e-06,)] [eta: 3:50:21, time (data): 1.100 (0.003)] l_pix: 2.3481e-02 
2024-05-19 22:02:06,662 INFO: [train..][epoch:537, iter: 238,000, lr:(6.250e-06,)] [eta: 3:46:34, time (data): 1.092 (0.004)] l_pix: 2.3727e-02 
2024-05-19 22:05:45,417 INFO: [train..][epoch:537, iter: 238,200, lr:(6.250e-06,)] [eta: 3:42:47, time (data): 1.101 (0.003)] l_pix: 2.1443e-02 
2024-05-19 22:09:36,051 INFO: [train..][epoch:538, iter: 238,400, lr:(6.250e-06,)] [eta: 3:39:01, time (data): 1.092 (0.004)] l_pix: 2.1824e-02 
2024-05-19 22:13:17,778 INFO: [train..][epoch:538, iter: 238,600, lr:(6.250e-06,)] [eta: 3:35:14, time (data): 1.092 (0.003)] l_pix: 2.0471e-02 
2024-05-19 22:17:08,294 INFO: [train..][epoch:539, iter: 238,800, lr:(6.250e-06,)] [eta: 3:31:28, time (data): 1.080 (0.002)] l_pix: 2.5540e-02 
2024-05-19 22:20:46,533 INFO: [train..][epoch:539, iter: 239,000, lr:(6.250e-06,)] [eta: 3:27:41, time (data): 1.094 (0.003)] l_pix: 4.2153e-02 
2024-05-19 22:24:25,235 INFO: [train..][epoch:539, iter: 239,200, lr:(6.250e-06,)] [eta: 3:23:54, time (data): 1.100 (0.003)] l_pix: 8.4332e-03 
2024-05-19 22:28:15,414 INFO: [train..][epoch:540, iter: 239,400, lr:(6.250e-06,)] [eta: 3:20:07, time (data): 1.092 (0.003)] l_pix: 1.9786e-02 
2024-05-19 22:31:54,498 INFO: [train..][epoch:540, iter: 239,600, lr:(6.250e-06,)] [eta: 3:16:21, time (data): 1.099 (0.004)] l_pix: 4.2995e-02 
2024-05-19 22:35:44,829 INFO: [train..][epoch:541, iter: 239,800, lr:(6.250e-06,)] [eta: 3:12:34, time (data): 1.100 (0.003)] l_pix: 3.1609e-02 
2024-05-19 22:39:23,326 INFO: [train..][epoch:541, iter: 240,000, lr:(6.250e-06,)] [eta: 3:08:47, time (data): 1.088 (0.003)] l_pix: 1.2129e-02 
2024-05-19 22:39:23,327 INFO: Saving models and training states.
2024-05-19 22:39:24,672 INFO: Validation Set5
	 # psnr: 32.9664	Best: 32.9774 @ 195000 iter

2024-05-19 22:43:14,427 INFO: [train..][epoch:542, iter: 240,200, lr:(6.250e-06,)] [eta: 3:05:01, time (data): 1.087 (0.003)] l_pix: 3.5114e-02 
2024-05-19 22:46:53,282 INFO: [train..][epoch:542, iter: 240,400, lr:(6.250e-06,)] [eta: 3:01:14, time (data): 1.087 (0.003)] l_pix: 2.8684e-02 
2024-05-19 22:50:44,388 INFO: [train..][epoch:543, iter: 240,600, lr:(6.250e-06,)] [eta: 2:57:28, time (data): 1.092 (0.004)] l_pix: 2.4201e-02 
2024-05-19 22:54:23,149 INFO: [train..][epoch:543, iter: 240,800, lr:(6.250e-06,)] [eta: 2:53:41, time (data): 1.090 (0.003)] l_pix: 3.6868e-02 
2024-05-19 22:58:13,979 INFO: [train..][epoch:544, iter: 241,000, lr:(6.250e-06,)] [eta: 2:49:54, time (data): 1.082 (0.001)] l_pix: 2.6941e-02 
2024-05-19 23:01:52,026 INFO: [train..][epoch:544, iter: 241,200, lr:(6.250e-06,)] [eta: 2:46:07, time (data): 1.090 (0.003)] l_pix: 1.0724e-02 
2024-05-19 23:05:30,932 INFO: [train..][epoch:544, iter: 241,400, lr:(6.250e-06,)] [eta: 2:42:20, time (data): 1.095 (0.003)] l_pix: 2.2678e-02 
2024-05-19 23:09:20,442 INFO: [train..][epoch:545, iter: 241,600, lr:(6.250e-06,)] [eta: 2:38:34, time (data): 1.148 (0.064)] l_pix: 2.3929e-02 
2024-05-19 23:12:59,443 INFO: [train..][epoch:545, iter: 241,800, lr:(6.250e-06,)] [eta: 2:34:47, time (data): 1.095 (0.003)] l_pix: 1.4609e-02 
2024-05-19 23:16:49,188 INFO: [train..][epoch:546, iter: 242,000, lr:(6.250e-06,)] [eta: 2:31:01, time (data): 1.149 (0.064)] l_pix: 3.2743e-02 
2024-05-19 23:20:27,463 INFO: [train..][epoch:546, iter: 242,200, lr:(6.250e-06,)] [eta: 2:27:14, time (data): 1.092 (0.003)] l_pix: 1.9381e-02 
2024-05-19 23:24:18,043 INFO: [train..][epoch:547, iter: 242,400, lr:(6.250e-06,)] [eta: 2:23:28, time (data): 1.154 (0.064)] l_pix: 1.9402e-02 
2024-05-19 23:27:56,965 INFO: [train..][epoch:547, iter: 242,600, lr:(6.250e-06,)] [eta: 2:19:41, time (data): 1.095 (0.004)] l_pix: 2.0947e-02 
2024-05-19 23:31:48,625 INFO: [train..][epoch:548, iter: 242,800, lr:(6.250e-06,)] [eta: 2:15:54, time (data): 1.160 (0.066)] l_pix: 1.7502e-02 
2024-05-19 23:35:26,543 INFO: [train..][epoch:548, iter: 243,000, lr:(6.250e-06,)] [eta: 2:12:08, time (data): 1.090 (0.003)] l_pix: 1.5120e-02 
2024-05-19 23:39:05,370 INFO: [train..][epoch:548, iter: 243,200, lr:(6.250e-06,)] [eta: 2:08:21, time (data): 1.094 (0.003)] l_pix: 2.3409e-02 
2024-05-19 23:42:57,036 INFO: [train..][epoch:549, iter: 243,400, lr:(6.250e-06,)] [eta: 2:04:34, time (data): 1.098 (0.003)] l_pix: 1.7857e-02 
2024-05-19 23:46:35,439 INFO: [train..][epoch:549, iter: 243,600, lr:(6.250e-06,)] [eta: 2:00:48, time (data): 1.092 (0.003)] l_pix: 2.4771e-02 
2024-05-19 23:50:25,611 INFO: [train..][epoch:550, iter: 243,800, lr:(6.250e-06,)] [eta: 1:57:01, time (data): 1.155 (0.067)] l_pix: 1.3477e-02 
2024-05-19 23:54:04,591 INFO: [train..][epoch:550, iter: 244,000, lr:(6.250e-06,)] [eta: 1:53:14, time (data): 1.095 (0.004)] l_pix: 1.2777e-02 
2024-05-19 23:57:55,698 INFO: [train..][epoch:551, iter: 244,200, lr:(6.250e-06,)] [eta: 1:49:28, time (data): 1.160 (0.069)] l_pix: 1.3244e-02 
2024-05-20 00:01:35,183 INFO: [train..][epoch:551, iter: 244,400, lr:(6.250e-06,)] [eta: 1:45:41, time (data): 1.097 (0.004)] l_pix: 2.1044e-02 
2024-05-20 00:05:25,962 INFO: [train..][epoch:552, iter: 244,600, lr:(6.250e-06,)] [eta: 1:41:55, time (data): 1.159 (0.068)] l_pix: 1.8646e-02 
2024-05-20 00:09:04,838 INFO: [train..][epoch:552, iter: 244,800, lr:(6.250e-06,)] [eta: 1:38:08, time (data): 1.095 (0.003)] l_pix: 3.2207e-02 
2024-05-20 00:12:55,627 INFO: [train..][epoch:553, iter: 245,000, lr:(6.250e-06,)] [eta: 1:34:22, time (data): 1.160 (0.068)] l_pix: 1.9955e-02 
2024-05-20 00:12:55,628 INFO: Saving models and training states.
2024-05-20 00:12:56,936 INFO: Validation Set5
	 # psnr: 32.9705	Best: 32.9774 @ 195000 iter

2024-05-20 00:16:35,336 INFO: [train..][epoch:553, iter: 245,200, lr:(6.250e-06,)] [eta: 1:30:35, time (data): 1.093 (0.004)] l_pix: 2.3107e-02 
2024-05-20 00:20:14,586 INFO: [train..][epoch:553, iter: 245,400, lr:(6.250e-06,)] [eta: 1:26:48, time (data): 1.096 (0.003)] l_pix: 1.7010e-02 
2024-05-20 00:24:04,869 INFO: [train..][epoch:554, iter: 245,600, lr:(6.250e-06,)] [eta: 1:23:02, time (data): 1.158 (0.070)] l_pix: 2.1859e-02 
2024-05-20 00:27:43,511 INFO: [train..][epoch:554, iter: 245,800, lr:(6.250e-06,)] [eta: 1:19:15, time (data): 1.093 (0.003)] l_pix: 1.6173e-02 
2024-05-20 00:31:33,415 INFO: [train..][epoch:555, iter: 246,000, lr:(6.250e-06,)] [eta: 1:15:29, time (data): 1.157 (0.072)] l_pix: 2.2551e-02 
2024-05-20 00:35:13,027 INFO: [train..][epoch:555, iter: 246,200, lr:(6.250e-06,)] [eta: 1:11:42, time (data): 1.099 (0.004)] l_pix: 2.6513e-02 
2024-05-20 00:39:03,005 INFO: [train..][epoch:556, iter: 246,400, lr:(6.250e-06,)] [eta: 1:07:56, time (data): 1.158 (0.073)] l_pix: 1.5404e-02 
2024-05-20 00:42:41,209 INFO: [train..][epoch:556, iter: 246,600, lr:(6.250e-06,)] [eta: 1:04:09, time (data): 1.092 (0.003)] l_pix: 1.3867e-02 
2024-05-20 00:46:32,196 INFO: [train..][epoch:557, iter: 246,800, lr:(6.250e-06,)] [eta: 1:00:23, time (data): 1.164 (0.073)] l_pix: 1.8086e-02 
2024-05-20 00:50:09,988 INFO: [train..][epoch:557, iter: 247,000, lr:(6.250e-06,)] [eta: 0:56:36, time (data): 1.089 (0.003)] l_pix: 2.5737e-02 
2024-05-20 00:54:01,033 INFO: [train..][epoch:558, iter: 247,200, lr:(6.250e-06,)] [eta: 0:52:50, time (data): 1.165 (0.072)] l_pix: 2.1564e-02 
2024-05-20 00:57:39,202 INFO: [train..][epoch:558, iter: 247,400, lr:(6.250e-06,)] [eta: 0:49:03, time (data): 1.091 (0.003)] l_pix: 2.9512e-02 
2024-05-20 01:01:18,466 INFO: [train..][epoch:558, iter: 247,600, lr:(6.250e-06,)] [eta: 0:45:16, time (data): 1.096 (0.003)] l_pix: 1.2937e-02 
2024-05-20 01:05:08,184 INFO: [train..][epoch:559, iter: 247,800, lr:(6.250e-06,)] [eta: 0:41:30, time (data): 1.159 (0.074)] l_pix: 1.8079e-02 
2024-05-20 01:08:46,997 INFO: [train..][epoch:559, iter: 248,000, lr:(6.250e-06,)] [eta: 0:37:43, time (data): 1.094 (0.003)] l_pix: 1.5815e-02 
2024-05-20 01:12:37,345 INFO: [train..][epoch:560, iter: 248,200, lr:(6.250e-06,)] [eta: 0:33:57, time (data): 1.163 (0.076)] l_pix: 2.0241e-02 
2024-05-20 01:16:15,645 INFO: [train..][epoch:560, iter: 248,400, lr:(6.250e-06,)] [eta: 0:30:10, time (data): 1.091 (0.003)] l_pix: 3.2541e-02 
2024-05-20 01:20:06,243 INFO: [train..][epoch:561, iter: 248,600, lr:(6.250e-06,)] [eta: 0:26:24, time (data): 1.166 (0.079)] l_pix: 3.2099e-02 
2024-05-20 01:23:44,683 INFO: [train..][epoch:561, iter: 248,800, lr:(6.250e-06,)] [eta: 0:22:37, time (data): 1.092 (0.003)] l_pix: 2.8215e-02 
2024-05-20 01:27:35,279 INFO: [train..][epoch:562, iter: 249,000, lr:(6.250e-06,)] [eta: 0:18:51, time (data): 1.168 (0.077)] l_pix: 2.6436e-02 
2024-05-20 01:31:13,445 INFO: [train..][epoch:562, iter: 249,200, lr:(6.250e-06,)] [eta: 0:15:04, time (data): 1.092 (0.003)] l_pix: 2.2664e-02 
2024-05-20 01:34:52,010 INFO: [train..][epoch:562, iter: 249,400, lr:(6.250e-06,)] [eta: 0:11:18, time (data): 1.093 (0.003)] l_pix: 1.9763e-02 
2024-05-20 01:38:42,085 INFO: [train..][epoch:563, iter: 249,600, lr:(6.250e-06,)] [eta: 0:07:31, time (data): 1.092 (0.003)] l_pix: 2.9227e-02 
2024-05-20 01:42:20,737 INFO: [train..][epoch:563, iter: 249,800, lr:(6.250e-06,)] [eta: 0:03:45, time (data): 1.093 (0.003)] l_pix: 2.5218e-02 
2024-05-20 01:46:10,547 INFO: [train..][epoch:564, iter: 250,000, lr:(6.250e-06,)] [eta: -1 day, 23:59:59, time (data): 1.165 (0.079)] l_pix: 2.0611e-02 
2024-05-20 01:46:10,548 INFO: Saving models and training states.
2024-05-20 01:46:11,936 INFO: Validation Set5
	 # psnr: 32.9567	Best: 32.9774 @ 195000 iter

2024-05-20 01:46:11,939 INFO: End of training. Time consumed: 3 days, 6:38:37
2024-05-20 01:46:11,939 INFO: Save the latest model.
2024-05-20 01:46:12,849 INFO: Validation Set5
	 # psnr: 32.9567	Best: 32.9774 @ 195000 iter

