2024-05-16 11:15:39,273 INFO: 
                ____                _       _____  ____
               / __ ) ____ _ _____ (_)_____/ ___/ / __ \
              / __  |/ __ `// ___// // ___/\__ \ / /_/ /
             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/
            /_____/ \__,_//____//_/ \___//____//_/ |_|
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	BasicSR: 1.3.5
	PyTorch: 1.8.0
	TorchVision: 0.9.0
2024-05-16 11:15:39,274 INFO: 
  name: train_DAT_S_x2
  model_type: DATModel
  scale: 2
  num_gpu: 1
  manual_seed: 10
  datasets:[
    train:[
      task: SR
      name: DF2K
      type: PairedImageDataset
      dataroot_gt: datasets/DF2K/HR
      dataroot_lq: datasets/DF2K/LR_bicubic/X2
      filename_tmpl: {}x2
      io_backend:[
        type: disk
      ]
      gt_size: 128
      use_hflip: True
      use_rot: True
      use_shuffle: True
      num_worker_per_gpu: 12
      batch_size_per_gpu: 8
      dataset_enlarge_ratio: 1
      prefetch_mode: None
      phase: train
      scale: 2
    ]
    val:[
      task: SR
      name: Set5
      type: PairedImageDataset
      dataroot_gt: datasets/benchmark/Set5/HR
      dataroot_lq: datasets/benchmark/Set5/LR_bicubic/X2
      filename_tmpl: {}x2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
  ]
  network_g:[
    type: DAT
    upscale: 2
    in_chans: 3
    img_size: 64
    img_range: 1.0
    split_size: [8, 16]
    depth: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    expansion_factor: 2
    resi_connection: 1conv
  ]
  path:[
    pretrain_network_g: None
    strict_load_g: True
    resume_state: None
    experiments_root: /home/user/projects_sr/DAT/experiments/train_DAT_S_x2
    models: /home/user/projects_sr/DAT/experiments/train_DAT_S_x2/models
    training_states: /home/user/projects_sr/DAT/experiments/train_DAT_S_x2/training_states
    log: /home/user/projects_sr/DAT/experiments/train_DAT_S_x2
    visualization: /home/user/projects_sr/DAT/experiments/train_DAT_S_x2/visualization
  ]
  train:[
    optim_g:[
      type: Adam
      lr: 0.0002
      weight_decay: 0
      betas: [0.9, 0.99]
    ]
    scheduler:[
      type: MultiStepLR
      milestones: [250000, 400000, 450000, 475000]
      gamma: 0.5
    ]
    total_iter: 500000
    warmup_iter: -1
    pixel_opt:[
      type: L1Loss
      loss_weight: 1.0
      reduction: mean
    ]
  ]
  val:[
    val_freq: 5000.0
    save_img: False
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 2
        test_y_channel: True
      ]
    ]
  ]
  logger:[
    print_freq: 200
    save_checkpoint_freq: 5000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: True
  rank: 0
  world_size: 1
  auto_resume: False
  is_train: True
  root_path: /home/user/projects_sr/DAT

2024-05-16 11:15:39,596 INFO: Dataset [PairedImageDataset] - DF2K is built.
2024-05-16 11:15:39,597 INFO: Training statistics:
	Number of train images: 3550
	Dataset enlarge ratio: 1
	Batch size per gpu: 8
	World size (gpu number): 1
	Require iter number per epoch: 444
	Total epochs: 1127; iters: 500000.
2024-05-16 11:15:39,597 INFO: Dataset [PairedImageDataset] - Set5 is built.
2024-05-16 11:15:39,597 INFO: Number of val images/folders in Set5: 5
2024-05-16 11:15:39,880 INFO: Network [DAT] is created.
2024-05-16 11:15:43,486 INFO: Network: DistributedDataParallel - DAT, with parameters: 11,064,419
2024-05-16 11:15:43,487 INFO: DAT(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (before_RG): Sequential(
    (0): Rearrange('b c h w -> b (h w) c')
    (1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (layers): ModuleList(
    (0): ResidualGroup(
      (blocks): ModuleList(
        (0): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): Identity()
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (1): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.003)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (2): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.006)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (3): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.009)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (4): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.011)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (5): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.014)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (1): ResidualGroup(
      (blocks): ModuleList(
        (0): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.017)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (1): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.020)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (2): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.023)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (3): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.026)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (4): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.029)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (5): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.031)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (2): ResidualGroup(
      (blocks): ModuleList(
        (0): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.034)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (1): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.037)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (2): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.040)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (3): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.043)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (4): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.046)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (5): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.049)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (3): ResidualGroup(
      (blocks): ModuleList(
        (0): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.051)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (1): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.054)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (2): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.057)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (3): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.060)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (4): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.063)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (5): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.066)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (4): ResidualGroup(
      (blocks): ModuleList(
        (0): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.069)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (1): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.071)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (2): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.074)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (3): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.077)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (4): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.080)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (5): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.083)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (5): ResidualGroup(
      (blocks): ModuleList(
        (0): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.086)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (1): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.089)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (2): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.091)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (3): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.094)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (4): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Spatial_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (attns): ModuleList(
              (0): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
              (1): Spatial_Attention(
                (pos): DynamicPosBias(
                  (pos_proj): Linear(in_features=2, out_features=5, bias=True)
                  (pos1): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos2): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=5, bias=True)
                  )
                  (pos3): Sequential(
                    (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)
                    (1): ReLU(inplace=True)
                    (2): Linear(in_features=5, out_features=3, bias=True)
                  )
                )
                (attn_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.097)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
        (5): DATB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (attn): Adaptive_Channel_Attention(
            (qkv): Linear(in_features=180, out_features=540, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=180, out_features=180, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (dwconv): Sequential(
              (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
              (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
            )
            (channel_interaction): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(180, 22, kernel_size=(1, 1), stride=(1, 1))
              (2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): GELU()
              (4): Conv2d(22, 180, kernel_size=(1, 1), stride=(1, 1))
            )
            (spatial_interaction): Sequential(
              (0): Conv2d(180, 11, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU()
              (3): Conv2d(11, 1, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath(drop_prob=0.100)
          (ffn): SGFN(
            (fc1): Linear(in_features=180, out_features=360, bias=True)
            (act): GELU()
            (sg): SpatialGate(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
            )
            (fc2): Linear(in_features=180, out_features=180, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2024-05-16 11:15:43,492 INFO: Loss [L1Loss] is created.
2024-05-16 11:15:43,497 INFO: Model [DATModel] is created.
2024-05-16 11:15:54,172 INFO: Start training from epoch: 0, iter: 0
2024-05-16 11:19:43,188 INFO: [train..][epoch:  0, iter:     200, lr:(2.000e-04,)] [eta: 6 days, 3:23:47, time (data): 1.145 (0.072)] l_pix: 6.3999e-02 
2024-05-16 11:23:18,456 INFO: [train..][epoch:  0, iter:     400, lr:(2.000e-04,)] [eta: 6 days, 4:20:57, time (data): 1.076 (0.002)] l_pix: 3.1645e-02 
2024-05-16 11:27:12,856 INFO: [train..][epoch:  1, iter:     600, lr:(2.000e-04,)] [eta: 6 days, 9:02:52, time (data): 1.173 (0.097)] l_pix: 2.3259e-02 
2024-05-16 11:30:49,559 INFO: [train..][epoch:  1, iter:     800, lr:(2.000e-04,)] [eta: 6 days, 8:18:09, time (data): 1.084 (0.002)] l_pix: 3.6191e-02 
2024-05-16 11:34:40,218 INFO: [train..][epoch:  2, iter:   1,000, lr:(2.000e-04,)] [eta: 6 days, 9:45:49, time (data): 1.155 (0.075)] l_pix: 1.7502e-02 
2024-05-16 11:38:16,753 INFO: [train..][epoch:  2, iter:   1,200, lr:(2.000e-04,)] [eta: 6 days, 9:05:14, time (data): 1.083 (0.002)] l_pix: 3.2714e-02 
2024-05-16 11:42:05,545 INFO: [train..][epoch:  3, iter:   1,400, lr:(2.000e-04,)] [eta: 6 days, 9:47:54, time (data): 1.145 (0.065)] l_pix: 3.0223e-02 
2024-05-16 11:45:42,140 INFO: [train..][epoch:  3, iter:   1,600, lr:(2.000e-04,)] [eta: 6 days, 9:15:41, time (data): 1.083 (0.002)] l_pix: 1.4579e-02 
2024-05-16 11:49:35,061 INFO: [train..][epoch:  4, iter:   1,800, lr:(2.000e-04,)] [eta: 6 days, 10:05:05, time (data): 1.168 (0.084)] l_pix: 2.1170e-02 
2024-05-16 11:55:12,930 INFO: [train..][epoch:  4, iter:   2,000, lr:(2.000e-04,)] [eta: 6 days, 17:59:09, time (data): 1.717 (0.003)] l_pix: 1.4979e-02 
2024-05-16 12:02:03,931 INFO: [train..][epoch:  4, iter:   2,200, lr:(2.000e-04,)] [eta: 7 days, 5:01:42, time (data): 2.054 (0.003)] l_pix: 1.4284e-02 
2024-05-16 12:09:17,718 INFO: [train..][epoch:  5, iter:   2,400, lr:(2.000e-04,)] [eta: 7 days, 15:31:25, time (data): 2.175 (0.127)] l_pix: 2.4359e-02 
2024-05-16 12:16:14,686 INFO: [train..][epoch:  5, iter:   2,600, lr:(2.000e-04,)] [eta: 7 days, 23:29:37, time (data): 2.085 (0.003)] l_pix: 1.5283e-02 
2024-05-16 12:23:28,552 INFO: [train..][epoch:  6, iter:   2,800, lr:(2.000e-04,)] [eta: 8 days, 7:08:31, time (data): 2.176 (0.106)] l_pix: 1.8998e-02 
2024-05-16 12:29:33,895 INFO: [train..][epoch:  6, iter:   3,000, lr:(2.000e-04,)] [eta: 8 days, 10:36:08, time (data): 1.807 (0.003)] l_pix: 1.9205e-02 
2024-05-16 12:33:29,371 INFO: [train..][epoch:  7, iter:   3,200, lr:(2.000e-04,)] [eta: 8 days, 8:01:08, time (data): 1.185 (0.107)] l_pix: 3.3969e-02 
2024-05-16 12:39:03,589 INFO: [train..][epoch:  7, iter:   3,400, lr:(2.000e-04,)] [eta: 8 days, 9:44:12, time (data): 1.713 (0.003)] l_pix: 2.4736e-02 
2024-05-16 12:45:46,924 INFO: [train..][epoch:  8, iter:   3,600, lr:(2.000e-04,)] [eta: 8 days, 13:53:59, time (data): 2.026 (0.111)] l_pix: 1.8984e-02 
2024-05-16 12:51:48,198 INFO: [train..][epoch:  8, iter:   3,800, lr:(2.000e-04,)] [eta: 8 days, 16:05:16, time (data): 1.795 (0.004)] l_pix: 1.4265e-02 
2024-05-16 12:57:11,532 INFO: [train..][epoch:  9, iter:   4,000, lr:(2.000e-04,)] [eta: 8 days, 16:44:26, time (data): 1.643 (0.086)] l_pix: 2.3552e-02 
2024-05-16 13:02:49,298 INFO: [train..][epoch:  9, iter:   4,200, lr:(2.000e-04,)] [eta: 8 days, 17:47:45, time (data): 1.685 (0.004)] l_pix: 1.9488e-02 
2024-05-16 13:07:29,265 INFO: [train..][epoch:  9, iter:   4,400, lr:(2.000e-04,)] [eta: 8 days, 16:56:19, time (data): 1.416 (0.004)] l_pix: 1.6663e-02 
2024-05-16 13:12:45,091 INFO: [train..][epoch: 10, iter:   4,600, lr:(2.000e-04,)] [eta: 8 days, 17:13:18, time (data): 1.591 (0.113)] l_pix: 1.7289e-02 
2024-05-16 13:17:08,820 INFO: [train..][epoch: 10, iter:   4,800, lr:(2.000e-04,)] [eta: 8 days, 15:58:52, time (data): 1.295 (0.003)] l_pix: 2.2683e-02 
2024-05-16 13:21:51,586 INFO: [train..][epoch: 11, iter:   5,000, lr:(2.000e-04,)] [eta: 8 days, 15:21:27, time (data): 1.421 (0.090)] l_pix: 2.1994e-02 
2024-05-16 13:21:51,587 INFO: Saving models and training states.
2024-05-16 13:21:59,278 INFO: Validation Set5
	 # psnr: 36.7130	Best: 36.7130 @ 5000 iter

2024-05-16 13:26:06,538 INFO: [train..][epoch: 11, iter:   5,200, lr:(2.000e-04,)] [eta: 8 days, 14:02:26, time (data): 1.245 (0.003)] l_pix: 1.5048e-02 
2024-05-16 13:30:13,948 INFO: [train..][epoch: 12, iter:   5,400, lr:(2.000e-04,)] [eta: 8 days, 12:37:27, time (data): 1.232 (0.106)] l_pix: 1.8519e-02 
2024-05-16 13:33:50,463 INFO: [train..][epoch: 12, iter:   5,600, lr:(2.000e-04,)] [eta: 8 days, 10:32:47, time (data): 1.084 (0.002)] l_pix: 1.5438e-02 
2024-05-16 13:37:41,628 INFO: [train..][epoch: 13, iter:   5,800, lr:(2.000e-04,)] [eta: 8 days, 8:57:17, time (data): 1.168 (0.085)] l_pix: 1.6880e-02 
2024-05-16 13:41:18,371 INFO: [train..][epoch: 13, iter:   6,000, lr:(2.000e-04,)] [eta: 8 days, 7:08:05, time (data): 1.085 (0.002)] l_pix: 1.4263e-02 
2024-05-16 13:44:55,854 INFO: [train..][epoch: 13, iter:   6,200, lr:(2.000e-04,)] [eta: 8 days, 5:26:40, time (data): 1.088 (0.002)] l_pix: 1.6203e-02 
2024-05-16 13:48:45,997 INFO: [train..][epoch: 14, iter:   6,400, lr:(2.000e-04,)] [eta: 8 days, 4:07:40, time (data): 1.082 (0.003)] l_pix: 2.9299e-02 
2024-05-16 13:52:22,357 INFO: [train..][epoch: 14, iter:   6,600, lr:(2.000e-04,)] [eta: 8 days, 2:36:01, time (data): 1.081 (0.002)] l_pix: 1.6503e-02 
2024-05-16 13:56:13,452 INFO: [train..][epoch: 15, iter:   6,800, lr:(2.000e-04,)] [eta: 8 days, 1:27:24, time (data): 1.169 (0.094)] l_pix: 2.6515e-02 
2024-05-16 13:59:50,860 INFO: [train..][epoch: 15, iter:   7,000, lr:(2.000e-04,)] [eta: 8 days, 0:06:23, time (data): 1.087 (0.002)] l_pix: 1.1816e-02 
2024-05-16 14:03:40,597 INFO: [train..][epoch: 16, iter:   7,200, lr:(2.000e-04,)] [eta: 7 days, 23:03:45, time (data): 1.162 (0.084)] l_pix: 1.7328e-02 
2024-05-16 14:07:17,336 INFO: [train..][epoch: 16, iter:   7,400, lr:(2.000e-04,)] [eta: 7 days, 21:49:51, time (data): 1.084 (0.002)] l_pix: 2.5818e-02 
2024-05-16 14:11:09,052 INFO: [train..][epoch: 17, iter:   7,600, lr:(2.000e-04,)] [eta: 7 days, 20:55:50, time (data): 1.176 (0.092)] l_pix: 1.3957e-02 
2024-05-16 14:14:46,736 INFO: [train..][epoch: 17, iter:   7,800, lr:(2.000e-04,)] [eta: 7 days, 19:49:38, time (data): 1.087 (0.002)] l_pix: 2.0507e-02 
2024-05-16 14:18:37,591 INFO: [train..][epoch: 18, iter:   8,000, lr:(2.000e-04,)] [eta: 7 days, 19:00:04, time (data): 1.171 (0.090)] l_pix: 1.4196e-02 
2024-05-16 14:22:14,414 INFO: [train..][epoch: 18, iter:   8,200, lr:(2.000e-04,)] [eta: 7 days, 17:58:42, time (data): 1.086 (0.002)] l_pix: 1.1081e-02 
2024-05-16 14:25:51,308 INFO: [train..][epoch: 18, iter:   8,400, lr:(2.000e-04,)] [eta: 7 days, 17:00:09, time (data): 1.084 (0.002)] l_pix: 1.4743e-02 
2024-05-16 14:29:41,602 INFO: [train..][epoch: 19, iter:   8,600, lr:(2.000e-04,)] [eta: 7 days, 16:16:55, time (data): 1.081 (0.002)] l_pix: 1.6880e-02 
2024-05-16 14:33:19,062 INFO: [train..][epoch: 19, iter:   8,800, lr:(2.000e-04,)] [eta: 7 days, 15:23:31, time (data): 1.086 (0.002)] l_pix: 1.5351e-02 
2024-05-16 14:37:12,241 INFO: [train..][epoch: 20, iter:   9,000, lr:(2.000e-04,)] [eta: 7 days, 14:46:39, time (data): 1.190 (0.112)] l_pix: 1.5412e-02 
2024-05-16 14:40:49,857 INFO: [train..][epoch: 20, iter:   9,200, lr:(2.000e-04,)] [eta: 7 days, 13:57:22, time (data): 1.089 (0.002)] l_pix: 1.5952e-02 
2024-05-16 14:44:39,266 INFO: [train..][epoch: 21, iter:   9,400, lr:(2.000e-04,)] [eta: 7 days, 13:20:17, time (data): 1.165 (0.090)] l_pix: 1.8090e-02 
2024-05-16 14:48:16,478 INFO: [train..][epoch: 21, iter:   9,600, lr:(2.000e-04,)] [eta: 7 days, 12:34:12, time (data): 1.086 (0.002)] l_pix: 1.3054e-02 
2024-05-16 14:52:05,353 INFO: [train..][epoch: 22, iter:   9,800, lr:(2.000e-04,)] [eta: 7 days, 11:59:35, time (data): 1.163 (0.085)] l_pix: 2.2402e-02 
2024-05-16 14:55:42,363 INFO: [train..][epoch: 22, iter:  10,000, lr:(2.000e-04,)] [eta: 7 days, 11:16:30, time (data): 1.089 (0.002)] l_pix: 1.0051e-02 
2024-05-16 14:55:42,394 INFO: Saving models and training states.
2024-05-16 14:55:45,798 INFO: Validation Set5
	 # psnr: 37.4396	Best: 37.4396 @ 10000 iter

2024-05-16 14:59:35,160 INFO: [train..][epoch: 23, iter:  10,200, lr:(2.000e-04,)] [eta: 7 days, 10:47:36, time (data): 1.167 (0.086)] l_pix: 1.0755e-02 
2024-05-16 15:03:11,879 INFO: [train..][epoch: 23, iter:  10,400, lr:(2.000e-04,)] [eta: 7 days, 10:07:03, time (data): 1.085 (0.002)] l_pix: 2.0800e-02 
2024-05-16 15:06:49,160 INFO: [train..][epoch: 23, iter:  10,600, lr:(2.000e-04,)] [eta: 7 days, 9:28:19, time (data): 1.085 (0.002)] l_pix: 2.0345e-02 
2024-05-16 15:10:39,175 INFO: [train..][epoch: 24, iter:  10,800, lr:(2.000e-04,)] [eta: 7 days, 9:00:30, time (data): 1.078 (0.002)] l_pix: 1.7957e-02 
2024-05-16 15:14:16,959 INFO: [train..][epoch: 24, iter:  11,000, lr:(2.000e-04,)] [eta: 7 days, 8:24:30, time (data): 1.089 (0.002)] l_pix: 1.7080e-02 
2024-05-16 15:18:05,861 INFO: [train..][epoch: 25, iter:  11,200, lr:(2.000e-04,)] [eta: 7 days, 7:57:44, time (data): 1.167 (0.091)] l_pix: 1.7900e-02 
2024-05-16 15:21:43,875 INFO: [train..][epoch: 25, iter:  11,400, lr:(2.000e-04,)] [eta: 7 days, 7:24:01, time (data): 1.091 (0.002)] l_pix: 7.4064e-03 
2024-05-16 15:25:33,107 INFO: [train..][epoch: 26, iter:  11,600, lr:(2.000e-04,)] [eta: 7 days, 6:59:11, time (data): 1.170 (0.094)] l_pix: 2.7561e-02 
2024-05-16 15:29:10,693 INFO: [train..][epoch: 26, iter:  11,800, lr:(2.000e-04,)] [eta: 7 days, 6:27:03, time (data): 1.089 (0.002)] l_pix: 1.2763e-02 
2024-05-16 15:33:00,975 INFO: [train..][epoch: 27, iter:  12,000, lr:(2.000e-04,)] [eta: 7 days, 6:04:28, time (data): 1.179 (0.098)] l_pix: 1.2689e-02 
2024-05-16 15:36:38,091 INFO: [train..][epoch: 27, iter:  12,200, lr:(2.000e-04,)] [eta: 7 days, 5:33:43, time (data): 1.089 (0.002)] l_pix: 1.8146e-02 
2024-05-16 15:40:15,305 INFO: [train..][epoch: 27, iter:  12,400, lr:(2.000e-04,)] [eta: 7 days, 5:03:55, time (data): 1.085 (0.002)] l_pix: 1.3510e-02 
2024-05-16 15:44:04,514 INFO: [train..][epoch: 28, iter:  12,600, lr:(2.000e-04,)] [eta: 7 days, 4:42:40, time (data): 1.085 (0.002)] l_pix: 1.4984e-02 
2024-05-16 15:47:42,045 INFO: [train..][epoch: 28, iter:  12,800, lr:(2.000e-04,)] [eta: 7 days, 4:14:34, time (data): 1.087 (0.002)] l_pix: 1.5657e-02 
2024-05-16 15:51:31,073 INFO: [train..][epoch: 29, iter:  13,000, lr:(2.000e-04,)] [eta: 7 days, 3:54:23, time (data): 1.080 (0.002)] l_pix: 1.7550e-02 
2024-05-16 15:55:08,882 INFO: [train..][epoch: 29, iter:  13,200, lr:(2.000e-04,)] [eta: 7 days, 3:27:49, time (data): 1.088 (0.002)] l_pix: 1.7127e-02 
2024-05-16 15:58:59,631 INFO: [train..][epoch: 30, iter:  13,400, lr:(2.000e-04,)] [eta: 7 days, 3:09:45, time (data): 1.187 (0.113)] l_pix: 1.4030e-02 
2024-05-16 16:02:37,199 INFO: [train..][epoch: 30, iter:  13,600, lr:(2.000e-04,)] [eta: 7 days, 2:44:16, time (data): 1.088 (0.002)] l_pix: 1.9568e-02 
2024-05-16 16:06:27,123 INFO: [train..][epoch: 31, iter:  13,800, lr:(2.000e-04,)] [eta: 7 days, 2:26:39, time (data): 1.182 (0.106)] l_pix: 1.1926e-02 
2024-05-16 16:10:04,188 INFO: [train..][epoch: 31, iter:  14,000, lr:(2.000e-04,)] [eta: 7 days, 2:02:00, time (data): 1.090 (0.002)] l_pix: 1.8673e-02 
2024-05-16 16:13:54,804 INFO: [train..][epoch: 32, iter:  14,200, lr:(2.000e-04,)] [eta: 7 days, 1:45:40, time (data): 1.188 (0.109)] l_pix: 1.9009e-02 
2024-05-16 16:17:31,025 INFO: [train..][epoch: 32, iter:  14,400, lr:(2.000e-04,)] [eta: 7 days, 1:21:35, time (data): 1.084 (0.002)] l_pix: 1.3997e-02 
2024-05-16 16:21:08,764 INFO: [train..][epoch: 32, iter:  14,600, lr:(2.000e-04,)] [eta: 7 days, 0:58:55, time (data): 1.087 (0.002)] l_pix: 1.6586e-02 
2024-05-16 16:24:59,829 INFO: [train..][epoch: 33, iter:  14,800, lr:(2.000e-04,)] [eta: 7 days, 0:44:02, time (data): 1.077 (0.003)] l_pix: 2.1203e-02 
2024-05-16 16:28:38,043 INFO: [train..][epoch: 33, iter:  15,000, lr:(2.000e-04,)] [eta: 7 days, 0:22:31, time (data): 1.091 (0.003)] l_pix: 1.2165e-02 
2024-05-16 16:28:38,056 INFO: Saving models and training states.
2024-05-16 16:28:41,294 INFO: Validation Set5
	 # psnr: 37.5747	Best: 37.5747 @ 15000 iter

2024-05-16 16:32:30,717 INFO: [train..][epoch: 34, iter:  15,200, lr:(2.000e-04,)] [eta: 7 days, 0:09:10, time (data): 1.077 (0.002)] l_pix: 1.5501e-02 
2024-05-16 16:36:08,547 INFO: [train..][epoch: 34, iter:  15,400, lr:(2.000e-04,)] [eta: 6 days, 23:48:17, time (data): 1.091 (0.002)] l_pix: 1.6215e-02 
2024-05-16 16:40:03,979 INFO: [train..][epoch: 35, iter:  15,600, lr:(2.000e-04,)] [eta: 6 days, 23:36:56, time (data): 1.231 (0.156)] l_pix: 1.4123e-02 
2024-05-16 16:43:41,438 INFO: [train..][epoch: 35, iter:  15,800, lr:(2.000e-04,)] [eta: 6 days, 23:16:36, time (data): 1.094 (0.002)] l_pix: 1.4199e-02 
2024-05-16 16:47:32,519 INFO: [train..][epoch: 36, iter:  16,000, lr:(2.000e-04,)] [eta: 6 days, 23:03:33, time (data): 1.198 (0.118)] l_pix: 8.5263e-03 
2024-05-16 16:51:09,399 INFO: [train..][epoch: 36, iter:  16,200, lr:(2.000e-04,)] [eta: 6 days, 22:43:40, time (data): 1.090 (0.002)] l_pix: 1.4069e-02 
2024-05-16 16:55:00,143 INFO: [train..][epoch: 37, iter:  16,400, lr:(2.000e-04,)] [eta: 6 days, 22:30:59, time (data): 1.197 (0.114)] l_pix: 1.9532e-02 
2024-05-16 16:58:36,088 INFO: [train..][epoch: 37, iter:  16,600, lr:(2.000e-04,)] [eta: 6 days, 22:11:20, time (data): 1.083 (0.002)] l_pix: 1.7688e-02 
2024-05-16 17:02:14,242 INFO: [train..][epoch: 37, iter:  16,800, lr:(2.000e-04,)] [eta: 6 days, 21:53:08, time (data): 1.091 (0.002)] l_pix: 1.3967e-02 
2024-05-16 17:06:05,399 INFO: [train..][epoch: 38, iter:  17,000, lr:(2.000e-04,)] [eta: 6 days, 21:41:25, time (data): 1.074 (0.002)] l_pix: 1.4664e-02 
2024-05-16 17:09:43,211 INFO: [train..][epoch: 38, iter:  17,200, lr:(2.000e-04,)] [eta: 6 days, 21:23:39, time (data): 1.093 (0.002)] l_pix: 1.8401e-02 
